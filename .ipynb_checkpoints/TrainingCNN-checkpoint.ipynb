{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe4b4d-5f70-4258-9966-6845a33bd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descarga de índices bursátiles desde Yahoo Finances.\n",
    "# -- Sólo descomentar una vez, el resto de usos se pueden hacer desde el fichero descargado\n",
    "\"\"\"\n",
    "import yfinance as yf\n",
    "\n",
    "tickers = [\n",
    "    \"^GSPC\",\"^IXIC\",\"^DJI\",\"^RUT\",\n",
    "    \"^FTSE\",\"^GDAXI\",\"^FCHI\",\"^125904-USD-STRD\",\"^IBEX\",\n",
    "    \"^N225\",\"^HSI\",\"000001.SS\",\"^KS11\",\"^BSESN\",\n",
    "    \"^GSPTSE\",\"^BVSP\",\"^MXX\",\"^MERV\",\n",
    "    \"^AXJO\",\"^NZ50\",\n",
    "    \"ES=F\",\"NQ=F\",\"YM=F\",\"ZT=F\",\"^VIX\"\n",
    "]\n",
    "\n",
    "# Descarga de cierres diarios sin agrupar por ticker\n",
    "data = yf.download(\n",
    "    tickers,\n",
    "    start=\"2005-01-01\",\n",
    "    end=\"2025-01-02\"\n",
    ")\n",
    "\n",
    "cierres = data[\"Close\"]  # DataFrame con cada ticker como columna\n",
    "cierres.to_csv(\"./data/cierres_diarios_2005_2025.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be074fb9-6bc8-4a09-beb8-1329bfaa6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso de los datos descargados para entrenamiento\n",
    "# -- Asegurarse de enrutamiento y nombre de fichero correctos\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/cierres_diarios_2005_2025n.csv', parse_dates=['Date'], index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9401af07-1d10-406c-ae0e-1bb81dfb3913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 20:26:48.425163: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-09-17 20:26:48.425192: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-09-17 20:26:48.425198: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-09-17 20:26:48.425216: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-17 20:26:48.425227: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Preparación de los datos\n",
    "\n",
    "# Eliminación de nulos\n",
    "df.ffill(inplace=True)\n",
    "df.bfill(inplace=True)\n",
    "\n",
    "# Split en crudo (¡antes de escalar!)\n",
    "n = len(df)\n",
    "train_raw = df.iloc[:int(n*0.7)]\n",
    "val_raw   = df.iloc[int(n*0.7):int(n*0.9)]\n",
    "test_raw  = df.iloc[int(n*0.9):]\n",
    "\n",
    "# Ajustar scaler SOLO con TRAIN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_raw)  # <- fit solo con train\n",
    "\n",
    "# Transformar cada split con ese scaler\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(scaler.transform(train_raw), index=train_raw.index, columns=train_raw.columns).astype(\"float32\")\n",
    "val_df   = pd.DataFrame(scaler.transform(val_raw),   index=val_raw.index,   columns=val_raw.columns).astype(\"float32\")\n",
    "test_df  = pd.DataFrame(scaler.transform(test_raw),  index=test_raw.index,  columns=test_raw.columns).astype(\"float32\")\n",
    "\n",
    "# Guardar scaler para escenarios S/M/L\n",
    "dump(scaler, \"scaler_modelos.joblib\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_dataset(data, window_size, horizon, batch_size=32, shuffle=True):\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        data=data.values,\n",
    "        targets=None,\n",
    "        sequence_length=window_size + horizon,\n",
    "        sequence_stride=1,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return ds.map(\n",
    "        lambda seq: (\n",
    "            tf.cast(seq[:, :window_size, :], tf.float32),\n",
    "            tf.cast(seq[:, window_size:, :], tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Recreamos datasets con shuffle=False para val/test:\n",
    "train_dss = make_dataset(train_df, window_size=20,  horizon=1,  batch_size=32, shuffle=True)\n",
    "val_dss   = make_dataset(val_df,   window_size=20,  horizon=1,  batch_size=32, shuffle=False)\n",
    "test_dss  = make_dataset(test_df,  window_size=20,  horizon=1,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_dsm = make_dataset(train_df, window_size=60,  horizon=5,  batch_size=32, shuffle=True)\n",
    "val_dsm   = make_dataset(val_df,   window_size=60,  horizon=5,  batch_size=32, shuffle=False)\n",
    "test_dsm  = make_dataset(test_df,  window_size=60,  horizon=5,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_dsl = make_dataset(train_df, window_size=120, horizon=20, batch_size=32, shuffle=True)\n",
    "val_dsl   = make_dataset(val_df,   window_size=120, horizon=20, batch_size=32, shuffle=False)\n",
    "test_dsl  = make_dataset(test_df,  window_size=120, horizon=20, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c2b1de-2e02-47e9-88a3-f00a4a682c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Barrido Huber delta _S ===\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 20:26:51.652501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - log_cosh: 0.3328 - loss: 0.0073 - within_eps_0_005: 0.0043 - within_eps_0_01: 0.0091 - within_eps_0_02: 0.0189 - within_eps_0_05: 0.0470 - within_eps_0_1: 0.0933 - val_log_cosh: 0.1084 - val_loss: 0.0036 - val_within_eps_0_005: 0.0093 - val_within_eps_0_01: 0.0186 - val_within_eps_0_02: 0.0384 - val_within_eps_0_05: 0.1025 - val_within_eps_0_1: 0.1952\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - log_cosh: 0.1630 - loss: 0.0048 - within_eps_0_005: 0.0061 - within_eps_0_01: 0.0134 - within_eps_0_02: 0.0260 - within_eps_0_05: 0.0662 - within_eps_0_1: 0.1311 - val_log_cosh: 0.0733 - val_loss: 0.0028 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1391 - val_within_eps_0_1: 0.2783\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0923 - loss: 0.0035 - within_eps_0_005: 0.0086 - within_eps_0_01: 0.0178 - within_eps_0_02: 0.0358 - within_eps_0_05: 0.0916 - within_eps_0_1: 0.1808 - val_log_cosh: 0.0723 - val_loss: 0.0027 - val_within_eps_0_005: 0.0176 - val_within_eps_0_01: 0.0339 - val_within_eps_0_02: 0.0677 - val_within_eps_0_05: 0.1546 - val_within_eps_0_1: 0.2861\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - log_cosh: 0.0400 - loss: 0.0022 - within_eps_0_005: 0.0147 - within_eps_0_01: 0.0286 - within_eps_0_02: 0.0575 - within_eps_0_05: 0.1434 - within_eps_0_1: 0.2819 - val_log_cosh: 0.0619 - val_loss: 0.0025 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0530 - val_within_eps_0_05: 0.1403 - val_within_eps_0_1: 0.2964\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - log_cosh: 0.0109 - loss: 0.0011 - within_eps_0_005: 0.0291 - within_eps_0_01: 0.0576 - within_eps_0_02: 0.1137 - within_eps_0_05: 0.2775 - within_eps_0_1: 0.5193 - val_log_cosh: 0.0663 - val_loss: 0.0026 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1356 - val_within_eps_0_1: 0.2801\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0061 - loss: 8.1293e-04 - within_eps_0_005: 0.0388 - within_eps_0_01: 0.0763 - within_eps_0_02: 0.1514 - within_eps_0_05: 0.3691 - within_eps_0_1: 0.6576 - val_log_cosh: 0.0628 - val_loss: 0.0025 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1594 - val_within_eps_0_1: 0.3319\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0048 - loss: 7.1568e-04 - within_eps_0_005: 0.0414 - within_eps_0_01: 0.0864 - within_eps_0_02: 0.1728 - within_eps_0_05: 0.4164 - within_eps_0_1: 0.7159 - val_log_cosh: 0.0643 - val_loss: 0.0025 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0323 - val_within_eps_0_02: 0.0638 - val_within_eps_0_05: 0.1754 - val_within_eps_0_1: 0.3375\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0040 - loss: 6.4138e-04 - within_eps_0_005: 0.0488 - within_eps_0_01: 0.0966 - within_eps_0_02: 0.1935 - within_eps_0_05: 0.4541 - within_eps_0_1: 0.7620 - val_log_cosh: 0.0570 - val_loss: 0.0023 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0435 - val_within_eps_0_02: 0.0862 - val_within_eps_0_05: 0.1894 - val_within_eps_0_1: 0.3454\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0034 - loss: 5.9071e-04 - within_eps_0_005: 0.0525 - within_eps_0_01: 0.1058 - within_eps_0_02: 0.2108 - within_eps_0_05: 0.4889 - within_eps_0_1: 0.7954 - val_log_cosh: 0.0680 - val_loss: 0.0026 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0338 - val_within_eps_0_02: 0.0681 - val_within_eps_0_05: 0.1780 - val_within_eps_0_1: 0.3312\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0029 - loss: 5.3745e-04 - within_eps_0_005: 0.0582 - within_eps_0_01: 0.1150 - within_eps_0_02: 0.2295 - within_eps_0_05: 0.5284 - within_eps_0_1: 0.8311 - val_log_cosh: 0.0653 - val_loss: 0.0025 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0380 - val_within_eps_0_02: 0.0744 - val_within_eps_0_05: 0.1882 - val_within_eps_0_1: 0.3475\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0027 - loss: 5.0981e-04 - within_eps_0_005: 0.0613 - within_eps_0_01: 0.1223 - within_eps_0_02: 0.2431 - within_eps_0_05: 0.5552 - within_eps_0_1: 0.8451 - val_log_cosh: 0.0647 - val_loss: 0.0025 - val_within_eps_0_005: 0.0197 - val_within_eps_0_01: 0.0369 - val_within_eps_0_02: 0.0732 - val_within_eps_0_05: 0.1860 - val_within_eps_0_1: 0.3489\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0024 - loss: 4.8188e-04 - within_eps_0_005: 0.0645 - within_eps_0_01: 0.1293 - within_eps_0_02: 0.2587 - within_eps_0_05: 0.5740 - within_eps_0_1: 0.8652 - val_log_cosh: 0.0610 - val_loss: 0.0024 - val_within_eps_0_005: 0.0200 - val_within_eps_0_01: 0.0444 - val_within_eps_0_02: 0.0901 - val_within_eps_0_05: 0.2121 - val_within_eps_0_1: 0.3792\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0022 - loss: 4.5315e-04 - within_eps_0_005: 0.0704 - within_eps_0_01: 0.1405 - within_eps_0_02: 0.2747 - within_eps_0_05: 0.6041 - within_eps_0_1: 0.8799 - val_log_cosh: 0.0663 - val_loss: 0.0026 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0761 - val_within_eps_0_05: 0.1836 - val_within_eps_0_1: 0.3383\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0020 - loss: 4.3405e-04 - within_eps_0_005: 0.0719 - within_eps_0_01: 0.1458 - within_eps_0_02: 0.2835 - within_eps_0_05: 0.6201 - within_eps_0_1: 0.8931 - val_log_cosh: 0.0614 - val_loss: 0.0025 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0394 - val_within_eps_0_02: 0.0791 - val_within_eps_0_05: 0.1876 - val_within_eps_0_1: 0.3574\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0020 - loss: 4.2604e-04 - within_eps_0_005: 0.0718 - within_eps_0_01: 0.1455 - within_eps_0_02: 0.2882 - within_eps_0_05: 0.6282 - within_eps_0_1: 0.8998 - val_log_cosh: 0.0608 - val_loss: 0.0024 - val_within_eps_0_005: 0.0217 - val_within_eps_0_01: 0.0431 - val_within_eps_0_02: 0.0877 - val_within_eps_0_05: 0.2082 - val_within_eps_0_1: 0.3730\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0018 - loss: 4.0346e-04 - within_eps_0_005: 0.0789 - within_eps_0_01: 0.1542 - within_eps_0_02: 0.3031 - within_eps_0_05: 0.6503 - within_eps_0_1: 0.9114 - val_log_cosh: 0.0620 - val_loss: 0.0025 - val_within_eps_0_005: 0.0229 - val_within_eps_0_01: 0.0463 - val_within_eps_0_02: 0.0917 - val_within_eps_0_05: 0.1983 - val_within_eps_0_1: 0.3627\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0017 - loss: 3.9701e-04 - within_eps_0_005: 0.0811 - within_eps_0_01: 0.1598 - within_eps_0_02: 0.3090 - within_eps_0_05: 0.6590 - within_eps_0_1: 0.9137 - val_log_cosh: 0.0633 - val_loss: 0.0025 - val_within_eps_0_005: 0.0218 - val_within_eps_0_01: 0.0418 - val_within_eps_0_02: 0.0839 - val_within_eps_0_05: 0.1978 - val_within_eps_0_1: 0.3614\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0017 - loss: 3.9553e-04 - within_eps_0_005: 0.0789 - within_eps_0_01: 0.1582 - within_eps_0_02: 0.3084 - within_eps_0_05: 0.6604 - within_eps_0_1: 0.9145 - val_log_cosh: 0.0595 - val_loss: 0.0024 - val_within_eps_0_005: 0.0217 - val_within_eps_0_01: 0.0423 - val_within_eps_0_02: 0.0836 - val_within_eps_0_05: 0.1979 - val_within_eps_0_1: 0.3721\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0016 - loss: 3.7129e-04 - within_eps_0_005: 0.0854 - within_eps_0_01: 0.1703 - within_eps_0_02: 0.3289 - within_eps_0_05: 0.6882 - within_eps_0_1: 0.9263 - val_log_cosh: 0.0663 - val_loss: 0.0026 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0683 - val_within_eps_0_05: 0.1802 - val_within_eps_0_1: 0.3238\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0016 - loss: 3.7748e-04 - within_eps_0_005: 0.0853 - within_eps_0_01: 0.1685 - within_eps_0_02: 0.3261 - within_eps_0_05: 0.6792 - within_eps_0_1: 0.9230 - val_log_cosh: 0.0659 - val_loss: 0.0026 - val_within_eps_0_005: 0.0182 - val_within_eps_0_01: 0.0375 - val_within_eps_0_02: 0.0769 - val_within_eps_0_05: 0.1843 - val_within_eps_0_1: 0.3374\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0015 - loss: 3.6624e-04 - within_eps_0_005: 0.0842 - within_eps_0_01: 0.1703 - within_eps_0_02: 0.3341 - within_eps_0_05: 0.6937 - within_eps_0_1: 0.9280 - val_log_cosh: 0.0634 - val_loss: 0.0025 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0426 - val_within_eps_0_02: 0.0847 - val_within_eps_0_05: 0.2051 - val_within_eps_0_1: 0.3627\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0014 - loss: 3.5208e-04 - within_eps_0_005: 0.0912 - within_eps_0_01: 0.1807 - within_eps_0_02: 0.3502 - within_eps_0_05: 0.7087 - within_eps_0_1: 0.9349 - val_log_cosh: 0.0652 - val_loss: 0.0026 - val_within_eps_0_005: 0.0201 - val_within_eps_0_01: 0.0400 - val_within_eps_0_02: 0.0790 - val_within_eps_0_05: 0.1885 - val_within_eps_0_1: 0.3344\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0014 - loss: 3.4854e-04 - within_eps_0_005: 0.0908 - within_eps_0_01: 0.1824 - within_eps_0_02: 0.3516 - within_eps_0_05: 0.7108 - within_eps_0_1: 0.9375 - val_log_cosh: 0.0617 - val_loss: 0.0025 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0456 - val_within_eps_0_02: 0.0882 - val_within_eps_0_05: 0.2016 - val_within_eps_0_1: 0.3564\n",
      "  -> val_loss(min) δ=0.01: 0.002322742948\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - log_cosh: 0.3174 - loss: 0.0141 - within_eps_0_005: 0.0048 - within_eps_0_01: 0.0094 - within_eps_0_02: 0.0186 - within_eps_0_05: 0.0468 - within_eps_0_1: 0.0931 - val_log_cosh: 0.0912 - val_loss: 0.0064 - val_within_eps_0_005: 0.0095 - val_within_eps_0_01: 0.0189 - val_within_eps_0_02: 0.0386 - val_within_eps_0_05: 0.0986 - val_within_eps_0_1: 0.2013\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.1561 - loss: 0.0093 - within_eps_0_005: 0.0065 - within_eps_0_01: 0.0137 - within_eps_0_02: 0.0276 - within_eps_0_05: 0.0688 - within_eps_0_1: 0.1361 - val_log_cosh: 0.0847 - val_loss: 0.0060 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0224 - val_within_eps_0_02: 0.0480 - val_within_eps_0_05: 0.1255 - val_within_eps_0_1: 0.2517\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0838 - loss: 0.0065 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0197 - within_eps_0_02: 0.0387 - within_eps_0_05: 0.0968 - within_eps_0_1: 0.1924 - val_log_cosh: 0.0690 - val_loss: 0.0054 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0501 - val_within_eps_0_05: 0.1289 - val_within_eps_0_1: 0.2635\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0301 - loss: 0.0037 - within_eps_0_005: 0.0165 - within_eps_0_01: 0.0333 - within_eps_0_02: 0.0688 - within_eps_0_05: 0.1698 - within_eps_0_1: 0.3303 - val_log_cosh: 0.0586 - val_loss: 0.0047 - val_within_eps_0_005: 0.0201 - val_within_eps_0_01: 0.0387 - val_within_eps_0_02: 0.0763 - val_within_eps_0_05: 0.1793 - val_within_eps_0_1: 0.3387\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0102 - loss: 0.0021 - within_eps_0_005: 0.0287 - within_eps_0_01: 0.0589 - within_eps_0_02: 0.1178 - within_eps_0_05: 0.2888 - within_eps_0_1: 0.5339 - val_log_cosh: 0.0567 - val_loss: 0.0046 - val_within_eps_0_005: 0.0202 - val_within_eps_0_01: 0.0407 - val_within_eps_0_02: 0.0829 - val_within_eps_0_05: 0.1854 - val_within_eps_0_1: 0.3429\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0060 - loss: 0.0015 - within_eps_0_005: 0.0378 - within_eps_0_01: 0.0741 - within_eps_0_02: 0.1515 - within_eps_0_05: 0.3702 - within_eps_0_1: 0.6593 - val_log_cosh: 0.0633 - val_loss: 0.0050 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0341 - val_within_eps_0_02: 0.0666 - val_within_eps_0_05: 0.1666 - val_within_eps_0_1: 0.3304\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0047 - loss: 0.0013 - within_eps_0_005: 0.0445 - within_eps_0_01: 0.0868 - within_eps_0_02: 0.1724 - within_eps_0_05: 0.4160 - within_eps_0_1: 0.7168 - val_log_cosh: 0.0691 - val_loss: 0.0052 - val_within_eps_0_005: 0.0195 - val_within_eps_0_01: 0.0363 - val_within_eps_0_02: 0.0727 - val_within_eps_0_05: 0.1679 - val_within_eps_0_1: 0.3175\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0041 - loss: 0.0012 - within_eps_0_005: 0.0481 - within_eps_0_01: 0.0952 - within_eps_0_02: 0.1879 - within_eps_0_05: 0.4479 - within_eps_0_1: 0.7538 - val_log_cosh: 0.0673 - val_loss: 0.0051 - val_within_eps_0_005: 0.0197 - val_within_eps_0_01: 0.0400 - val_within_eps_0_02: 0.0760 - val_within_eps_0_05: 0.1687 - val_within_eps_0_1: 0.3270\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0035 - loss: 0.0011 - within_eps_0_005: 0.0527 - within_eps_0_01: 0.1051 - within_eps_0_02: 0.2124 - within_eps_0_05: 0.4952 - within_eps_0_1: 0.7971 - val_log_cosh: 0.0583 - val_loss: 0.0046 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0387 - val_within_eps_0_02: 0.0790 - val_within_eps_0_05: 0.1929 - val_within_eps_0_1: 0.3647\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0033 - loss: 0.0011 - within_eps_0_005: 0.0578 - within_eps_0_01: 0.1123 - within_eps_0_02: 0.2206 - within_eps_0_05: 0.5076 - within_eps_0_1: 0.8073 - val_log_cosh: 0.0606 - val_loss: 0.0048 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0368 - val_within_eps_0_02: 0.0734 - val_within_eps_0_05: 0.1744 - val_within_eps_0_1: 0.3399\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0029 - loss: 9.7979e-04 - within_eps_0_005: 0.0590 - within_eps_0_01: 0.1208 - within_eps_0_02: 0.2365 - within_eps_0_05: 0.5375 - within_eps_0_1: 0.8310 - val_log_cosh: 0.0708 - val_loss: 0.0053 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0334 - val_within_eps_0_02: 0.0653 - val_within_eps_0_05: 0.1582 - val_within_eps_0_1: 0.2990\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0027 - loss: 9.2450e-04 - within_eps_0_005: 0.0644 - within_eps_0_01: 0.1274 - within_eps_0_02: 0.2507 - within_eps_0_05: 0.5607 - within_eps_0_1: 0.8468 - val_log_cosh: 0.0601 - val_loss: 0.0047 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0418 - val_within_eps_0_02: 0.0862 - val_within_eps_0_05: 0.1957 - val_within_eps_0_1: 0.3490\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0025 - loss: 8.7908e-04 - within_eps_0_005: 0.0672 - within_eps_0_01: 0.1330 - within_eps_0_02: 0.2627 - within_eps_0_05: 0.5810 - within_eps_0_1: 0.8634 - val_log_cosh: 0.0621 - val_loss: 0.0049 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0371 - val_within_eps_0_02: 0.0736 - val_within_eps_0_05: 0.1739 - val_within_eps_0_1: 0.3443\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0024 - loss: 8.5618e-04 - within_eps_0_005: 0.0687 - within_eps_0_01: 0.1352 - within_eps_0_02: 0.2670 - within_eps_0_05: 0.5938 - within_eps_0_1: 0.8698 - val_log_cosh: 0.0731 - val_loss: 0.0055 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0542 - val_within_eps_0_05: 0.1416 - val_within_eps_0_1: 0.2836\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0025 - loss: 8.7874e-04 - within_eps_0_005: 0.0673 - within_eps_0_01: 0.1320 - within_eps_0_02: 0.2611 - within_eps_0_05: 0.5791 - within_eps_0_1: 0.8640 - val_log_cosh: 0.0684 - val_loss: 0.0052 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0336 - val_within_eps_0_02: 0.0652 - val_within_eps_0_05: 0.1599 - val_within_eps_0_1: 0.3060\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0022 - loss: 8.1053e-04 - within_eps_0_005: 0.0707 - within_eps_0_01: 0.1416 - within_eps_0_02: 0.2802 - within_eps_0_05: 0.6163 - within_eps_0_1: 0.8819 - val_log_cosh: 0.0628 - val_loss: 0.0049 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0389 - val_within_eps_0_02: 0.0740 - val_within_eps_0_05: 0.1811 - val_within_eps_0_1: 0.3424\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0021 - loss: 7.8932e-04 - within_eps_0_005: 0.0723 - within_eps_0_01: 0.1476 - within_eps_0_02: 0.2899 - within_eps_0_05: 0.6252 - within_eps_0_1: 0.8871 - val_log_cosh: 0.0660 - val_loss: 0.0051 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0361 - val_within_eps_0_02: 0.0716 - val_within_eps_0_05: 0.1658 - val_within_eps_0_1: 0.3205\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0020 - loss: 7.6645e-04 - within_eps_0_005: 0.0772 - within_eps_0_01: 0.1522 - within_eps_0_02: 0.2972 - within_eps_0_05: 0.6353 - within_eps_0_1: 0.8960 - val_log_cosh: 0.0740 - val_loss: 0.0055 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0277 - val_within_eps_0_02: 0.0554 - val_within_eps_0_05: 0.1427 - val_within_eps_0_1: 0.2819\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0020 - loss: 7.4379e-04 - within_eps_0_005: 0.0794 - within_eps_0_01: 0.1589 - within_eps_0_02: 0.3098 - within_eps_0_05: 0.6515 - within_eps_0_1: 0.8991 - val_log_cosh: 0.0709 - val_loss: 0.0053 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0572 - val_within_eps_0_05: 0.1546 - val_within_eps_0_1: 0.2952\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0019 - loss: 7.2392e-04 - within_eps_0_005: 0.0838 - within_eps_0_01: 0.1636 - within_eps_0_02: 0.3167 - within_eps_0_05: 0.6578 - within_eps_0_1: 0.9053 - val_log_cosh: 0.0684 - val_loss: 0.0052 - val_within_eps_0_005: 0.0177 - val_within_eps_0_01: 0.0351 - val_within_eps_0_02: 0.0699 - val_within_eps_0_05: 0.1686 - val_within_eps_0_1: 0.3101\n",
      "  -> val_loss(min) δ=0.02: 0.004598179832\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - log_cosh: 0.3414 - loss: 0.0360 - within_eps_0_005: 0.0043 - within_eps_0_01: 0.0089 - within_eps_0_02: 0.0178 - within_eps_0_05: 0.0452 - within_eps_0_1: 0.0896 - val_log_cosh: 0.1059 - val_loss: 0.0168 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0225 - val_within_eps_0_02: 0.0437 - val_within_eps_0_05: 0.1150 - val_within_eps_0_1: 0.2227\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.1630 - loss: 0.0232 - within_eps_0_005: 0.0069 - within_eps_0_01: 0.0137 - within_eps_0_02: 0.0261 - within_eps_0_05: 0.0648 - within_eps_0_1: 0.1295 - val_log_cosh: 0.0833 - val_loss: 0.0141 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0563 - val_within_eps_0_05: 0.1291 - val_within_eps_0_1: 0.2469\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0875 - loss: 0.0160 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0195 - within_eps_0_02: 0.0381 - within_eps_0_05: 0.0951 - within_eps_0_1: 0.1863 - val_log_cosh: 0.0647 - val_loss: 0.0117 - val_within_eps_0_005: 0.0177 - val_within_eps_0_01: 0.0356 - val_within_eps_0_02: 0.0673 - val_within_eps_0_05: 0.1588 - val_within_eps_0_1: 0.3071\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0273 - loss: 0.0081 - within_eps_0_005: 0.0189 - within_eps_0_01: 0.0367 - within_eps_0_02: 0.0723 - within_eps_0_05: 0.1799 - within_eps_0_1: 0.3502 - val_log_cosh: 0.0514 - val_loss: 0.0100 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0383 - val_within_eps_0_02: 0.0772 - val_within_eps_0_05: 0.1942 - val_within_eps_0_1: 0.3570\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0091 - loss: 0.0042 - within_eps_0_005: 0.0309 - within_eps_0_01: 0.0627 - within_eps_0_02: 0.1253 - within_eps_0_05: 0.3057 - within_eps_0_1: 0.5622 - val_log_cosh: 0.0548 - val_loss: 0.0103 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0840 - val_within_eps_0_05: 0.1998 - val_within_eps_0_1: 0.3653\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0059 - loss: 0.0032 - within_eps_0_005: 0.0398 - within_eps_0_01: 0.0784 - within_eps_0_02: 0.1546 - within_eps_0_05: 0.3746 - within_eps_0_1: 0.6630 - val_log_cosh: 0.0556 - val_loss: 0.0107 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0351 - val_within_eps_0_02: 0.0720 - val_within_eps_0_05: 0.1872 - val_within_eps_0_1: 0.3528\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0046 - loss: 0.0027 - within_eps_0_005: 0.0462 - within_eps_0_01: 0.0900 - within_eps_0_02: 0.1771 - within_eps_0_05: 0.4210 - within_eps_0_1: 0.7241 - val_log_cosh: 0.0620 - val_loss: 0.0116 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0398 - val_within_eps_0_02: 0.0762 - val_within_eps_0_05: 0.1751 - val_within_eps_0_1: 0.3284\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0039 - loss: 0.0024 - within_eps_0_005: 0.0483 - within_eps_0_01: 0.0970 - within_eps_0_02: 0.1919 - within_eps_0_05: 0.4538 - within_eps_0_1: 0.7616 - val_log_cosh: 0.0587 - val_loss: 0.0112 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0390 - val_within_eps_0_02: 0.0753 - val_within_eps_0_05: 0.1830 - val_within_eps_0_1: 0.3296\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0033 - loss: 0.0021 - within_eps_0_005: 0.0540 - within_eps_0_01: 0.1077 - within_eps_0_02: 0.2131 - within_eps_0_05: 0.4940 - within_eps_0_1: 0.7977 - val_log_cosh: 0.0563 - val_loss: 0.0110 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0729 - val_within_eps_0_05: 0.1842 - val_within_eps_0_1: 0.3378\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0030 - loss: 0.0020 - within_eps_0_005: 0.0543 - within_eps_0_01: 0.1123 - within_eps_0_02: 0.2235 - within_eps_0_05: 0.5189 - within_eps_0_1: 0.8209 - val_log_cosh: 0.0576 - val_loss: 0.0111 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0364 - val_within_eps_0_02: 0.0732 - val_within_eps_0_05: 0.1778 - val_within_eps_0_1: 0.3387\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0027 - loss: 0.0018 - within_eps_0_005: 0.0603 - within_eps_0_01: 0.1202 - within_eps_0_02: 0.2365 - within_eps_0_05: 0.5405 - within_eps_0_1: 0.8419 - val_log_cosh: 0.0653 - val_loss: 0.0123 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0548 - val_within_eps_0_05: 0.1449 - val_within_eps_0_1: 0.2842\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0024 - loss: 0.0017 - within_eps_0_005: 0.0659 - within_eps_0_01: 0.1309 - within_eps_0_02: 0.2541 - within_eps_0_05: 0.5708 - within_eps_0_1: 0.8606 - val_log_cosh: 0.0645 - val_loss: 0.0122 - val_within_eps_0_005: 0.0118 - val_within_eps_0_01: 0.0250 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1460 - val_within_eps_0_1: 0.2919\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0022 - loss: 0.0016 - within_eps_0_005: 0.0668 - within_eps_0_01: 0.1350 - within_eps_0_02: 0.2670 - within_eps_0_05: 0.5907 - within_eps_0_1: 0.8742 - val_log_cosh: 0.0555 - val_loss: 0.0108 - val_within_eps_0_005: 0.0202 - val_within_eps_0_01: 0.0397 - val_within_eps_0_02: 0.0795 - val_within_eps_0_05: 0.1869 - val_within_eps_0_1: 0.3425\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0021 - loss: 0.0015 - within_eps_0_005: 0.0725 - within_eps_0_01: 0.1433 - within_eps_0_02: 0.2819 - within_eps_0_05: 0.6098 - within_eps_0_1: 0.8855 - val_log_cosh: 0.0631 - val_loss: 0.0121 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0253 - val_within_eps_0_02: 0.0511 - val_within_eps_0_05: 0.1395 - val_within_eps_0_1: 0.2899\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0020 - loss: 0.0014 - within_eps_0_005: 0.0761 - within_eps_0_01: 0.1478 - within_eps_0_02: 0.2857 - within_eps_0_05: 0.6239 - within_eps_0_1: 0.8934 - val_log_cosh: 0.0559 - val_loss: 0.0109 - val_within_eps_0_005: 0.0178 - val_within_eps_0_01: 0.0350 - val_within_eps_0_02: 0.0702 - val_within_eps_0_05: 0.1751 - val_within_eps_0_1: 0.3368\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0020 - loss: 0.0014 - within_eps_0_005: 0.0719 - within_eps_0_01: 0.1435 - within_eps_0_02: 0.2802 - within_eps_0_05: 0.6221 - within_eps_0_1: 0.8938 - val_log_cosh: 0.0617 - val_loss: 0.0118 - val_within_eps_0_005: 0.0167 - val_within_eps_0_01: 0.0345 - val_within_eps_0_02: 0.0683 - val_within_eps_0_05: 0.1640 - val_within_eps_0_1: 0.3089\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0018 - loss: 0.0013 - within_eps_0_005: 0.0784 - within_eps_0_01: 0.1539 - within_eps_0_02: 0.3022 - within_eps_0_05: 0.6457 - within_eps_0_1: 0.9072 - val_log_cosh: 0.0600 - val_loss: 0.0116 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0614 - val_within_eps_0_05: 0.1558 - val_within_eps_0_1: 0.3104\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0017 - loss: 0.0013 - within_eps_0_005: 0.0777 - within_eps_0_01: 0.1561 - within_eps_0_02: 0.3056 - within_eps_0_05: 0.6558 - within_eps_0_1: 0.9134 - val_log_cosh: 0.0636 - val_loss: 0.0120 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0586 - val_within_eps_0_05: 0.1551 - val_within_eps_0_1: 0.3031\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0841 - within_eps_0_01: 0.1666 - within_eps_0_02: 0.3212 - within_eps_0_05: 0.6734 - within_eps_0_1: 0.9204 - val_log_cosh: 0.0594 - val_loss: 0.0114 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0300 - val_within_eps_0_02: 0.0633 - val_within_eps_0_05: 0.1644 - val_within_eps_0_1: 0.3239\n",
      "  -> val_loss(min) δ=0.05: 0.010008188896\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - log_cosh: 0.3384 - loss: 0.0691 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0092 - within_eps_0_02: 0.0179 - within_eps_0_05: 0.0459 - within_eps_0_1: 0.0922 - val_log_cosh: 0.0996 - val_loss: 0.0292 - val_within_eps_0_005: 0.0126 - val_within_eps_0_01: 0.0270 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1300 - val_within_eps_0_1: 0.2505\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.1629 - loss: 0.0441 - within_eps_0_005: 0.0068 - within_eps_0_01: 0.0137 - within_eps_0_02: 0.0279 - within_eps_0_05: 0.0662 - within_eps_0_1: 0.1295 - val_log_cosh: 0.0816 - val_loss: 0.0250 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0612 - val_within_eps_0_05: 0.1523 - val_within_eps_0_1: 0.2846\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.1055 - loss: 0.0336 - within_eps_0_005: 0.0075 - within_eps_0_01: 0.0161 - within_eps_0_02: 0.0341 - within_eps_0_05: 0.0842 - within_eps_0_1: 0.1667 - val_log_cosh: 0.0678 - val_loss: 0.0224 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0551 - val_within_eps_0_05: 0.1472 - val_within_eps_0_1: 0.2845\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0469 - loss: 0.0201 - within_eps_0_005: 0.0132 - within_eps_0_01: 0.0261 - within_eps_0_02: 0.0521 - within_eps_0_05: 0.1324 - within_eps_0_1: 0.2618 - val_log_cosh: 0.0664 - val_loss: 0.0225 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0347 - val_within_eps_0_02: 0.0667 - val_within_eps_0_05: 0.1489 - val_within_eps_0_1: 0.2874\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0112 - loss: 0.0077 - within_eps_0_005: 0.0284 - within_eps_0_01: 0.0571 - within_eps_0_02: 0.1128 - within_eps_0_05: 0.2775 - within_eps_0_1: 0.5192 - val_log_cosh: 0.0667 - val_loss: 0.0225 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0630 - val_within_eps_0_05: 0.1524 - val_within_eps_0_1: 0.3003\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0063 - loss: 0.0050 - within_eps_0_005: 0.0390 - within_eps_0_01: 0.0758 - within_eps_0_02: 0.1506 - within_eps_0_05: 0.3615 - within_eps_0_1: 0.6511 - val_log_cosh: 0.0655 - val_loss: 0.0220 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0669 - val_within_eps_0_05: 0.1672 - val_within_eps_0_1: 0.3290\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0049 - loss: 0.0041 - within_eps_0_005: 0.0423 - within_eps_0_01: 0.0857 - within_eps_0_02: 0.1725 - within_eps_0_05: 0.4104 - within_eps_0_1: 0.7080 - val_log_cosh: 0.0675 - val_loss: 0.0228 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0302 - val_within_eps_0_02: 0.0607 - val_within_eps_0_05: 0.1550 - val_within_eps_0_1: 0.2978\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0042 - loss: 0.0036 - within_eps_0_005: 0.0477 - within_eps_0_01: 0.0956 - within_eps_0_02: 0.1883 - within_eps_0_05: 0.4409 - within_eps_0_1: 0.7483 - val_log_cosh: 0.0667 - val_loss: 0.0227 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0365 - val_within_eps_0_02: 0.0703 - val_within_eps_0_05: 0.1606 - val_within_eps_0_1: 0.3017\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0036 - loss: 0.0032 - within_eps_0_005: 0.0506 - within_eps_0_01: 0.1019 - within_eps_0_02: 0.2000 - within_eps_0_05: 0.4755 - within_eps_0_1: 0.7814 - val_log_cosh: 0.0621 - val_loss: 0.0217 - val_within_eps_0_005: 0.0179 - val_within_eps_0_01: 0.0356 - val_within_eps_0_02: 0.0703 - val_within_eps_0_05: 0.1667 - val_within_eps_0_1: 0.3034\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0032 - loss: 0.0028 - within_eps_0_005: 0.0525 - within_eps_0_01: 0.1089 - within_eps_0_02: 0.2191 - within_eps_0_05: 0.5032 - within_eps_0_1: 0.8110 - val_log_cosh: 0.0614 - val_loss: 0.0216 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0360 - val_within_eps_0_02: 0.0706 - val_within_eps_0_05: 0.1656 - val_within_eps_0_1: 0.2997\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0029 - loss: 0.0026 - within_eps_0_005: 0.0582 - within_eps_0_01: 0.1151 - within_eps_0_02: 0.2290 - within_eps_0_05: 0.5242 - within_eps_0_1: 0.8274 - val_log_cosh: 0.0611 - val_loss: 0.0216 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0686 - val_within_eps_0_05: 0.1700 - val_within_eps_0_1: 0.3041\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0027 - loss: 0.0024 - within_eps_0_005: 0.0598 - within_eps_0_01: 0.1215 - within_eps_0_02: 0.2380 - within_eps_0_05: 0.5481 - within_eps_0_1: 0.8421 - val_log_cosh: 0.0602 - val_loss: 0.0212 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0353 - val_within_eps_0_02: 0.0713 - val_within_eps_0_05: 0.1678 - val_within_eps_0_1: 0.3142\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0025 - loss: 0.0023 - within_eps_0_005: 0.0643 - within_eps_0_01: 0.1274 - within_eps_0_02: 0.2516 - within_eps_0_05: 0.5635 - within_eps_0_1: 0.8558 - val_log_cosh: 0.0642 - val_loss: 0.0224 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0255 - val_within_eps_0_02: 0.0535 - val_within_eps_0_05: 0.1454 - val_within_eps_0_1: 0.2866\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0023 - loss: 0.0021 - within_eps_0_005: 0.0635 - within_eps_0_01: 0.1302 - within_eps_0_02: 0.2540 - within_eps_0_05: 0.5778 - within_eps_0_1: 0.8690 - val_log_cosh: 0.0615 - val_loss: 0.0216 - val_within_eps_0_005: 0.0177 - val_within_eps_0_01: 0.0356 - val_within_eps_0_02: 0.0712 - val_within_eps_0_05: 0.1625 - val_within_eps_0_1: 0.2963\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0021 - loss: 0.0020 - within_eps_0_005: 0.0694 - within_eps_0_01: 0.1386 - within_eps_0_02: 0.2717 - within_eps_0_05: 0.5995 - within_eps_0_1: 0.8825 - val_log_cosh: 0.0600 - val_loss: 0.0211 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0636 - val_within_eps_0_05: 0.1644 - val_within_eps_0_1: 0.3055\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0021 - loss: 0.0019 - within_eps_0_005: 0.0722 - within_eps_0_01: 0.1404 - within_eps_0_02: 0.2766 - within_eps_0_05: 0.6079 - within_eps_0_1: 0.8857 - val_log_cosh: 0.0631 - val_loss: 0.0219 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0608 - val_within_eps_0_05: 0.1573 - val_within_eps_0_1: 0.3024\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0021 - loss: 0.0019 - within_eps_0_005: 0.0728 - within_eps_0_01: 0.1436 - within_eps_0_02: 0.2767 - within_eps_0_05: 0.6136 - within_eps_0_1: 0.8885 - val_log_cosh: 0.0607 - val_loss: 0.0213 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0273 - val_within_eps_0_02: 0.0561 - val_within_eps_0_05: 0.1524 - val_within_eps_0_1: 0.3122\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0019 - loss: 0.0018 - within_eps_0_005: 0.0729 - within_eps_0_01: 0.1458 - within_eps_0_02: 0.2862 - within_eps_0_05: 0.6245 - within_eps_0_1: 0.9005 - val_log_cosh: 0.0602 - val_loss: 0.0212 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0641 - val_within_eps_0_05: 0.1619 - val_within_eps_0_1: 0.3103\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0753 - within_eps_0_01: 0.1495 - within_eps_0_02: 0.2922 - within_eps_0_05: 0.6361 - within_eps_0_1: 0.9045 - val_log_cosh: 0.0674 - val_loss: 0.0229 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0630 - val_within_eps_0_05: 0.1523 - val_within_eps_0_1: 0.2860\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0017 - loss: 0.0016 - within_eps_0_005: 0.0784 - within_eps_0_01: 0.1546 - within_eps_0_02: 0.3040 - within_eps_0_05: 0.6525 - within_eps_0_1: 0.9139 - val_log_cosh: 0.0651 - val_loss: 0.0224 - val_within_eps_0_005: 0.0159 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0594 - val_within_eps_0_05: 0.1450 - val_within_eps_0_1: 0.2878\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0017 - loss: 0.0016 - within_eps_0_005: 0.0805 - within_eps_0_01: 0.1586 - within_eps_0_02: 0.3064 - within_eps_0_05: 0.6551 - within_eps_0_1: 0.9134 - val_log_cosh: 0.0598 - val_loss: 0.0207 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0662 - val_within_eps_0_05: 0.1674 - val_within_eps_0_1: 0.3346\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0016 - loss: 0.0015 - within_eps_0_005: 0.0821 - within_eps_0_01: 0.1644 - within_eps_0_02: 0.3183 - within_eps_0_05: 0.6720 - within_eps_0_1: 0.9243 - val_log_cosh: 0.0627 - val_loss: 0.0218 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1477 - val_within_eps_0_1: 0.2986\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0015 - loss: 0.0014 - within_eps_0_005: 0.0841 - within_eps_0_01: 0.1691 - within_eps_0_02: 0.3276 - within_eps_0_05: 0.6816 - within_eps_0_1: 0.9281 - val_log_cosh: 0.0642 - val_loss: 0.0219 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0638 - val_within_eps_0_05: 0.1589 - val_within_eps_0_1: 0.3016\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0015 - loss: 0.0015 - within_eps_0_005: 0.0833 - within_eps_0_01: 0.1660 - within_eps_0_02: 0.3207 - within_eps_0_05: 0.6777 - within_eps_0_1: 0.9281 - val_log_cosh: 0.0567 - val_loss: 0.0199 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0365 - val_within_eps_0_02: 0.0708 - val_within_eps_0_05: 0.1783 - val_within_eps_0_1: 0.3449\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0015 - loss: 0.0014 - within_eps_0_005: 0.0834 - within_eps_0_01: 0.1695 - within_eps_0_02: 0.3319 - within_eps_0_05: 0.6910 - within_eps_0_1: 0.9310 - val_log_cosh: 0.0612 - val_loss: 0.0211 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1576 - val_within_eps_0_1: 0.3203\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0014 - loss: 0.0013 - within_eps_0_005: 0.0882 - within_eps_0_01: 0.1724 - within_eps_0_02: 0.3374 - within_eps_0_05: 0.6981 - within_eps_0_1: 0.9382 - val_log_cosh: 0.0552 - val_loss: 0.0195 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0330 - val_within_eps_0_02: 0.0672 - val_within_eps_0_05: 0.1730 - val_within_eps_0_1: 0.3418\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0014 - loss: 0.0014 - within_eps_0_005: 0.0851 - within_eps_0_01: 0.1719 - within_eps_0_02: 0.3330 - within_eps_0_05: 0.6931 - within_eps_0_1: 0.9348 - val_log_cosh: 0.0601 - val_loss: 0.0207 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0352 - val_within_eps_0_02: 0.0692 - val_within_eps_0_05: 0.1717 - val_within_eps_0_1: 0.3363\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0014 - loss: 0.0013 - within_eps_0_005: 0.0881 - within_eps_0_01: 0.1766 - within_eps_0_02: 0.3426 - within_eps_0_05: 0.7094 - within_eps_0_1: 0.9400 - val_log_cosh: 0.0644 - val_loss: 0.0219 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0333 - val_within_eps_0_02: 0.0651 - val_within_eps_0_05: 0.1571 - val_within_eps_0_1: 0.3044\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0013 - loss: 0.0013 - within_eps_0_005: 0.0891 - within_eps_0_01: 0.1780 - within_eps_0_02: 0.3442 - within_eps_0_05: 0.7112 - within_eps_0_1: 0.9422 - val_log_cosh: 0.0634 - val_loss: 0.0215 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0336 - val_within_eps_0_02: 0.0675 - val_within_eps_0_05: 0.1705 - val_within_eps_0_1: 0.3209\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0013 - loss: 0.0012 - within_eps_0_005: 0.0929 - within_eps_0_01: 0.1829 - within_eps_0_02: 0.3537 - within_eps_0_05: 0.7194 - within_eps_0_1: 0.9435 - val_log_cosh: 0.0614 - val_loss: 0.0209 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0661 - val_within_eps_0_05: 0.1679 - val_within_eps_0_1: 0.3339\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0013 - loss: 0.0012 - within_eps_0_005: 0.0928 - within_eps_0_01: 0.1860 - within_eps_0_02: 0.3554 - within_eps_0_05: 0.7250 - within_eps_0_1: 0.9485 - val_log_cosh: 0.0671 - val_loss: 0.0224 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0354 - val_within_eps_0_02: 0.0704 - val_within_eps_0_05: 0.1588 - val_within_eps_0_1: 0.3027\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0012 - loss: 0.0012 - within_eps_0_005: 0.0971 - within_eps_0_01: 0.1905 - within_eps_0_02: 0.3624 - within_eps_0_05: 0.7306 - within_eps_0_1: 0.9491 - val_log_cosh: 0.0600 - val_loss: 0.0204 - val_within_eps_0_005: 0.0191 - val_within_eps_0_01: 0.0380 - val_within_eps_0_02: 0.0745 - val_within_eps_0_05: 0.1854 - val_within_eps_0_1: 0.3510\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0012 - loss: 0.0011 - within_eps_0_005: 0.0939 - within_eps_0_01: 0.1889 - within_eps_0_02: 0.3656 - within_eps_0_05: 0.7388 - within_eps_0_1: 0.9525 - val_log_cosh: 0.0651 - val_loss: 0.0217 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0361 - val_within_eps_0_02: 0.0738 - val_within_eps_0_05: 0.1774 - val_within_eps_0_1: 0.3222\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0012 - loss: 0.0011 - within_eps_0_005: 0.0978 - within_eps_0_01: 0.1903 - within_eps_0_02: 0.3709 - within_eps_0_05: 0.7406 - within_eps_0_1: 0.9516 - val_log_cosh: 0.0612 - val_loss: 0.0206 - val_within_eps_0_005: 0.0191 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0760 - val_within_eps_0_05: 0.1912 - val_within_eps_0_1: 0.3483\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0012 - loss: 0.0012 - within_eps_0_005: 0.0949 - within_eps_0_01: 0.1886 - within_eps_0_02: 0.3604 - within_eps_0_05: 0.7298 - within_eps_0_1: 0.9505 - val_log_cosh: 0.0663 - val_loss: 0.0220 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0368 - val_within_eps_0_02: 0.0761 - val_within_eps_0_05: 0.1726 - val_within_eps_0_1: 0.3198\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0011 - loss: 0.0010 - within_eps_0_005: 0.1019 - within_eps_0_01: 0.1984 - within_eps_0_02: 0.3840 - within_eps_0_05: 0.7588 - within_eps_0_1: 0.9602 - val_log_cosh: 0.0646 - val_loss: 0.0215 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0363 - val_within_eps_0_02: 0.0718 - val_within_eps_0_05: 0.1773 - val_within_eps_0_1: 0.3294\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0012 - loss: 0.0011 - within_eps_0_005: 0.0968 - within_eps_0_01: 0.1931 - within_eps_0_02: 0.3743 - within_eps_0_05: 0.7480 - within_eps_0_1: 0.9529 - val_log_cosh: 0.0711 - val_loss: 0.0235 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0304 - val_within_eps_0_02: 0.0581 - val_within_eps_0_05: 0.1468 - val_within_eps_0_1: 0.2865\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0011 - loss: 0.0011 - within_eps_0_005: 0.1010 - within_eps_0_01: 0.1972 - within_eps_0_02: 0.3789 - within_eps_0_05: 0.7528 - within_eps_0_1: 0.9586 - val_log_cosh: 0.0634 - val_loss: 0.0212 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0392 - val_within_eps_0_02: 0.0752 - val_within_eps_0_05: 0.1832 - val_within_eps_0_1: 0.3386\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0011 - loss: 0.0010 - within_eps_0_005: 0.1041 - within_eps_0_01: 0.2050 - within_eps_0_02: 0.3896 - within_eps_0_05: 0.7622 - within_eps_0_1: 0.9622 - val_log_cosh: 0.0699 - val_loss: 0.0232 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0597 - val_within_eps_0_05: 0.1498 - val_within_eps_0_1: 0.2908\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0011 - loss: 0.0011 - within_eps_0_005: 0.1016 - within_eps_0_01: 0.1998 - within_eps_0_02: 0.3792 - within_eps_0_05: 0.7515 - within_eps_0_1: 0.9588 - val_log_cosh: 0.0708 - val_loss: 0.0231 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0342 - val_within_eps_0_02: 0.0665 - val_within_eps_0_05: 0.1593 - val_within_eps_0_1: 0.3043\n",
      "Epoch 41/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0010 - loss: 0.0010 - within_eps_0_005: 0.1055 - within_eps_0_01: 0.2058 - within_eps_0_02: 0.3938 - within_eps_0_05: 0.7673 - within_eps_0_1: 0.9640 - val_log_cosh: 0.0669 - val_loss: 0.0222 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0327 - val_within_eps_0_02: 0.0691 - val_within_eps_0_05: 0.1695 - val_within_eps_0_1: 0.3211\n",
      "  -> val_loss(min) δ=0.1: 0.019511036575\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - log_cosh: 0.3301 - loss: 0.1537 - within_eps_0_005: 0.0049 - within_eps_0_01: 0.0094 - within_eps_0_02: 0.0182 - within_eps_0_05: 0.0453 - within_eps_0_1: 0.0911 - val_log_cosh: 0.1001 - val_loss: 0.0625 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0231 - val_within_eps_0_02: 0.0472 - val_within_eps_0_05: 0.1139 - val_within_eps_0_1: 0.2110\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.1654 - loss: 0.0952 - within_eps_0_005: 0.0069 - within_eps_0_01: 0.0134 - within_eps_0_02: 0.0272 - within_eps_0_05: 0.0662 - within_eps_0_1: 0.1323 - val_log_cosh: 0.0772 - val_loss: 0.0490 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1462 - val_within_eps_0_1: 0.2601\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0794 - loss: 0.0554 - within_eps_0_005: 0.0102 - within_eps_0_01: 0.0203 - within_eps_0_02: 0.0398 - within_eps_0_05: 0.1001 - within_eps_0_1: 0.1992 - val_log_cosh: 0.0790 - val_loss: 0.0504 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0241 - val_within_eps_0_02: 0.0483 - val_within_eps_0_05: 0.1199 - val_within_eps_0_1: 0.2234\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0201 - loss: 0.0184 - within_eps_0_005: 0.0214 - within_eps_0_01: 0.0420 - within_eps_0_02: 0.0839 - within_eps_0_05: 0.2072 - within_eps_0_1: 0.3946 - val_log_cosh: 0.0738 - val_loss: 0.0463 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0633 - val_within_eps_0_05: 0.1477 - val_within_eps_0_1: 0.2852\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0085 - loss: 0.0084 - within_eps_0_005: 0.0315 - within_eps_0_01: 0.0626 - within_eps_0_02: 0.1267 - within_eps_0_05: 0.3098 - within_eps_0_1: 0.5688 - val_log_cosh: 0.0647 - val_loss: 0.0409 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0384 - val_within_eps_0_02: 0.0776 - val_within_eps_0_05: 0.1842 - val_within_eps_0_1: 0.3376\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0062 - loss: 0.0062 - within_eps_0_005: 0.0389 - within_eps_0_01: 0.0767 - within_eps_0_02: 0.1501 - within_eps_0_05: 0.3622 - within_eps_0_1: 0.6489 - val_log_cosh: 0.0664 - val_loss: 0.0421 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1671 - val_within_eps_0_1: 0.3283\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0051 - loss: 0.0051 - within_eps_0_005: 0.0425 - within_eps_0_01: 0.0831 - within_eps_0_02: 0.1671 - within_eps_0_05: 0.3998 - within_eps_0_1: 0.6965 - val_log_cosh: 0.0778 - val_loss: 0.0484 - val_within_eps_0_005: 0.0195 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0732 - val_within_eps_0_05: 0.1633 - val_within_eps_0_1: 0.3049\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0046 - loss: 0.0045 - within_eps_0_005: 0.0445 - within_eps_0_01: 0.0882 - within_eps_0_02: 0.1764 - within_eps_0_05: 0.4185 - within_eps_0_1: 0.7253 - val_log_cosh: 0.0682 - val_loss: 0.0432 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0344 - val_within_eps_0_02: 0.0732 - val_within_eps_0_05: 0.1791 - val_within_eps_0_1: 0.3403\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0040 - loss: 0.0040 - within_eps_0_005: 0.0466 - within_eps_0_01: 0.0954 - within_eps_0_02: 0.1867 - within_eps_0_05: 0.4435 - within_eps_0_1: 0.7538 - val_log_cosh: 0.0662 - val_loss: 0.0423 - val_within_eps_0_005: 0.0159 - val_within_eps_0_01: 0.0335 - val_within_eps_0_02: 0.0700 - val_within_eps_0_05: 0.1837 - val_within_eps_0_1: 0.3401\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0035 - loss: 0.0035 - within_eps_0_005: 0.0512 - within_eps_0_01: 0.1014 - within_eps_0_02: 0.1992 - within_eps_0_05: 0.4732 - within_eps_0_1: 0.7825 - val_log_cosh: 0.0675 - val_loss: 0.0434 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0349 - val_within_eps_0_02: 0.0701 - val_within_eps_0_05: 0.1737 - val_within_eps_0_1: 0.3355\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0032 - loss: 0.0032 - within_eps_0_005: 0.0548 - within_eps_0_01: 0.1063 - within_eps_0_02: 0.2108 - within_eps_0_05: 0.4948 - within_eps_0_1: 0.8032 - val_log_cosh: 0.0742 - val_loss: 0.0474 - val_within_eps_0_005: 0.0172 - val_within_eps_0_01: 0.0340 - val_within_eps_0_02: 0.0682 - val_within_eps_0_05: 0.1659 - val_within_eps_0_1: 0.3025\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0030 - loss: 0.0030 - within_eps_0_005: 0.0566 - within_eps_0_01: 0.1131 - within_eps_0_02: 0.2210 - within_eps_0_05: 0.5122 - within_eps_0_1: 0.8190 - val_log_cosh: 0.0765 - val_loss: 0.0486 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0314 - val_within_eps_0_02: 0.0633 - val_within_eps_0_05: 0.1597 - val_within_eps_0_1: 0.3017\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0027 - loss: 0.0027 - within_eps_0_005: 0.0600 - within_eps_0_01: 0.1178 - within_eps_0_02: 0.2303 - within_eps_0_05: 0.5290 - within_eps_0_1: 0.8377 - val_log_cosh: 0.0724 - val_loss: 0.0467 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0661 - val_within_eps_0_05: 0.1695 - val_within_eps_0_1: 0.2941\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0026 - loss: 0.0026 - within_eps_0_005: 0.0608 - within_eps_0_01: 0.1228 - within_eps_0_02: 0.2413 - within_eps_0_05: 0.5503 - within_eps_0_1: 0.8517 - val_log_cosh: 0.0705 - val_loss: 0.0456 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0776 - val_within_eps_0_05: 0.1769 - val_within_eps_0_1: 0.3068\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0024 - loss: 0.0024 - within_eps_0_005: 0.0641 - within_eps_0_01: 0.1279 - within_eps_0_02: 0.2484 - within_eps_0_05: 0.5633 - within_eps_0_1: 0.8617 - val_log_cosh: 0.0673 - val_loss: 0.0436 - val_within_eps_0_005: 0.0211 - val_within_eps_0_01: 0.0420 - val_within_eps_0_02: 0.0838 - val_within_eps_0_05: 0.1915 - val_within_eps_0_1: 0.3283\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0647 - within_eps_0_01: 0.1302 - within_eps_0_02: 0.2593 - within_eps_0_05: 0.5851 - within_eps_0_1: 0.8769 - val_log_cosh: 0.0659 - val_loss: 0.0429 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0768 - val_within_eps_0_05: 0.1851 - val_within_eps_0_1: 0.3240\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0684 - within_eps_0_01: 0.1358 - within_eps_0_02: 0.2678 - within_eps_0_05: 0.5944 - within_eps_0_1: 0.8808 - val_log_cosh: 0.0654 - val_loss: 0.0427 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0814 - val_within_eps_0_05: 0.1888 - val_within_eps_0_1: 0.3261\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0020 - loss: 0.0020 - within_eps_0_005: 0.0699 - within_eps_0_01: 0.1377 - within_eps_0_02: 0.2731 - within_eps_0_05: 0.6122 - within_eps_0_1: 0.8941 - val_log_cosh: 0.0659 - val_loss: 0.0429 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0760 - val_within_eps_0_05: 0.1871 - val_within_eps_0_1: 0.3172\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0019 - loss: 0.0019 - within_eps_0_005: 0.0711 - within_eps_0_01: 0.1406 - within_eps_0_02: 0.2774 - within_eps_0_05: 0.6197 - within_eps_0_1: 0.9000 - val_log_cosh: 0.0681 - val_loss: 0.0443 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0654 - val_within_eps_0_05: 0.1649 - val_within_eps_0_1: 0.3172\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0019 - loss: 0.0019 - within_eps_0_005: 0.0733 - within_eps_0_01: 0.1502 - within_eps_0_02: 0.2910 - within_eps_0_05: 0.6321 - within_eps_0_1: 0.9017 - val_log_cosh: 0.0695 - val_loss: 0.0451 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0780 - val_within_eps_0_05: 0.1764 - val_within_eps_0_1: 0.3066\n",
      "  -> val_loss(min) δ=0.25: 0.040919363499\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - log_cosh: 0.3628 - loss: 0.2781 - within_eps_0_005: 0.0046 - within_eps_0_01: 0.0090 - within_eps_0_02: 0.0172 - within_eps_0_05: 0.0449 - within_eps_0_1: 0.0894 - val_log_cosh: 0.0995 - val_loss: 0.0875 - val_within_eps_0_005: 0.0099 - val_within_eps_0_01: 0.0202 - val_within_eps_0_02: 0.0399 - val_within_eps_0_05: 0.1054 - val_within_eps_0_1: 0.2036\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.1569 - loss: 0.1406 - within_eps_0_005: 0.0071 - within_eps_0_01: 0.0141 - within_eps_0_02: 0.0274 - within_eps_0_05: 0.0678 - within_eps_0_1: 0.1332 - val_log_cosh: 0.0900 - val_loss: 0.0791 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0563 - val_within_eps_0_05: 0.1304 - val_within_eps_0_1: 0.2517\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0660 - loss: 0.0649 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0221 - within_eps_0_02: 0.0441 - within_eps_0_05: 0.1089 - within_eps_0_1: 0.2169 - val_log_cosh: 0.0662 - val_loss: 0.0584 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0285 - val_within_eps_0_02: 0.0579 - val_within_eps_0_05: 0.1509 - val_within_eps_0_1: 0.2994\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0232 - loss: 0.0236 - within_eps_0_005: 0.0188 - within_eps_0_01: 0.0375 - within_eps_0_02: 0.0750 - within_eps_0_05: 0.1867 - within_eps_0_1: 0.3635 - val_log_cosh: 0.0591 - val_loss: 0.0524 - val_within_eps_0_005: 0.0166 - val_within_eps_0_01: 0.0322 - val_within_eps_0_02: 0.0652 - val_within_eps_0_05: 0.1677 - val_within_eps_0_1: 0.3306\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0114 - loss: 0.0115 - within_eps_0_005: 0.0283 - within_eps_0_01: 0.0567 - within_eps_0_02: 0.1103 - within_eps_0_05: 0.2702 - within_eps_0_1: 0.5064 - val_log_cosh: 0.0572 - val_loss: 0.0511 - val_within_eps_0_005: 0.0187 - val_within_eps_0_01: 0.0375 - val_within_eps_0_02: 0.0751 - val_within_eps_0_05: 0.1827 - val_within_eps_0_1: 0.3406\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0080 - loss: 0.0081 - within_eps_0_005: 0.0335 - within_eps_0_01: 0.0667 - within_eps_0_02: 0.1321 - within_eps_0_05: 0.3189 - within_eps_0_1: 0.5867 - val_log_cosh: 0.0529 - val_loss: 0.0476 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0459 - val_within_eps_0_02: 0.0904 - val_within_eps_0_05: 0.2109 - val_within_eps_0_1: 0.3759\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0066 - loss: 0.0066 - within_eps_0_005: 0.0370 - within_eps_0_01: 0.0739 - within_eps_0_02: 0.1470 - within_eps_0_05: 0.3519 - within_eps_0_1: 0.6302 - val_log_cosh: 0.0564 - val_loss: 0.0513 - val_within_eps_0_005: 0.0196 - val_within_eps_0_01: 0.0379 - val_within_eps_0_02: 0.0770 - val_within_eps_0_05: 0.1882 - val_within_eps_0_1: 0.3447\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0058 - loss: 0.0059 - within_eps_0_005: 0.0396 - within_eps_0_01: 0.0796 - within_eps_0_02: 0.1550 - within_eps_0_05: 0.3698 - within_eps_0_1: 0.6619 - val_log_cosh: 0.0522 - val_loss: 0.0474 - val_within_eps_0_005: 0.0247 - val_within_eps_0_01: 0.0463 - val_within_eps_0_02: 0.0936 - val_within_eps_0_05: 0.2122 - val_within_eps_0_1: 0.3818\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0051 - loss: 0.0051 - within_eps_0_005: 0.0427 - within_eps_0_01: 0.0851 - within_eps_0_02: 0.1678 - within_eps_0_05: 0.4001 - within_eps_0_1: 0.6936 - val_log_cosh: 0.0547 - val_loss: 0.0498 - val_within_eps_0_005: 0.0206 - val_within_eps_0_01: 0.0405 - val_within_eps_0_02: 0.0820 - val_within_eps_0_05: 0.1870 - val_within_eps_0_1: 0.3522\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0046 - loss: 0.0046 - within_eps_0_005: 0.0440 - within_eps_0_01: 0.0886 - within_eps_0_02: 0.1767 - within_eps_0_05: 0.4223 - within_eps_0_1: 0.7215 - val_log_cosh: 0.0513 - val_loss: 0.0471 - val_within_eps_0_005: 0.0208 - val_within_eps_0_01: 0.0426 - val_within_eps_0_02: 0.0836 - val_within_eps_0_05: 0.2077 - val_within_eps_0_1: 0.3645\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0042 - loss: 0.0042 - within_eps_0_005: 0.0473 - within_eps_0_01: 0.0930 - within_eps_0_02: 0.1864 - within_eps_0_05: 0.4408 - within_eps_0_1: 0.7455 - val_log_cosh: 0.0562 - val_loss: 0.0515 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0437 - val_within_eps_0_02: 0.0843 - val_within_eps_0_05: 0.1950 - val_within_eps_0_1: 0.3533\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0038 - loss: 0.0038 - within_eps_0_005: 0.0501 - within_eps_0_01: 0.0967 - within_eps_0_02: 0.1964 - within_eps_0_05: 0.4602 - within_eps_0_1: 0.7687 - val_log_cosh: 0.0564 - val_loss: 0.0520 - val_within_eps_0_005: 0.0215 - val_within_eps_0_01: 0.0407 - val_within_eps_0_02: 0.0797 - val_within_eps_0_05: 0.1873 - val_within_eps_0_1: 0.3401\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0035 - loss: 0.0035 - within_eps_0_005: 0.0498 - within_eps_0_01: 0.1017 - within_eps_0_02: 0.2022 - within_eps_0_05: 0.4765 - within_eps_0_1: 0.7837 - val_log_cosh: 0.0536 - val_loss: 0.0495 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0376 - val_within_eps_0_02: 0.0750 - val_within_eps_0_05: 0.1885 - val_within_eps_0_1: 0.3523\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0033 - loss: 0.0033 - within_eps_0_005: 0.0526 - within_eps_0_01: 0.1051 - within_eps_0_02: 0.2121 - within_eps_0_05: 0.4889 - within_eps_0_1: 0.7998 - val_log_cosh: 0.0584 - val_loss: 0.0539 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0349 - val_within_eps_0_02: 0.0706 - val_within_eps_0_05: 0.1769 - val_within_eps_0_1: 0.3336\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0031 - loss: 0.0031 - within_eps_0_005: 0.0528 - within_eps_0_01: 0.1069 - within_eps_0_02: 0.2150 - within_eps_0_05: 0.5065 - within_eps_0_1: 0.8091 - val_log_cosh: 0.0603 - val_loss: 0.0555 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0363 - val_within_eps_0_02: 0.0689 - val_within_eps_0_05: 0.1653 - val_within_eps_0_1: 0.3087\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0030 - loss: 0.0030 - within_eps_0_005: 0.0578 - within_eps_0_01: 0.1129 - within_eps_0_02: 0.2227 - within_eps_0_05: 0.5121 - within_eps_0_1: 0.8152 - val_log_cosh: 0.0562 - val_loss: 0.0516 - val_within_eps_0_005: 0.0208 - val_within_eps_0_01: 0.0417 - val_within_eps_0_02: 0.0789 - val_within_eps_0_05: 0.1913 - val_within_eps_0_1: 0.3446\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0027 - loss: 0.0027 - within_eps_0_005: 0.0593 - within_eps_0_01: 0.1180 - within_eps_0_02: 0.2326 - within_eps_0_05: 0.5386 - within_eps_0_1: 0.8374 - val_log_cosh: 0.0586 - val_loss: 0.0540 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0347 - val_within_eps_0_02: 0.0695 - val_within_eps_0_05: 0.1793 - val_within_eps_0_1: 0.3287\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0025 - loss: 0.0026 - within_eps_0_005: 0.0626 - within_eps_0_01: 0.1220 - within_eps_0_02: 0.2389 - within_eps_0_05: 0.5495 - within_eps_0_1: 0.8506 - val_log_cosh: 0.0530 - val_loss: 0.0489 - val_within_eps_0_005: 0.0208 - val_within_eps_0_01: 0.0407 - val_within_eps_0_02: 0.0791 - val_within_eps_0_05: 0.1982 - val_within_eps_0_1: 0.3534\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0025 - loss: 0.0025 - within_eps_0_005: 0.0627 - within_eps_0_01: 0.1245 - within_eps_0_02: 0.2456 - within_eps_0_05: 0.5568 - within_eps_0_1: 0.8562 - val_log_cosh: 0.0587 - val_loss: 0.0541 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0364 - val_within_eps_0_02: 0.0704 - val_within_eps_0_05: 0.1706 - val_within_eps_0_1: 0.3215\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0024 - loss: 0.0024 - within_eps_0_005: 0.0652 - within_eps_0_01: 0.1310 - within_eps_0_02: 0.2559 - within_eps_0_05: 0.5737 - within_eps_0_1: 0.8668 - val_log_cosh: 0.0550 - val_loss: 0.0506 - val_within_eps_0_005: 0.0191 - val_within_eps_0_01: 0.0367 - val_within_eps_0_02: 0.0734 - val_within_eps_0_05: 0.1859 - val_within_eps_0_1: 0.3345\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0671 - within_eps_0_01: 0.1337 - within_eps_0_02: 0.2604 - within_eps_0_05: 0.5858 - within_eps_0_1: 0.8722 - val_log_cosh: 0.0535 - val_loss: 0.0493 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0374 - val_within_eps_0_02: 0.0750 - val_within_eps_0_05: 0.1917 - val_within_eps_0_1: 0.3519\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0023 - loss: 0.0023 - within_eps_0_005: 0.0659 - within_eps_0_01: 0.1293 - within_eps_0_02: 0.2538 - within_eps_0_05: 0.5766 - within_eps_0_1: 0.8695 - val_log_cosh: 0.0597 - val_loss: 0.0548 - val_within_eps_0_005: 0.0213 - val_within_eps_0_01: 0.0392 - val_within_eps_0_02: 0.0777 - val_within_eps_0_05: 0.1767 - val_within_eps_0_1: 0.3384\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0021 - loss: 0.0021 - within_eps_0_005: 0.0709 - within_eps_0_01: 0.1380 - within_eps_0_02: 0.2688 - within_eps_0_05: 0.6018 - within_eps_0_1: 0.8857 - val_log_cosh: 0.0572 - val_loss: 0.0527 - val_within_eps_0_005: 0.0198 - val_within_eps_0_01: 0.0388 - val_within_eps_0_02: 0.0757 - val_within_eps_0_05: 0.1853 - val_within_eps_0_1: 0.3480\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0021 - loss: 0.0021 - within_eps_0_005: 0.0683 - within_eps_0_01: 0.1353 - within_eps_0_02: 0.2655 - within_eps_0_05: 0.5955 - within_eps_0_1: 0.8822 - val_log_cosh: 0.0613 - val_loss: 0.0563 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0343 - val_within_eps_0_02: 0.0739 - val_within_eps_0_05: 0.1810 - val_within_eps_0_1: 0.3281\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0020 - loss: 0.0020 - within_eps_0_005: 0.0709 - within_eps_0_01: 0.1415 - within_eps_0_02: 0.2777 - within_eps_0_05: 0.6155 - within_eps_0_1: 0.8936 - val_log_cosh: 0.0576 - val_loss: 0.0530 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0371 - val_within_eps_0_02: 0.0737 - val_within_eps_0_05: 0.1755 - val_within_eps_0_1: 0.3368\n",
      "  -> val_loss(min) δ=0.5: 0.047081563622\n",
      "\n",
      "Tabla val_loss(min) por δ (orden asc):\n",
      "  δ=0.01: 0.002322742948\n",
      "  δ=0.02: 0.004598179832\n",
      "  δ=0.05: 0.010008188896\n",
      "  δ= 0.1: 0.019511036575\n",
      "  δ=0.25: 0.040919363499\n",
      "  δ= 0.5: 0.047081563622\n",
      "\n",
      ">>> Mejor δ por tu regla: 0.01 (val_loss=0.002322742948)\n",
      "\n",
      "Resultados TEST - Escenario S (CNN)\n",
      "  loss (Huber):              0.015785\n",
      "  log_cosh:                  1.310483\n",
      "  within_eps_0_005          : 0.008248\n",
      "  within_eps_0_01           : 0.018568\n",
      "  within_eps_0_02           : 0.037288\n",
      "  within_eps_0_05           : 0.095644\n",
      "  within_eps_0_1            : 0.181793\n",
      "  AUTC[0.005–0.100]:         0.097644\n",
      "\n",
      "=== Barrido Huber delta _M ===\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - log_cosh: 0.3071 - loss: 0.0069 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0093 - within_eps_0_02: 0.0188 - within_eps_0_05: 0.0466 - within_eps_0_1: 0.0942 - val_log_cosh: 0.1036 - val_loss: 0.0034 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0235 - val_within_eps_0_02: 0.0475 - val_within_eps_0_05: 0.1193 - val_within_eps_0_1: 0.2220\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.1578 - loss: 0.0047 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0140 - within_eps_0_02: 0.0276 - within_eps_0_05: 0.0678 - within_eps_0_1: 0.1339 - val_log_cosh: 0.0760 - val_loss: 0.0028 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1418 - val_within_eps_0_1: 0.2818\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0650 - loss: 0.0029 - within_eps_0_005: 0.0109 - within_eps_0_01: 0.0220 - within_eps_0_02: 0.0444 - within_eps_0_05: 0.1111 - within_eps_0_1: 0.2198 - val_log_cosh: 0.0889 - val_loss: 0.0031 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0257 - val_within_eps_0_02: 0.0512 - val_within_eps_0_05: 0.1275 - val_within_eps_0_1: 0.2538\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0212 - loss: 0.0016 - within_eps_0_005: 0.0204 - within_eps_0_01: 0.0406 - within_eps_0_02: 0.0816 - within_eps_0_05: 0.1996 - within_eps_0_1: 0.3860 - val_log_cosh: 0.0830 - val_loss: 0.0030 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0622 - val_within_eps_0_05: 0.1464 - val_within_eps_0_1: 0.2738\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0073 - loss: 8.9802e-04 - within_eps_0_005: 0.0349 - within_eps_0_01: 0.0699 - within_eps_0_02: 0.1394 - within_eps_0_05: 0.3394 - within_eps_0_1: 0.6134 - val_log_cosh: 0.0783 - val_loss: 0.0029 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1406 - val_within_eps_0_1: 0.2757\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0044 - loss: 6.8032e-04 - within_eps_0_005: 0.0462 - within_eps_0_01: 0.0921 - within_eps_0_02: 0.1824 - within_eps_0_05: 0.4334 - within_eps_0_1: 0.7359 - val_log_cosh: 0.0796 - val_loss: 0.0031 - val_within_eps_0_005: 0.0097 - val_within_eps_0_01: 0.0196 - val_within_eps_0_02: 0.0402 - val_within_eps_0_05: 0.1053 - val_within_eps_0_1: 0.2246\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0037 - loss: 6.1453e-04 - within_eps_0_005: 0.0508 - within_eps_0_01: 0.1015 - within_eps_0_02: 0.2014 - within_eps_0_05: 0.4751 - within_eps_0_1: 0.7788 - val_log_cosh: 0.0731 - val_loss: 0.0030 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0255 - val_within_eps_0_02: 0.0512 - val_within_eps_0_05: 0.1301 - val_within_eps_0_1: 0.2500\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0031 - loss: 5.5704e-04 - within_eps_0_005: 0.0561 - within_eps_0_01: 0.1115 - within_eps_0_02: 0.2215 - within_eps_0_05: 0.5134 - within_eps_0_1: 0.8172 - val_log_cosh: 0.0763 - val_loss: 0.0030 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0239 - val_within_eps_0_02: 0.0484 - val_within_eps_0_05: 0.1239 - val_within_eps_0_1: 0.2370\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0028 - loss: 5.2110e-04 - within_eps_0_005: 0.0608 - within_eps_0_01: 0.1206 - within_eps_0_02: 0.2379 - within_eps_0_05: 0.5434 - within_eps_0_1: 0.8402 - val_log_cosh: 0.0834 - val_loss: 0.0032 - val_within_eps_0_005: 0.0096 - val_within_eps_0_01: 0.0194 - val_within_eps_0_02: 0.0385 - val_within_eps_0_05: 0.1003 - val_within_eps_0_1: 0.2003\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0025 - loss: 4.9155e-04 - within_eps_0_005: 0.0648 - within_eps_0_01: 0.1287 - within_eps_0_02: 0.2519 - within_eps_0_05: 0.5679 - within_eps_0_1: 0.8592 - val_log_cosh: 0.0724 - val_loss: 0.0029 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0582 - val_within_eps_0_05: 0.1425 - val_within_eps_0_1: 0.2579\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0023 - loss: 4.6917e-04 - within_eps_0_005: 0.0672 - within_eps_0_01: 0.1337 - within_eps_0_02: 0.2636 - within_eps_0_05: 0.5897 - within_eps_0_1: 0.8717 - val_log_cosh: 0.0744 - val_loss: 0.0030 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0257 - val_within_eps_0_02: 0.0514 - val_within_eps_0_05: 0.1297 - val_within_eps_0_1: 0.2464\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0021 - loss: 4.4265e-04 - within_eps_0_005: 0.0720 - within_eps_0_01: 0.1436 - within_eps_0_02: 0.2810 - within_eps_0_05: 0.6134 - within_eps_0_1: 0.8865 - val_log_cosh: 0.0750 - val_loss: 0.0030 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1319 - val_within_eps_0_1: 0.2498\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0021 - loss: 4.5091e-04 - within_eps_0_005: 0.0695 - within_eps_0_01: 0.1385 - within_eps_0_02: 0.2719 - within_eps_0_05: 0.6032 - within_eps_0_1: 0.8830 - val_log_cosh: 0.0751 - val_loss: 0.0030 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0482 - val_within_eps_0_05: 0.1189 - val_within_eps_0_1: 0.2366\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0020 - loss: 4.2673e-04 - within_eps_0_005: 0.0746 - within_eps_0_01: 0.1476 - within_eps_0_02: 0.2887 - within_eps_0_05: 0.6298 - within_eps_0_1: 0.8965 - val_log_cosh: 0.0745 - val_loss: 0.0029 - val_within_eps_0_005: 0.0119 - val_within_eps_0_01: 0.0244 - val_within_eps_0_02: 0.0499 - val_within_eps_0_05: 0.1256 - val_within_eps_0_1: 0.2445\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0018 - loss: 4.0314e-04 - within_eps_0_005: 0.0795 - within_eps_0_01: 0.1570 - within_eps_0_02: 0.3072 - within_eps_0_05: 0.6540 - within_eps_0_1: 0.9087 - val_log_cosh: 0.0713 - val_loss: 0.0028 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0515 - val_within_eps_0_05: 0.1321 - val_within_eps_0_1: 0.2547\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0018 - loss: 4.0830e-04 - within_eps_0_005: 0.0773 - within_eps_0_01: 0.1542 - within_eps_0_02: 0.3016 - within_eps_0_05: 0.6473 - within_eps_0_1: 0.9054 - val_log_cosh: 0.0722 - val_loss: 0.0029 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0273 - val_within_eps_0_02: 0.0545 - val_within_eps_0_05: 0.1310 - val_within_eps_0_1: 0.2481\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0017 - loss: 3.9319e-04 - within_eps_0_005: 0.0811 - within_eps_0_01: 0.1601 - within_eps_0_02: 0.3113 - within_eps_0_05: 0.6633 - within_eps_0_1: 0.9144 - val_log_cosh: 0.0701 - val_loss: 0.0028 - val_within_eps_0_005: 0.0126 - val_within_eps_0_01: 0.0258 - val_within_eps_0_02: 0.0523 - val_within_eps_0_05: 0.1333 - val_within_eps_0_1: 0.2537\n",
      "  -> val_loss(min) δ=0.01: 0.002785458462\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - log_cosh: 0.3136 - loss: 0.0139 - within_eps_0_005: 0.0046 - within_eps_0_01: 0.0093 - within_eps_0_02: 0.0189 - within_eps_0_05: 0.0473 - within_eps_0_1: 0.0944 - val_log_cosh: 0.0935 - val_loss: 0.0063 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0487 - val_within_eps_0_05: 0.1171 - val_within_eps_0_1: 0.2262\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.1581 - loss: 0.0094 - within_eps_0_005: 0.0066 - within_eps_0_01: 0.0130 - within_eps_0_02: 0.0257 - within_eps_0_05: 0.0662 - within_eps_0_1: 0.1316 - val_log_cosh: 0.0746 - val_loss: 0.0055 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0277 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1316 - val_within_eps_0_1: 0.2522\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0744 - loss: 0.0061 - within_eps_0_005: 0.0104 - within_eps_0_01: 0.0207 - within_eps_0_02: 0.0412 - within_eps_0_05: 0.1028 - within_eps_0_1: 0.2038 - val_log_cosh: 0.0654 - val_loss: 0.0050 - val_within_eps_0_005: 0.0166 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0667 - val_within_eps_0_05: 0.1589 - val_within_eps_0_1: 0.2982\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0230 - loss: 0.0032 - within_eps_0_005: 0.0193 - within_eps_0_01: 0.0387 - within_eps_0_02: 0.0770 - within_eps_0_05: 0.1915 - within_eps_0_1: 0.3720 - val_log_cosh: 0.0699 - val_loss: 0.0052 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0588 - val_within_eps_0_05: 0.1449 - val_within_eps_0_1: 0.2826\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0073 - loss: 0.0017 - within_eps_0_005: 0.0351 - within_eps_0_01: 0.0704 - within_eps_0_02: 0.1405 - within_eps_0_05: 0.3398 - within_eps_0_1: 0.6157 - val_log_cosh: 0.0674 - val_loss: 0.0052 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0603 - val_within_eps_0_05: 0.1505 - val_within_eps_0_1: 0.2799\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0044 - loss: 0.0013 - within_eps_0_005: 0.0462 - within_eps_0_01: 0.0928 - within_eps_0_02: 0.1836 - within_eps_0_05: 0.4344 - within_eps_0_1: 0.7372 - val_log_cosh: 0.0607 - val_loss: 0.0048 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0328 - val_within_eps_0_02: 0.0655 - val_within_eps_0_05: 0.1632 - val_within_eps_0_1: 0.3193\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0035 - loss: 0.0011 - within_eps_0_005: 0.0530 - within_eps_0_01: 0.1053 - within_eps_0_02: 0.2066 - within_eps_0_05: 0.4837 - within_eps_0_1: 0.7890 - val_log_cosh: 0.0735 - val_loss: 0.0055 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0621 - val_within_eps_0_05: 0.1458 - val_within_eps_0_1: 0.2787\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0029 - loss: 9.8290e-04 - within_eps_0_005: 0.0591 - within_eps_0_01: 0.1172 - within_eps_0_02: 0.2315 - within_eps_0_05: 0.5276 - within_eps_0_1: 0.8288 - val_log_cosh: 0.0709 - val_loss: 0.0053 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0635 - val_within_eps_0_05: 0.1606 - val_within_eps_0_1: 0.2997\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0028 - loss: 9.7695e-04 - within_eps_0_005: 0.0583 - within_eps_0_01: 0.1154 - within_eps_0_02: 0.2285 - within_eps_0_05: 0.5267 - within_eps_0_1: 0.8328 - val_log_cosh: 0.0664 - val_loss: 0.0051 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0368 - val_within_eps_0_02: 0.0727 - val_within_eps_0_05: 0.1738 - val_within_eps_0_1: 0.3148\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0024 - loss: 8.8818e-04 - within_eps_0_005: 0.0632 - within_eps_0_01: 0.1275 - within_eps_0_02: 0.2512 - within_eps_0_05: 0.5682 - within_eps_0_1: 0.8609 - val_log_cosh: 0.0709 - val_loss: 0.0054 - val_within_eps_0_005: 0.0183 - val_within_eps_0_01: 0.0371 - val_within_eps_0_02: 0.0726 - val_within_eps_0_05: 0.1694 - val_within_eps_0_1: 0.3028\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0022 - loss: 8.3961e-04 - within_eps_0_005: 0.0682 - within_eps_0_01: 0.1363 - within_eps_0_02: 0.2656 - within_eps_0_05: 0.5916 - within_eps_0_1: 0.8753 - val_log_cosh: 0.0736 - val_loss: 0.0056 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0338 - val_within_eps_0_02: 0.0664 - val_within_eps_0_05: 0.1553 - val_within_eps_0_1: 0.2923\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0020 - loss: 7.9225e-04 - within_eps_0_005: 0.0720 - within_eps_0_01: 0.1432 - within_eps_0_02: 0.2813 - within_eps_0_05: 0.6149 - within_eps_0_1: 0.8888 - val_log_cosh: 0.0805 - val_loss: 0.0060 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0269 - val_within_eps_0_02: 0.0543 - val_within_eps_0_05: 0.1384 - val_within_eps_0_1: 0.2633\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0020 - loss: 7.6774e-04 - within_eps_0_005: 0.0739 - within_eps_0_01: 0.1477 - within_eps_0_02: 0.2888 - within_eps_0_05: 0.6296 - within_eps_0_1: 0.8957 - val_log_cosh: 0.0856 - val_loss: 0.0063 - val_within_eps_0_005: 0.0110 - val_within_eps_0_01: 0.0222 - val_within_eps_0_02: 0.0449 - val_within_eps_0_05: 0.1113 - val_within_eps_0_1: 0.2324\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0019 - loss: 7.7178e-04 - within_eps_0_005: 0.0731 - within_eps_0_01: 0.1441 - within_eps_0_02: 0.2839 - within_eps_0_05: 0.6231 - within_eps_0_1: 0.8955 - val_log_cosh: 0.0761 - val_loss: 0.0057 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0569 - val_within_eps_0_05: 0.1377 - val_within_eps_0_1: 0.2718\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0017 - loss: 7.1311e-04 - within_eps_0_005: 0.0806 - within_eps_0_01: 0.1591 - within_eps_0_02: 0.3094 - within_eps_0_05: 0.6561 - within_eps_0_1: 0.9108 - val_log_cosh: 0.0798 - val_loss: 0.0059 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0247 - val_within_eps_0_02: 0.0493 - val_within_eps_0_05: 0.1245 - val_within_eps_0_1: 0.2459\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0017 - loss: 6.9458e-04 - within_eps_0_005: 0.0827 - within_eps_0_01: 0.1623 - within_eps_0_02: 0.3165 - within_eps_0_05: 0.6666 - within_eps_0_1: 0.9154 - val_log_cosh: 0.0792 - val_loss: 0.0060 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0230 - val_within_eps_0_02: 0.0457 - val_within_eps_0_05: 0.1137 - val_within_eps_0_1: 0.2325\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0016 - loss: 6.8197e-04 - within_eps_0_005: 0.0827 - within_eps_0_01: 0.1638 - within_eps_0_02: 0.3177 - within_eps_0_05: 0.6706 - within_eps_0_1: 0.9212 - val_log_cosh: 0.0780 - val_loss: 0.0058 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0605 - val_within_eps_0_05: 0.1459 - val_within_eps_0_1: 0.2685\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0016 - loss: 6.7703e-04 - within_eps_0_005: 0.0823 - within_eps_0_01: 0.1645 - within_eps_0_02: 0.3202 - within_eps_0_05: 0.6741 - within_eps_0_1: 0.9218 - val_log_cosh: 0.0712 - val_loss: 0.0055 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0576 - val_within_eps_0_05: 0.1394 - val_within_eps_0_1: 0.2702\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0015 - loss: 6.4577e-04 - within_eps_0_005: 0.0862 - within_eps_0_01: 0.1720 - within_eps_0_02: 0.3327 - within_eps_0_05: 0.6928 - within_eps_0_1: 0.9294 - val_log_cosh: 0.0781 - val_loss: 0.0058 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0543 - val_within_eps_0_05: 0.1323 - val_within_eps_0_1: 0.2606\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0014 - loss: 6.2878e-04 - within_eps_0_005: 0.0883 - within_eps_0_01: 0.1755 - within_eps_0_02: 0.3408 - within_eps_0_05: 0.7019 - within_eps_0_1: 0.9345 - val_log_cosh: 0.0794 - val_loss: 0.0059 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0232 - val_within_eps_0_02: 0.0469 - val_within_eps_0_05: 0.1150 - val_within_eps_0_1: 0.2396\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0014 - loss: 6.2584e-04 - within_eps_0_005: 0.0882 - within_eps_0_01: 0.1755 - within_eps_0_02: 0.3414 - within_eps_0_05: 0.7017 - within_eps_0_1: 0.9359 - val_log_cosh: 0.0720 - val_loss: 0.0054 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0613 - val_within_eps_0_05: 0.1571 - val_within_eps_0_1: 0.2814\n",
      "  -> val_loss(min) δ=0.02: 0.004816911183\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - log_cosh: 0.3201 - loss: 0.0345 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0095 - within_eps_0_02: 0.0190 - within_eps_0_05: 0.0473 - within_eps_0_1: 0.0938 - val_log_cosh: 0.0906 - val_loss: 0.0150 - val_within_eps_0_005: 0.0114 - val_within_eps_0_01: 0.0229 - val_within_eps_0_02: 0.0469 - val_within_eps_0_05: 0.1153 - val_within_eps_0_1: 0.2231\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.1508 - loss: 0.0221 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0140 - within_eps_0_02: 0.0278 - within_eps_0_05: 0.0693 - within_eps_0_1: 0.1381 - val_log_cosh: 0.0796 - val_loss: 0.0138 - val_within_eps_0_005: 0.0118 - val_within_eps_0_01: 0.0241 - val_within_eps_0_02: 0.0485 - val_within_eps_0_05: 0.1233 - val_within_eps_0_1: 0.2536\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0658 - loss: 0.0136 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0214 - within_eps_0_02: 0.0436 - within_eps_0_05: 0.1086 - within_eps_0_1: 0.2178 - val_log_cosh: 0.0729 - val_loss: 0.0129 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0309 - val_within_eps_0_02: 0.0619 - val_within_eps_0_05: 0.1506 - val_within_eps_0_1: 0.2826\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0198 - loss: 0.0067 - within_eps_0_005: 0.0210 - within_eps_0_01: 0.0420 - within_eps_0_02: 0.0839 - within_eps_0_05: 0.2088 - within_eps_0_1: 0.4000 - val_log_cosh: 0.0745 - val_loss: 0.0128 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0602 - val_within_eps_0_05: 0.1546 - val_within_eps_0_1: 0.3017\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0067 - loss: 0.0034 - within_eps_0_005: 0.0371 - within_eps_0_01: 0.0737 - within_eps_0_02: 0.1464 - within_eps_0_05: 0.3544 - within_eps_0_1: 0.6342 - val_log_cosh: 0.0818 - val_loss: 0.0137 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0621 - val_within_eps_0_05: 0.1495 - val_within_eps_0_1: 0.2860\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0043 - loss: 0.0025 - within_eps_0_005: 0.0466 - within_eps_0_01: 0.0934 - within_eps_0_02: 0.1859 - within_eps_0_05: 0.4392 - within_eps_0_1: 0.7422 - val_log_cosh: 0.0778 - val_loss: 0.0132 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0595 - val_within_eps_0_05: 0.1492 - val_within_eps_0_1: 0.3048\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0035 - loss: 0.0022 - within_eps_0_005: 0.0529 - within_eps_0_01: 0.1058 - within_eps_0_02: 0.2091 - within_eps_0_05: 0.4890 - within_eps_0_1: 0.7938 - val_log_cosh: 0.0754 - val_loss: 0.0129 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0308 - val_within_eps_0_02: 0.0600 - val_within_eps_0_05: 0.1532 - val_within_eps_0_1: 0.3048\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0031 - loss: 0.0020 - within_eps_0_005: 0.0566 - within_eps_0_01: 0.1132 - within_eps_0_02: 0.2233 - within_eps_0_05: 0.5176 - within_eps_0_1: 0.8185 - val_log_cosh: 0.0709 - val_loss: 0.0125 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0302 - val_within_eps_0_02: 0.0611 - val_within_eps_0_05: 0.1603 - val_within_eps_0_1: 0.3134\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0028 - loss: 0.0018 - within_eps_0_005: 0.0614 - within_eps_0_01: 0.1219 - within_eps_0_02: 0.2404 - within_eps_0_05: 0.5467 - within_eps_0_1: 0.8406 - val_log_cosh: 0.0802 - val_loss: 0.0136 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0333 - val_within_eps_0_02: 0.0641 - val_within_eps_0_05: 0.1542 - val_within_eps_0_1: 0.2944\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0026 - loss: 0.0017 - within_eps_0_005: 0.0646 - within_eps_0_01: 0.1276 - within_eps_0_02: 0.2536 - within_eps_0_05: 0.5663 - within_eps_0_1: 0.8528 - val_log_cosh: 0.0809 - val_loss: 0.0137 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0336 - val_within_eps_0_02: 0.0643 - val_within_eps_0_05: 0.1522 - val_within_eps_0_1: 0.2827\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0024 - loss: 0.0016 - within_eps_0_005: 0.0667 - within_eps_0_01: 0.1332 - within_eps_0_02: 0.2609 - within_eps_0_05: 0.5815 - within_eps_0_1: 0.8658 - val_log_cosh: 0.0773 - val_loss: 0.0132 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0351 - val_within_eps_0_02: 0.0710 - val_within_eps_0_05: 0.1661 - val_within_eps_0_1: 0.3013\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0022 - loss: 0.0016 - within_eps_0_005: 0.0698 - within_eps_0_01: 0.1389 - within_eps_0_02: 0.2717 - within_eps_0_05: 0.5999 - within_eps_0_1: 0.8768 - val_log_cosh: 0.0787 - val_loss: 0.0137 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0330 - val_within_eps_0_02: 0.0650 - val_within_eps_0_05: 0.1495 - val_within_eps_0_1: 0.2726\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - log_cosh: 0.0022 - loss: 0.0015 - within_eps_0_005: 0.0708 - within_eps_0_01: 0.1420 - within_eps_0_02: 0.2784 - within_eps_0_05: 0.6102 - within_eps_0_1: 0.8798 - val_log_cosh: 0.0815 - val_loss: 0.0140 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0338 - val_within_eps_0_02: 0.0653 - val_within_eps_0_05: 0.1484 - val_within_eps_0_1: 0.2637\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0020 - loss: 0.0014 - within_eps_0_005: 0.0737 - within_eps_0_01: 0.1464 - within_eps_0_02: 0.2878 - within_eps_0_05: 0.6259 - within_eps_0_1: 0.8945 - val_log_cosh: 0.0755 - val_loss: 0.0133 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0551 - val_within_eps_0_05: 0.1395 - val_within_eps_0_1: 0.2856\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0019 - loss: 0.0014 - within_eps_0_005: 0.0755 - within_eps_0_01: 0.1514 - within_eps_0_02: 0.2941 - within_eps_0_05: 0.6342 - within_eps_0_1: 0.8991 - val_log_cosh: 0.0754 - val_loss: 0.0132 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1516 - val_within_eps_0_1: 0.2915\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0019 - loss: 0.0014 - within_eps_0_005: 0.0778 - within_eps_0_01: 0.1558 - within_eps_0_02: 0.3034 - within_eps_0_05: 0.6471 - within_eps_0_1: 0.9035 - val_log_cosh: 0.0777 - val_loss: 0.0135 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1483 - val_within_eps_0_1: 0.2786\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0019 - loss: 0.0013 - within_eps_0_005: 0.0778 - within_eps_0_01: 0.1547 - within_eps_0_02: 0.3025 - within_eps_0_05: 0.6477 - within_eps_0_1: 0.9042 - val_log_cosh: 0.0726 - val_loss: 0.0128 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0304 - val_within_eps_0_02: 0.0622 - val_within_eps_0_05: 0.1583 - val_within_eps_0_1: 0.3066\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0018 - loss: 0.0013 - within_eps_0_005: 0.0803 - within_eps_0_01: 0.1605 - within_eps_0_02: 0.3120 - within_eps_0_05: 0.6595 - within_eps_0_1: 0.9107 - val_log_cosh: 0.0752 - val_loss: 0.0132 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0580 - val_within_eps_0_05: 0.1435 - val_within_eps_0_1: 0.2823\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0017 - loss: 0.0012 - within_eps_0_005: 0.0854 - within_eps_0_01: 0.1683 - within_eps_0_02: 0.3261 - within_eps_0_05: 0.6760 - within_eps_0_1: 0.9173 - val_log_cosh: 0.0798 - val_loss: 0.0138 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1379 - val_within_eps_0_1: 0.2619\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0863 - within_eps_0_01: 0.1714 - within_eps_0_02: 0.3306 - within_eps_0_05: 0.6826 - within_eps_0_1: 0.9209 - val_log_cosh: 0.0732 - val_loss: 0.0129 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1387 - val_within_eps_0_1: 0.2897\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0840 - within_eps_0_01: 0.1654 - within_eps_0_02: 0.3219 - within_eps_0_05: 0.6789 - within_eps_0_1: 0.9230 - val_log_cosh: 0.0725 - val_loss: 0.0126 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0346 - val_within_eps_0_02: 0.0678 - val_within_eps_0_05: 0.1685 - val_within_eps_0_1: 0.3230\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0015 - loss: 0.0012 - within_eps_0_005: 0.0892 - within_eps_0_01: 0.1759 - within_eps_0_02: 0.3397 - within_eps_0_05: 0.6923 - within_eps_0_1: 0.9255 - val_log_cosh: 0.0756 - val_loss: 0.0132 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1397 - val_within_eps_0_1: 0.2809\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0015 - loss: 0.0011 - within_eps_0_005: 0.0894 - within_eps_0_01: 0.1779 - within_eps_0_02: 0.3438 - within_eps_0_05: 0.7007 - within_eps_0_1: 0.9302 - val_log_cosh: 0.0785 - val_loss: 0.0136 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0537 - val_within_eps_0_05: 0.1380 - val_within_eps_0_1: 0.2704\n",
      "  -> val_loss(min) δ=0.05: 0.012545714155\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - log_cosh: 0.3246 - loss: 0.0673 - within_eps_0_005: 0.0045 - within_eps_0_01: 0.0093 - within_eps_0_02: 0.0185 - within_eps_0_05: 0.0466 - within_eps_0_1: 0.0924 - val_log_cosh: 0.1107 - val_loss: 0.0318 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0201 - val_within_eps_0_02: 0.0405 - val_within_eps_0_05: 0.0981 - val_within_eps_0_1: 0.1973\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.1632 - loss: 0.0441 - within_eps_0_005: 0.0065 - within_eps_0_01: 0.0131 - within_eps_0_02: 0.0257 - within_eps_0_05: 0.0650 - within_eps_0_1: 0.1301 - val_log_cosh: 0.0980 - val_loss: 0.0288 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0252 - val_within_eps_0_02: 0.0488 - val_within_eps_0_05: 0.1245 - val_within_eps_0_1: 0.2423\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0868 - loss: 0.0297 - within_eps_0_005: 0.0095 - within_eps_0_01: 0.0191 - within_eps_0_02: 0.0381 - within_eps_0_05: 0.0949 - within_eps_0_1: 0.1874 - val_log_cosh: 0.0661 - val_loss: 0.0219 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0602 - val_within_eps_0_05: 0.1529 - val_within_eps_0_1: 0.2886\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0251 - loss: 0.0134 - within_eps_0_005: 0.0187 - within_eps_0_01: 0.0370 - within_eps_0_02: 0.0748 - within_eps_0_05: 0.1843 - within_eps_0_1: 0.3591 - val_log_cosh: 0.0621 - val_loss: 0.0209 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0605 - val_within_eps_0_05: 0.1508 - val_within_eps_0_1: 0.3100\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0073 - loss: 0.0056 - within_eps_0_005: 0.0351 - within_eps_0_01: 0.0706 - within_eps_0_02: 0.1402 - within_eps_0_05: 0.3372 - within_eps_0_1: 0.6132 - val_log_cosh: 0.0609 - val_loss: 0.0204 - val_within_eps_0_005: 0.0177 - val_within_eps_0_01: 0.0358 - val_within_eps_0_02: 0.0718 - val_within_eps_0_05: 0.1747 - val_within_eps_0_1: 0.3263\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0047 - loss: 0.0039 - within_eps_0_005: 0.0440 - within_eps_0_01: 0.0889 - within_eps_0_02: 0.1767 - within_eps_0_05: 0.4210 - within_eps_0_1: 0.7230 - val_log_cosh: 0.0701 - val_loss: 0.0229 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0614 - val_within_eps_0_05: 0.1518 - val_within_eps_0_1: 0.2996\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0037 - loss: 0.0032 - within_eps_0_005: 0.0498 - within_eps_0_01: 0.1002 - within_eps_0_02: 0.1998 - within_eps_0_05: 0.4711 - within_eps_0_1: 0.7770 - val_log_cosh: 0.0700 - val_loss: 0.0227 - val_within_eps_0_005: 0.0176 - val_within_eps_0_01: 0.0348 - val_within_eps_0_02: 0.0678 - val_within_eps_0_05: 0.1621 - val_within_eps_0_1: 0.3193\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0034 - loss: 0.0030 - within_eps_0_005: 0.0537 - within_eps_0_01: 0.1068 - within_eps_0_02: 0.2112 - within_eps_0_05: 0.4932 - within_eps_0_1: 0.8001 - val_log_cosh: 0.0701 - val_loss: 0.0226 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0311 - val_within_eps_0_02: 0.0627 - val_within_eps_0_05: 0.1653 - val_within_eps_0_1: 0.3178\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0029 - loss: 0.0026 - within_eps_0_005: 0.0598 - within_eps_0_01: 0.1193 - within_eps_0_02: 0.2336 - within_eps_0_05: 0.5355 - within_eps_0_1: 0.8318 - val_log_cosh: 0.0714 - val_loss: 0.0230 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0334 - val_within_eps_0_02: 0.0660 - val_within_eps_0_05: 0.1637 - val_within_eps_0_1: 0.3150\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - log_cosh: 0.0027 - loss: 0.0024 - within_eps_0_005: 0.0616 - within_eps_0_01: 0.1223 - within_eps_0_02: 0.2412 - within_eps_0_05: 0.5500 - within_eps_0_1: 0.8464 - val_log_cosh: 0.0738 - val_loss: 0.0236 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0612 - val_within_eps_0_05: 0.1477 - val_within_eps_0_1: 0.2971\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - log_cosh: 0.0026 - loss: 0.0024 - within_eps_0_005: 0.0628 - within_eps_0_01: 0.1250 - within_eps_0_02: 0.2459 - within_eps_0_05: 0.5573 - within_eps_0_1: 0.8499 - val_log_cosh: 0.0724 - val_loss: 0.0231 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0342 - val_within_eps_0_02: 0.0685 - val_within_eps_0_05: 0.1732 - val_within_eps_0_1: 0.3201\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0024 - loss: 0.0022 - within_eps_0_005: 0.0675 - within_eps_0_01: 0.1337 - within_eps_0_02: 0.2619 - within_eps_0_05: 0.5834 - within_eps_0_1: 0.8673 - val_log_cosh: 0.0772 - val_loss: 0.0242 - val_within_eps_0_005: 0.0167 - val_within_eps_0_01: 0.0334 - val_within_eps_0_02: 0.0671 - val_within_eps_0_05: 0.1680 - val_within_eps_0_1: 0.3108\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - log_cosh: 0.0023 - loss: 0.0021 - within_eps_0_005: 0.0678 - within_eps_0_01: 0.1351 - within_eps_0_02: 0.2657 - within_eps_0_05: 0.5910 - within_eps_0_1: 0.8731 - val_log_cosh: 0.0784 - val_loss: 0.0248 - val_within_eps_0_005: 0.0179 - val_within_eps_0_01: 0.0354 - val_within_eps_0_02: 0.0695 - val_within_eps_0_05: 0.1604 - val_within_eps_0_1: 0.2967\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0022 - loss: 0.0020 - within_eps_0_005: 0.0712 - within_eps_0_01: 0.1405 - within_eps_0_02: 0.2751 - within_eps_0_05: 0.6026 - within_eps_0_1: 0.8799 - val_log_cosh: 0.0825 - val_loss: 0.0258 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0605 - val_within_eps_0_05: 0.1493 - val_within_eps_0_1: 0.2816\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0020 - loss: 0.0018 - within_eps_0_005: 0.0741 - within_eps_0_01: 0.1470 - within_eps_0_02: 0.2873 - within_eps_0_05: 0.6273 - within_eps_0_1: 0.8945 - val_log_cosh: 0.0851 - val_loss: 0.0268 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0637 - val_within_eps_0_05: 0.1537 - val_within_eps_0_1: 0.2760\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0019 - loss: 0.0018 - within_eps_0_005: 0.0765 - within_eps_0_01: 0.1515 - within_eps_0_02: 0.2964 - within_eps_0_05: 0.6374 - within_eps_0_1: 0.9005 - val_log_cosh: 0.0848 - val_loss: 0.0268 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0600 - val_within_eps_0_05: 0.1505 - val_within_eps_0_1: 0.2739\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0778 - within_eps_0_01: 0.1540 - within_eps_0_02: 0.3003 - within_eps_0_05: 0.6439 - within_eps_0_1: 0.9056 - val_log_cosh: 0.0925 - val_loss: 0.0292 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0233 - val_within_eps_0_02: 0.0478 - val_within_eps_0_05: 0.1163 - val_within_eps_0_1: 0.2241\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0761 - within_eps_0_01: 0.1519 - within_eps_0_02: 0.2983 - within_eps_0_05: 0.6430 - within_eps_0_1: 0.9059 - val_log_cosh: 0.0897 - val_loss: 0.0282 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0514 - val_within_eps_0_05: 0.1271 - val_within_eps_0_1: 0.2556\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0017 - loss: 0.0016 - within_eps_0_005: 0.0819 - within_eps_0_01: 0.1629 - within_eps_0_02: 0.3180 - within_eps_0_05: 0.6694 - within_eps_0_1: 0.9169 - val_log_cosh: 0.0793 - val_loss: 0.0258 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0620 - val_within_eps_0_05: 0.1443 - val_within_eps_0_1: 0.2659\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - log_cosh: 0.0016 - loss: 0.0015 - within_eps_0_005: 0.0834 - within_eps_0_01: 0.1656 - within_eps_0_02: 0.3221 - within_eps_0_05: 0.6776 - within_eps_0_1: 0.9240 - val_log_cosh: 0.0904 - val_loss: 0.0287 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0220 - val_within_eps_0_02: 0.0447 - val_within_eps_0_05: 0.1157 - val_within_eps_0_1: 0.2276\n",
      "  -> val_loss(min) δ=0.1: 0.020434387028\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - log_cosh: 0.3176 - loss: 0.1495 - within_eps_0_005: 0.0046 - within_eps_0_01: 0.0092 - within_eps_0_02: 0.0190 - within_eps_0_05: 0.0468 - within_eps_0_1: 0.0929 - val_log_cosh: 0.0870 - val_loss: 0.0538 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0544 - val_within_eps_0_05: 0.1273 - val_within_eps_0_1: 0.2372\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.1599 - loss: 0.0930 - within_eps_0_005: 0.0066 - within_eps_0_01: 0.0133 - within_eps_0_02: 0.0265 - within_eps_0_05: 0.0656 - within_eps_0_1: 0.1317 - val_log_cosh: 0.0783 - val_loss: 0.0488 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0271 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1349 - val_within_eps_0_1: 0.2643\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0891 - loss: 0.0608 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0184 - within_eps_0_02: 0.0372 - within_eps_0_05: 0.0929 - within_eps_0_1: 0.1844 - val_log_cosh: 0.0683 - val_loss: 0.0432 - val_within_eps_0_005: 0.0170 - val_within_eps_0_01: 0.0327 - val_within_eps_0_02: 0.0633 - val_within_eps_0_05: 0.1556 - val_within_eps_0_1: 0.2977\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0272 - loss: 0.0239 - within_eps_0_005: 0.0181 - within_eps_0_01: 0.0354 - within_eps_0_02: 0.0709 - within_eps_0_05: 0.1768 - within_eps_0_1: 0.3447 - val_log_cosh: 0.0899 - val_loss: 0.0548 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0563 - val_within_eps_0_05: 0.1357 - val_within_eps_0_1: 0.2535\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0079 - loss: 0.0078 - within_eps_0_005: 0.0331 - within_eps_0_01: 0.0666 - within_eps_0_02: 0.1325 - within_eps_0_05: 0.3231 - within_eps_0_1: 0.5911 - val_log_cosh: 0.0807 - val_loss: 0.0499 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1406 - val_within_eps_0_1: 0.2657\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - log_cosh: 0.0049 - loss: 0.0049 - within_eps_0_005: 0.0432 - within_eps_0_01: 0.0860 - within_eps_0_02: 0.1702 - within_eps_0_05: 0.4077 - within_eps_0_1: 0.7070 - val_log_cosh: 0.0760 - val_loss: 0.0475 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0292 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1466 - val_within_eps_0_1: 0.2973\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0040 - loss: 0.0040 - within_eps_0_005: 0.0476 - within_eps_0_01: 0.0956 - within_eps_0_02: 0.1911 - within_eps_0_05: 0.4510 - within_eps_0_1: 0.7566 - val_log_cosh: 0.0833 - val_loss: 0.0512 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0302 - val_within_eps_0_02: 0.0607 - val_within_eps_0_05: 0.1446 - val_within_eps_0_1: 0.2731\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0036 - loss: 0.0036 - within_eps_0_005: 0.0514 - within_eps_0_01: 0.1033 - within_eps_0_02: 0.2046 - within_eps_0_05: 0.4779 - within_eps_0_1: 0.7830 - val_log_cosh: 0.0862 - val_loss: 0.0530 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1427 - val_within_eps_0_1: 0.2689\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0033 - loss: 0.0033 - within_eps_0_005: 0.0542 - within_eps_0_01: 0.1081 - within_eps_0_02: 0.2133 - within_eps_0_05: 0.4961 - within_eps_0_1: 0.8010 - val_log_cosh: 0.0854 - val_loss: 0.0526 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1473 - val_within_eps_0_1: 0.2737\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0031 - loss: 0.0031 - within_eps_0_005: 0.0569 - within_eps_0_01: 0.1127 - within_eps_0_02: 0.2227 - within_eps_0_05: 0.5129 - within_eps_0_1: 0.8136 - val_log_cosh: 0.0742 - val_loss: 0.0466 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1530 - val_within_eps_0_1: 0.3087\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - log_cosh: 0.0029 - loss: 0.0029 - within_eps_0_005: 0.0579 - within_eps_0_01: 0.1155 - within_eps_0_02: 0.2266 - within_eps_0_05: 0.5246 - within_eps_0_1: 0.8270 - val_log_cosh: 0.0747 - val_loss: 0.0468 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0329 - val_within_eps_0_02: 0.0642 - val_within_eps_0_05: 0.1535 - val_within_eps_0_1: 0.3065\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0027 - loss: 0.0027 - within_eps_0_005: 0.0595 - within_eps_0_01: 0.1197 - within_eps_0_02: 0.2353 - within_eps_0_05: 0.5396 - within_eps_0_1: 0.8387 - val_log_cosh: 0.0806 - val_loss: 0.0503 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0313 - val_within_eps_0_02: 0.0615 - val_within_eps_0_05: 0.1407 - val_within_eps_0_1: 0.2798\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - log_cosh: 0.0026 - loss: 0.0027 - within_eps_0_005: 0.0604 - within_eps_0_01: 0.1207 - within_eps_0_02: 0.2386 - within_eps_0_05: 0.5455 - within_eps_0_1: 0.8437 - val_log_cosh: 0.0785 - val_loss: 0.0490 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1470 - val_within_eps_0_1: 0.2817\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0024 - loss: 0.0024 - within_eps_0_005: 0.0653 - within_eps_0_01: 0.1303 - within_eps_0_02: 0.2562 - within_eps_0_05: 0.5744 - within_eps_0_1: 0.8634 - val_log_cosh: 0.0716 - val_loss: 0.0454 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0353 - val_within_eps_0_02: 0.0684 - val_within_eps_0_05: 0.1620 - val_within_eps_0_1: 0.3067\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0665 - within_eps_0_01: 0.1326 - within_eps_0_02: 0.2618 - within_eps_0_05: 0.5860 - within_eps_0_1: 0.8729 - val_log_cosh: 0.0764 - val_loss: 0.0482 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0524 - val_within_eps_0_05: 0.1354 - val_within_eps_0_1: 0.2769\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0667 - within_eps_0_01: 0.1331 - within_eps_0_02: 0.2616 - within_eps_0_05: 0.5862 - within_eps_0_1: 0.8726 - val_log_cosh: 0.0700 - val_loss: 0.0447 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1538 - val_within_eps_0_1: 0.3126\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0021 - loss: 0.0021 - within_eps_0_005: 0.0689 - within_eps_0_01: 0.1364 - within_eps_0_02: 0.2679 - within_eps_0_05: 0.5958 - within_eps_0_1: 0.8815 - val_log_cosh: 0.0732 - val_loss: 0.0468 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0579 - val_within_eps_0_05: 0.1431 - val_within_eps_0_1: 0.2822\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0020 - loss: 0.0020 - within_eps_0_005: 0.0711 - within_eps_0_01: 0.1419 - within_eps_0_02: 0.2766 - within_eps_0_05: 0.6098 - within_eps_0_1: 0.8894 - val_log_cosh: 0.0749 - val_loss: 0.0478 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0254 - val_within_eps_0_02: 0.0518 - val_within_eps_0_05: 0.1321 - val_within_eps_0_1: 0.2783\n",
      "  -> val_loss(min) δ=0.25: 0.043195370585\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - log_cosh: 0.3195 - loss: 0.2512 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0095 - within_eps_0_02: 0.0188 - within_eps_0_05: 0.0469 - within_eps_0_1: 0.0945 - val_log_cosh: 0.0876 - val_loss: 0.0765 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0254 - val_within_eps_0_02: 0.0508 - val_within_eps_0_05: 0.1229 - val_within_eps_0_1: 0.2432\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - log_cosh: 0.1394 - loss: 0.1270 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0144 - within_eps_0_02: 0.0292 - within_eps_0_05: 0.0728 - within_eps_0_1: 0.1445 - val_log_cosh: 0.0710 - val_loss: 0.0620 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0647 - val_within_eps_0_05: 0.1519 - val_within_eps_0_1: 0.2903\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - log_cosh: 0.0508 - loss: 0.0508 - within_eps_0_005: 0.0130 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0513 - within_eps_0_05: 0.1278 - within_eps_0_1: 0.2510 - val_log_cosh: 0.0691 - val_loss: 0.0607 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0281 - val_within_eps_0_02: 0.0579 - val_within_eps_0_05: 0.1473 - val_within_eps_0_1: 0.2846\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0176 - loss: 0.0178 - within_eps_0_005: 0.0221 - within_eps_0_01: 0.0438 - within_eps_0_02: 0.0880 - within_eps_0_05: 0.2180 - within_eps_0_1: 0.4175 - val_log_cosh: 0.0748 - val_loss: 0.0657 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0576 - val_within_eps_0_05: 0.1449 - val_within_eps_0_1: 0.2875\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0083 - loss: 0.0084 - within_eps_0_005: 0.0324 - within_eps_0_01: 0.0648 - within_eps_0_02: 0.1282 - within_eps_0_05: 0.3160 - within_eps_0_1: 0.5783 - val_log_cosh: 0.0778 - val_loss: 0.0685 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1470 - val_within_eps_0_1: 0.2841\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0057 - loss: 0.0057 - within_eps_0_005: 0.0399 - within_eps_0_01: 0.0793 - within_eps_0_02: 0.1566 - within_eps_0_05: 0.3761 - within_eps_0_1: 0.6689 - val_log_cosh: 0.0824 - val_loss: 0.0728 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0619 - val_within_eps_0_05: 0.1439 - val_within_eps_0_1: 0.2726\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0047 - loss: 0.0047 - within_eps_0_005: 0.0450 - within_eps_0_01: 0.0901 - within_eps_0_02: 0.1775 - within_eps_0_05: 0.4196 - within_eps_0_1: 0.7214 - val_log_cosh: 0.0856 - val_loss: 0.0755 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1398 - val_within_eps_0_1: 0.2642\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0042 - loss: 0.0042 - within_eps_0_005: 0.0464 - within_eps_0_01: 0.0919 - within_eps_0_02: 0.1843 - within_eps_0_05: 0.4386 - within_eps_0_1: 0.7451 - val_log_cosh: 0.0791 - val_loss: 0.0700 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0624 - val_within_eps_0_05: 0.1461 - val_within_eps_0_1: 0.2668\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0039 - loss: 0.0039 - within_eps_0_005: 0.0486 - within_eps_0_01: 0.0970 - within_eps_0_02: 0.1929 - within_eps_0_05: 0.4562 - within_eps_0_1: 0.7626 - val_log_cosh: 0.0750 - val_loss: 0.0664 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0625 - val_within_eps_0_05: 0.1528 - val_within_eps_0_1: 0.2999\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0035 - loss: 0.0035 - within_eps_0_005: 0.0518 - within_eps_0_01: 0.1039 - within_eps_0_02: 0.2063 - within_eps_0_05: 0.4821 - within_eps_0_1: 0.7897 - val_log_cosh: 0.0710 - val_loss: 0.0631 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0334 - val_within_eps_0_02: 0.0661 - val_within_eps_0_05: 0.1614 - val_within_eps_0_1: 0.3051\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0031 - loss: 0.0032 - within_eps_0_005: 0.0548 - within_eps_0_01: 0.1089 - within_eps_0_02: 0.2166 - within_eps_0_05: 0.5027 - within_eps_0_1: 0.8088 - val_log_cosh: 0.0762 - val_loss: 0.0677 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0612 - val_within_eps_0_05: 0.1492 - val_within_eps_0_1: 0.2862\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0029 - loss: 0.0030 - within_eps_0_005: 0.0579 - within_eps_0_01: 0.1143 - within_eps_0_02: 0.2266 - within_eps_0_05: 0.5211 - within_eps_0_1: 0.8243 - val_log_cosh: 0.0751 - val_loss: 0.0668 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0631 - val_within_eps_0_05: 0.1497 - val_within_eps_0_1: 0.2816\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - log_cosh: 0.0028 - loss: 0.0028 - within_eps_0_005: 0.0597 - within_eps_0_01: 0.1184 - within_eps_0_02: 0.2331 - within_eps_0_05: 0.5341 - within_eps_0_1: 0.8351 - val_log_cosh: 0.0751 - val_loss: 0.0667 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0277 - val_within_eps_0_02: 0.0559 - val_within_eps_0_05: 0.1426 - val_within_eps_0_1: 0.2820\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0027 - loss: 0.0027 - within_eps_0_005: 0.0591 - within_eps_0_01: 0.1185 - within_eps_0_02: 0.2355 - within_eps_0_05: 0.5408 - within_eps_0_1: 0.8405 - val_log_cosh: 0.0738 - val_loss: 0.0657 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0578 - val_within_eps_0_05: 0.1413 - val_within_eps_0_1: 0.2813\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0026 - loss: 0.0026 - within_eps_0_005: 0.0618 - within_eps_0_01: 0.1224 - within_eps_0_02: 0.2424 - within_eps_0_05: 0.5518 - within_eps_0_1: 0.8476 - val_log_cosh: 0.0770 - val_loss: 0.0686 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0577 - val_within_eps_0_05: 0.1433 - val_within_eps_0_1: 0.2906\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0024 - loss: 0.0024 - within_eps_0_005: 0.0657 - within_eps_0_01: 0.1289 - within_eps_0_02: 0.2549 - within_eps_0_05: 0.5705 - within_eps_0_1: 0.8609 - val_log_cosh: 0.0785 - val_loss: 0.0702 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0564 - val_within_eps_0_05: 0.1415 - val_within_eps_0_1: 0.2735\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0024 - loss: 0.0024 - within_eps_0_005: 0.0636 - within_eps_0_01: 0.1270 - within_eps_0_02: 0.2528 - within_eps_0_05: 0.5722 - within_eps_0_1: 0.8633 - val_log_cosh: 0.0819 - val_loss: 0.0735 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0537 - val_within_eps_0_05: 0.1309 - val_within_eps_0_1: 0.2583\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0023 - loss: 0.0023 - within_eps_0_005: 0.0662 - within_eps_0_01: 0.1316 - within_eps_0_02: 0.2604 - within_eps_0_05: 0.5817 - within_eps_0_1: 0.8676 - val_log_cosh: 0.0824 - val_loss: 0.0741 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0566 - val_within_eps_0_05: 0.1391 - val_within_eps_0_1: 0.2590\n",
      "  -> val_loss(min) δ=0.5: 0.060675553977\n",
      "\n",
      "Tabla val_loss(min) por δ (orden asc):\n",
      "  δ=0.01: 0.002785458462\n",
      "  δ=0.02: 0.004816911183\n",
      "  δ=0.05: 0.012545714155\n",
      "  δ= 0.1: 0.020434387028\n",
      "  δ=0.25: 0.043195370585\n",
      "  δ= 0.5: 0.060675553977\n",
      "\n",
      ">>> Mejor δ por tu regla: 0.01 (val_loss=0.002785458462)\n",
      "\n",
      "Resultados TEST - Escenario M (CNN)\n",
      "  loss (Huber):              0.019197\n",
      "  log_cosh:                  1.597576\n",
      "  within_eps_0_005          : 0.003846\n",
      "  within_eps_0_01           : 0.007531\n",
      "  within_eps_0_02           : 0.015037\n",
      "  within_eps_0_05           : 0.038619\n",
      "  within_eps_0_1            : 0.079615\n",
      "  AUTC[0.005–0.100]:         0.041073\n",
      "\n",
      "=== Barrido Huber delta _L ===\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - log_cosh: 0.3084 - loss: 0.0070 - within_eps_0_005: 0.0049 - within_eps_0_01: 0.0096 - within_eps_0_02: 0.0191 - within_eps_0_05: 0.0477 - within_eps_0_1: 0.0953 - val_log_cosh: 0.0803 - val_loss: 0.0030 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0246 - val_within_eps_0_02: 0.0492 - val_within_eps_0_05: 0.1204 - val_within_eps_0_1: 0.2337\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - log_cosh: 0.1560 - loss: 0.0047 - within_eps_0_005: 0.0066 - within_eps_0_01: 0.0133 - within_eps_0_02: 0.0267 - within_eps_0_05: 0.0667 - within_eps_0_1: 0.1335 - val_log_cosh: 0.0697 - val_loss: 0.0027 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0254 - val_within_eps_0_02: 0.0508 - val_within_eps_0_05: 0.1273 - val_within_eps_0_1: 0.2545\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0901 - loss: 0.0035 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0183 - within_eps_0_02: 0.0365 - within_eps_0_05: 0.0914 - within_eps_0_1: 0.1819 - val_log_cosh: 0.0706 - val_loss: 0.0028 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1336 - val_within_eps_0_1: 0.2566\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0342 - loss: 0.0020 - within_eps_0_005: 0.0156 - within_eps_0_01: 0.0313 - within_eps_0_02: 0.0624 - within_eps_0_05: 0.1548 - within_eps_0_1: 0.3038 - val_log_cosh: 0.0736 - val_loss: 0.0028 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1418 - val_within_eps_0_1: 0.2741\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0111 - loss: 0.0011 - within_eps_0_005: 0.0285 - within_eps_0_01: 0.0565 - within_eps_0_02: 0.1123 - within_eps_0_05: 0.2751 - within_eps_0_1: 0.5149 - val_log_cosh: 0.0721 - val_loss: 0.0027 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0586 - val_within_eps_0_05: 0.1456 - val_within_eps_0_1: 0.2841\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0051 - loss: 7.3839e-04 - within_eps_0_005: 0.0421 - within_eps_0_01: 0.0840 - within_eps_0_02: 0.1671 - within_eps_0_05: 0.4004 - within_eps_0_1: 0.6991 - val_log_cosh: 0.0727 - val_loss: 0.0028 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0285 - val_within_eps_0_02: 0.0575 - val_within_eps_0_05: 0.1421 - val_within_eps_0_1: 0.2773\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0038 - loss: 6.2960e-04 - within_eps_0_005: 0.0497 - within_eps_0_01: 0.0995 - within_eps_0_02: 0.1976 - within_eps_0_05: 0.4635 - within_eps_0_1: 0.7686 - val_log_cosh: 0.0779 - val_loss: 0.0029 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0258 - val_within_eps_0_02: 0.0515 - val_within_eps_0_05: 0.1286 - val_within_eps_0_1: 0.2568\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0033 - loss: 5.7823e-04 - within_eps_0_005: 0.0539 - within_eps_0_01: 0.1076 - within_eps_0_02: 0.2133 - within_eps_0_05: 0.4965 - within_eps_0_1: 0.8025 - val_log_cosh: 0.0759 - val_loss: 0.0029 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0577 - val_within_eps_0_05: 0.1423 - val_within_eps_0_1: 0.2643\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0029 - loss: 5.4052e-04 - within_eps_0_005: 0.0578 - within_eps_0_01: 0.1151 - within_eps_0_02: 0.2277 - within_eps_0_05: 0.5251 - within_eps_0_1: 0.8275 - val_log_cosh: 0.0773 - val_loss: 0.0029 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0529 - val_within_eps_0_05: 0.1315 - val_within_eps_0_1: 0.2520\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0026 - loss: 5.0778e-04 - within_eps_0_005: 0.0619 - within_eps_0_01: 0.1235 - within_eps_0_02: 0.2431 - within_eps_0_05: 0.5529 - within_eps_0_1: 0.8481 - val_log_cosh: 0.0837 - val_loss: 0.0030 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0577 - val_within_eps_0_05: 0.1377 - val_within_eps_0_1: 0.2583\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0026 - loss: 5.0090e-04 - within_eps_0_005: 0.0625 - within_eps_0_01: 0.1243 - within_eps_0_02: 0.2454 - within_eps_0_05: 0.5567 - within_eps_0_1: 0.8528 - val_log_cosh: 0.0852 - val_loss: 0.0031 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0499 - val_within_eps_0_05: 0.1260 - val_within_eps_0_1: 0.2417\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0024 - loss: 4.8525e-04 - within_eps_0_005: 0.0639 - within_eps_0_01: 0.1282 - within_eps_0_02: 0.2521 - within_eps_0_05: 0.5708 - within_eps_0_1: 0.8634 - val_log_cosh: 0.0779 - val_loss: 0.0029 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1326 - val_within_eps_0_1: 0.2572\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0023 - loss: 4.6444e-04 - within_eps_0_005: 0.0679 - within_eps_0_01: 0.1349 - within_eps_0_02: 0.2650 - within_eps_0_05: 0.5901 - within_eps_0_1: 0.8754 - val_log_cosh: 0.0814 - val_loss: 0.0030 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1296 - val_within_eps_0_1: 0.2518\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0022 - loss: 4.5394e-04 - within_eps_0_005: 0.0687 - within_eps_0_01: 0.1362 - within_eps_0_02: 0.2683 - within_eps_0_05: 0.5991 - within_eps_0_1: 0.8831 - val_log_cosh: 0.0811 - val_loss: 0.0030 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1415 - val_within_eps_0_1: 0.2668\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0021 - loss: 4.4231e-04 - within_eps_0_005: 0.0705 - within_eps_0_01: 0.1397 - within_eps_0_02: 0.2740 - within_eps_0_05: 0.6092 - within_eps_0_1: 0.8895 - val_log_cosh: 0.0859 - val_loss: 0.0031 - val_within_eps_0_005: 0.0107 - val_within_eps_0_01: 0.0218 - val_within_eps_0_02: 0.0444 - val_within_eps_0_05: 0.1156 - val_within_eps_0_1: 0.2372\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0019 - loss: 4.2166e-04 - within_eps_0_005: 0.0744 - within_eps_0_01: 0.1480 - within_eps_0_02: 0.2892 - within_eps_0_05: 0.6316 - within_eps_0_1: 0.9009 - val_log_cosh: 0.0914 - val_loss: 0.0032 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0224 - val_within_eps_0_02: 0.0451 - val_within_eps_0_05: 0.1154 - val_within_eps_0_1: 0.2349\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0019 - loss: 4.1670e-04 - within_eps_0_005: 0.0746 - within_eps_0_01: 0.1488 - within_eps_0_02: 0.2919 - within_eps_0_05: 0.6362 - within_eps_0_1: 0.9039 - val_log_cosh: 0.0794 - val_loss: 0.0029 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0551 - val_within_eps_0_05: 0.1382 - val_within_eps_0_1: 0.2730\n",
      "  -> val_loss(min) δ=0.01: 0.002726405161\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - log_cosh: 0.3209 - loss: 0.0141 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0093 - within_eps_0_02: 0.0187 - within_eps_0_05: 0.0470 - within_eps_0_1: 0.0935 - val_log_cosh: 0.0933 - val_loss: 0.0064 - val_within_eps_0_005: 0.0104 - val_within_eps_0_01: 0.0207 - val_within_eps_0_02: 0.0415 - val_within_eps_0_05: 0.1061 - val_within_eps_0_1: 0.2167\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.1436 - loss: 0.0089 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0141 - within_eps_0_02: 0.0284 - within_eps_0_05: 0.0707 - within_eps_0_1: 0.1411 - val_log_cosh: 0.0757 - val_loss: 0.0056 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0255 - val_within_eps_0_02: 0.0506 - val_within_eps_0_05: 0.1265 - val_within_eps_0_1: 0.2495\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0620 - loss: 0.0055 - within_eps_0_005: 0.0112 - within_eps_0_01: 0.0225 - within_eps_0_02: 0.0451 - within_eps_0_05: 0.1122 - within_eps_0_1: 0.2224 - val_log_cosh: 0.0825 - val_loss: 0.0059 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0523 - val_within_eps_0_05: 0.1277 - val_within_eps_0_1: 0.2485\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0233 - loss: 0.0032 - within_eps_0_005: 0.0194 - within_eps_0_01: 0.0385 - within_eps_0_02: 0.0768 - within_eps_0_05: 0.1900 - within_eps_0_1: 0.3682 - val_log_cosh: 0.0799 - val_loss: 0.0058 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0270 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1326 - val_within_eps_0_1: 0.2565\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0084 - loss: 0.0018 - within_eps_0_005: 0.0332 - within_eps_0_01: 0.0660 - within_eps_0_02: 0.1316 - within_eps_0_05: 0.3196 - within_eps_0_1: 0.5840 - val_log_cosh: 0.0696 - val_loss: 0.0053 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0566 - val_within_eps_0_05: 0.1393 - val_within_eps_0_1: 0.2721\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0047 - loss: 0.0013 - within_eps_0_005: 0.0449 - within_eps_0_01: 0.0896 - within_eps_0_02: 0.1774 - within_eps_0_05: 0.4221 - within_eps_0_1: 0.7230 - val_log_cosh: 0.0722 - val_loss: 0.0055 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0595 - val_within_eps_0_05: 0.1486 - val_within_eps_0_1: 0.2891\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0040 - loss: 0.0012 - within_eps_0_005: 0.0488 - within_eps_0_01: 0.0975 - within_eps_0_02: 0.1936 - within_eps_0_05: 0.4553 - within_eps_0_1: 0.7621 - val_log_cosh: 0.0715 - val_loss: 0.0054 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0630 - val_within_eps_0_05: 0.1564 - val_within_eps_0_1: 0.2993\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0032 - loss: 0.0010 - within_eps_0_005: 0.0564 - within_eps_0_01: 0.1125 - within_eps_0_02: 0.2228 - within_eps_0_05: 0.5128 - within_eps_0_1: 0.8142 - val_log_cosh: 0.0798 - val_loss: 0.0059 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0623 - val_within_eps_0_05: 0.1493 - val_within_eps_0_1: 0.2628\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0031 - loss: 0.0010 - within_eps_0_005: 0.0574 - within_eps_0_01: 0.1139 - within_eps_0_02: 0.2247 - within_eps_0_05: 0.5172 - within_eps_0_1: 0.8191 - val_log_cosh: 0.0754 - val_loss: 0.0057 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0528 - val_within_eps_0_05: 0.1322 - val_within_eps_0_1: 0.2553\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0027 - loss: 9.3417e-04 - within_eps_0_005: 0.0625 - within_eps_0_01: 0.1246 - within_eps_0_02: 0.2457 - within_eps_0_05: 0.5546 - within_eps_0_1: 0.8455 - val_log_cosh: 0.0764 - val_loss: 0.0057 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0292 - val_within_eps_0_02: 0.0581 - val_within_eps_0_05: 0.1402 - val_within_eps_0_1: 0.2619\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0025 - loss: 8.9893e-04 - within_eps_0_005: 0.0644 - within_eps_0_01: 0.1281 - within_eps_0_02: 0.2519 - within_eps_0_05: 0.5681 - within_eps_0_1: 0.8572 - val_log_cosh: 0.0781 - val_loss: 0.0058 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0528 - val_within_eps_0_05: 0.1321 - val_within_eps_0_1: 0.2537\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0024 - loss: 8.8072e-04 - within_eps_0_005: 0.0654 - within_eps_0_01: 0.1302 - within_eps_0_02: 0.2562 - within_eps_0_05: 0.5763 - within_eps_0_1: 0.8627 - val_log_cosh: 0.0754 - val_loss: 0.0057 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0292 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1458 - val_within_eps_0_1: 0.2734\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0024 - loss: 8.7330e-04 - within_eps_0_005: 0.0659 - within_eps_0_01: 0.1314 - within_eps_0_02: 0.2585 - within_eps_0_05: 0.5807 - within_eps_0_1: 0.8650 - val_log_cosh: 0.0753 - val_loss: 0.0056 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0278 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1395 - val_within_eps_0_1: 0.2667\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - log_cosh: 0.0024 - loss: 8.5845e-04 - within_eps_0_005: 0.0669 - within_eps_0_01: 0.1331 - within_eps_0_02: 0.2619 - within_eps_0_05: 0.5864 - within_eps_0_1: 0.8705 - val_log_cosh: 0.0753 - val_loss: 0.0056 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0529 - val_within_eps_0_05: 0.1337 - val_within_eps_0_1: 0.2733\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0023 - loss: 8.3992e-04 - within_eps_0_005: 0.0678 - within_eps_0_01: 0.1354 - within_eps_0_02: 0.2660 - within_eps_0_05: 0.5938 - within_eps_0_1: 0.8764 - val_log_cosh: 0.0786 - val_loss: 0.0058 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0531 - val_within_eps_0_05: 0.1347 - val_within_eps_0_1: 0.2639\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0021 - loss: 7.8640e-04 - within_eps_0_005: 0.0743 - within_eps_0_01: 0.1475 - within_eps_0_02: 0.2875 - within_eps_0_05: 0.6228 - within_eps_0_1: 0.8890 - val_log_cosh: 0.0804 - val_loss: 0.0059 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0246 - val_within_eps_0_02: 0.0496 - val_within_eps_0_05: 0.1236 - val_within_eps_0_1: 0.2477\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0020 - loss: 7.6134e-04 - within_eps_0_005: 0.0766 - within_eps_0_01: 0.1523 - within_eps_0_02: 0.2967 - within_eps_0_05: 0.6358 - within_eps_0_1: 0.8961 - val_log_cosh: 0.0781 - val_loss: 0.0058 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1356 - val_within_eps_0_1: 0.2585\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0019 - loss: 7.3740e-04 - within_eps_0_005: 0.0776 - within_eps_0_01: 0.1541 - within_eps_0_02: 0.3012 - within_eps_0_05: 0.6468 - within_eps_0_1: 0.9041 - val_log_cosh: 0.0841 - val_loss: 0.0060 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1305 - val_within_eps_0_1: 0.2516\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0019 - loss: 7.5492e-04 - within_eps_0_005: 0.0755 - within_eps_0_01: 0.1497 - within_eps_0_02: 0.2933 - within_eps_0_05: 0.6360 - within_eps_0_1: 0.9010 - val_log_cosh: 0.0829 - val_loss: 0.0060 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0230 - val_within_eps_0_02: 0.0456 - val_within_eps_0_05: 0.1167 - val_within_eps_0_1: 0.2391\n",
      "Epoch 20/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0018 - loss: 7.1753e-04 - within_eps_0_005: 0.0800 - within_eps_0_01: 0.1595 - within_eps_0_02: 0.3104 - within_eps_0_05: 0.6571 - within_eps_0_1: 0.9082 - val_log_cosh: 0.0804 - val_loss: 0.0059 - val_within_eps_0_005: 0.0109 - val_within_eps_0_01: 0.0219 - val_within_eps_0_02: 0.0444 - val_within_eps_0_05: 0.1144 - val_within_eps_0_1: 0.2364\n",
      "  -> val_loss(min) δ=0.02: 0.005330707412\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - log_cosh: 0.3247 - loss: 0.0348 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0094 - within_eps_0_02: 0.0188 - within_eps_0_05: 0.0469 - within_eps_0_1: 0.0931 - val_log_cosh: 0.0860 - val_loss: 0.0145 - val_within_eps_0_005: 0.0105 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0425 - val_within_eps_0_05: 0.1085 - val_within_eps_0_1: 0.2164\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.1426 - loss: 0.0214 - within_eps_0_005: 0.0071 - within_eps_0_01: 0.0142 - within_eps_0_02: 0.0284 - within_eps_0_05: 0.0711 - within_eps_0_1: 0.1416 - val_log_cosh: 0.0911 - val_loss: 0.0149 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0486 - val_within_eps_0_05: 0.1240 - val_within_eps_0_1: 0.2404\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0630 - loss: 0.0133 - within_eps_0_005: 0.0111 - within_eps_0_01: 0.0224 - within_eps_0_02: 0.0448 - within_eps_0_05: 0.1117 - within_eps_0_1: 0.2211 - val_log_cosh: 0.0785 - val_loss: 0.0136 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1374 - val_within_eps_0_1: 0.2650\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0236 - loss: 0.0075 - within_eps_0_005: 0.0192 - within_eps_0_01: 0.0384 - within_eps_0_02: 0.0767 - within_eps_0_05: 0.1890 - within_eps_0_1: 0.3664 - val_log_cosh: 0.0844 - val_loss: 0.0144 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0571 - val_within_eps_0_05: 0.1393 - val_within_eps_0_1: 0.2638\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - log_cosh: 0.0080 - loss: 0.0038 - within_eps_0_005: 0.0339 - within_eps_0_01: 0.0677 - within_eps_0_02: 0.1352 - within_eps_0_05: 0.3280 - within_eps_0_1: 0.5973 - val_log_cosh: 0.0866 - val_loss: 0.0150 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0239 - val_within_eps_0_02: 0.0473 - val_within_eps_0_05: 0.1192 - val_within_eps_0_1: 0.2311\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0041 - loss: 0.0025 - within_eps_0_005: 0.0481 - within_eps_0_01: 0.0959 - within_eps_0_02: 0.1913 - within_eps_0_05: 0.4510 - within_eps_0_1: 0.7554 - val_log_cosh: 0.0976 - val_loss: 0.0162 - val_within_eps_0_005: 0.0119 - val_within_eps_0_01: 0.0235 - val_within_eps_0_02: 0.0472 - val_within_eps_0_05: 0.1163 - val_within_eps_0_1: 0.2244\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0036 - loss: 0.0022 - within_eps_0_005: 0.0515 - within_eps_0_01: 0.1033 - within_eps_0_02: 0.2047 - within_eps_0_05: 0.4791 - within_eps_0_1: 0.7864 - val_log_cosh: 0.0929 - val_loss: 0.0159 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0200 - val_within_eps_0_02: 0.0399 - val_within_eps_0_05: 0.1002 - val_within_eps_0_1: 0.2062\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0029 - loss: 0.0019 - within_eps_0_005: 0.0590 - within_eps_0_01: 0.1176 - within_eps_0_02: 0.2319 - within_eps_0_05: 0.5317 - within_eps_0_1: 0.8311 - val_log_cosh: 0.0820 - val_loss: 0.0145 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0264 - val_within_eps_0_02: 0.0524 - val_within_eps_0_05: 0.1270 - val_within_eps_0_1: 0.2379\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0026 - loss: 0.0018 - within_eps_0_005: 0.0627 - within_eps_0_01: 0.1241 - within_eps_0_02: 0.2445 - within_eps_0_05: 0.5549 - within_eps_0_1: 0.8502 - val_log_cosh: 0.1016 - val_loss: 0.0167 - val_within_eps_0_005: 0.0107 - val_within_eps_0_01: 0.0210 - val_within_eps_0_02: 0.0412 - val_within_eps_0_05: 0.1041 - val_within_eps_0_1: 0.2055\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0026 - loss: 0.0018 - within_eps_0_005: 0.0617 - within_eps_0_01: 0.1225 - within_eps_0_02: 0.2412 - within_eps_0_05: 0.5509 - within_eps_0_1: 0.8498 - val_log_cosh: 0.0912 - val_loss: 0.0156 - val_within_eps_0_005: 0.0092 - val_within_eps_0_01: 0.0183 - val_within_eps_0_02: 0.0378 - val_within_eps_0_05: 0.0997 - val_within_eps_0_1: 0.2112\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0023 - loss: 0.0016 - within_eps_0_005: 0.0685 - within_eps_0_01: 0.1365 - within_eps_0_02: 0.2675 - within_eps_0_05: 0.5942 - within_eps_0_1: 0.8760 - val_log_cosh: 0.0874 - val_loss: 0.0150 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0515 - val_within_eps_0_05: 0.1286 - val_within_eps_0_1: 0.2405\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0021 - loss: 0.0015 - within_eps_0_005: 0.0705 - within_eps_0_01: 0.1403 - within_eps_0_02: 0.2752 - within_eps_0_05: 0.6074 - within_eps_0_1: 0.8846 - val_log_cosh: 0.0747 - val_loss: 0.0133 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0323 - val_within_eps_0_02: 0.0640 - val_within_eps_0_05: 0.1496 - val_within_eps_0_1: 0.2746\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0021 - loss: 0.0015 - within_eps_0_005: 0.0705 - within_eps_0_01: 0.1400 - within_eps_0_02: 0.2753 - within_eps_0_05: 0.6081 - within_eps_0_1: 0.8860 - val_log_cosh: 0.0874 - val_loss: 0.0150 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0533 - val_within_eps_0_05: 0.1320 - val_within_eps_0_1: 0.2473\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0019 - loss: 0.0014 - within_eps_0_005: 0.0752 - within_eps_0_01: 0.1500 - within_eps_0_02: 0.2936 - within_eps_0_05: 0.6367 - within_eps_0_1: 0.9010 - val_log_cosh: 0.0868 - val_loss: 0.0149 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0504 - val_within_eps_0_05: 0.1280 - val_within_eps_0_1: 0.2483\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0018 - loss: 0.0013 - within_eps_0_005: 0.0775 - within_eps_0_01: 0.1537 - within_eps_0_02: 0.3003 - within_eps_0_05: 0.6451 - within_eps_0_1: 0.9066 - val_log_cosh: 0.0919 - val_loss: 0.0156 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0242 - val_within_eps_0_02: 0.0481 - val_within_eps_0_05: 0.1202 - val_within_eps_0_1: 0.2307\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0020 - loss: 0.0014 - within_eps_0_005: 0.0726 - within_eps_0_01: 0.1441 - within_eps_0_02: 0.2833 - within_eps_0_05: 0.6254 - within_eps_0_1: 0.8991 - val_log_cosh: 0.0826 - val_loss: 0.0144 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0285 - val_within_eps_0_02: 0.0566 - val_within_eps_0_05: 0.1375 - val_within_eps_0_1: 0.2553\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0019 - loss: 0.0014 - within_eps_0_005: 0.0744 - within_eps_0_01: 0.1473 - within_eps_0_02: 0.2883 - within_eps_0_05: 0.6293 - within_eps_0_1: 0.9025 - val_log_cosh: 0.0826 - val_loss: 0.0143 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0298 - val_within_eps_0_02: 0.0586 - val_within_eps_0_05: 0.1395 - val_within_eps_0_1: 0.2659\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0017 - loss: 0.0013 - within_eps_0_005: 0.0798 - within_eps_0_01: 0.1584 - within_eps_0_02: 0.3083 - within_eps_0_05: 0.6590 - within_eps_0_1: 0.9143 - val_log_cosh: 0.0814 - val_loss: 0.0143 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0271 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1335 - val_within_eps_0_1: 0.2525\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0829 - within_eps_0_01: 0.1643 - within_eps_0_02: 0.3196 - within_eps_0_05: 0.6756 - within_eps_0_1: 0.9207 - val_log_cosh: 0.0922 - val_loss: 0.0157 - val_within_eps_0_005: 0.0109 - val_within_eps_0_01: 0.0217 - val_within_eps_0_02: 0.0438 - val_within_eps_0_05: 0.1107 - val_within_eps_0_1: 0.2188\n",
      "Epoch 20/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0831 - within_eps_0_01: 0.1646 - within_eps_0_02: 0.3211 - within_eps_0_05: 0.6816 - within_eps_0_1: 0.9263 - val_log_cosh: 0.0838 - val_loss: 0.0146 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0253 - val_within_eps_0_02: 0.0512 - val_within_eps_0_05: 0.1307 - val_within_eps_0_1: 0.2480\n",
      "Epoch 21/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0015 - loss: 0.0012 - within_eps_0_005: 0.0854 - within_eps_0_01: 0.1691 - within_eps_0_02: 0.3285 - within_eps_0_05: 0.6911 - within_eps_0_1: 0.9293 - val_log_cosh: 0.0927 - val_loss: 0.0155 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0526 - val_within_eps_0_05: 0.1320 - val_within_eps_0_1: 0.2393\n",
      "Epoch 22/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0015 - loss: 0.0011 - within_eps_0_005: 0.0889 - within_eps_0_01: 0.1764 - within_eps_0_02: 0.3411 - within_eps_0_05: 0.7059 - within_eps_0_1: 0.9346 - val_log_cosh: 0.0780 - val_loss: 0.0138 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0308 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1432 - val_within_eps_0_1: 0.2662\n",
      "Epoch 23/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0015 - loss: 0.0012 - within_eps_0_005: 0.0824 - within_eps_0_01: 0.1634 - within_eps_0_02: 0.3189 - within_eps_0_05: 0.6815 - within_eps_0_1: 0.9300 - val_log_cosh: 0.0922 - val_loss: 0.0155 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0244 - val_within_eps_0_02: 0.0488 - val_within_eps_0_05: 0.1217 - val_within_eps_0_1: 0.2335\n",
      "Epoch 24/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0015 - loss: 0.0011 - within_eps_0_005: 0.0847 - within_eps_0_01: 0.1686 - within_eps_0_02: 0.3276 - within_eps_0_05: 0.6905 - within_eps_0_1: 0.9315 - val_log_cosh: 0.0878 - val_loss: 0.0151 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0502 - val_within_eps_0_05: 0.1259 - val_within_eps_0_1: 0.2345\n",
      "Epoch 25/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0014 - loss: 0.0011 - within_eps_0_005: 0.0891 - within_eps_0_01: 0.1771 - within_eps_0_02: 0.3428 - within_eps_0_05: 0.7072 - within_eps_0_1: 0.9351 - val_log_cosh: 0.0910 - val_loss: 0.0155 - val_within_eps_0_005: 0.0126 - val_within_eps_0_01: 0.0254 - val_within_eps_0_02: 0.0504 - val_within_eps_0_05: 0.1216 - val_within_eps_0_1: 0.2293\n",
      "Epoch 26/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0014 - loss: 0.0010 - within_eps_0_005: 0.0930 - within_eps_0_01: 0.1846 - within_eps_0_02: 0.3549 - within_eps_0_05: 0.7197 - within_eps_0_1: 0.9407 - val_log_cosh: 0.0917 - val_loss: 0.0156 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0207 - val_within_eps_0_02: 0.0416 - val_within_eps_0_05: 0.1055 - val_within_eps_0_1: 0.2149\n",
      "Epoch 27/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0014 - loss: 0.0011 - within_eps_0_005: 0.0889 - within_eps_0_01: 0.1764 - within_eps_0_02: 0.3416 - within_eps_0_05: 0.7076 - within_eps_0_1: 0.9369 - val_log_cosh: 0.0891 - val_loss: 0.0153 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0223 - val_within_eps_0_02: 0.0448 - val_within_eps_0_05: 0.1162 - val_within_eps_0_1: 0.2288\n",
      "  -> val_loss(min) δ=0.05: 0.013284153305\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 65ms/step - log_cosh: 0.3196 - loss: 0.0667 - within_eps_0_005: 0.0046 - within_eps_0_01: 0.0093 - within_eps_0_02: 0.0186 - within_eps_0_05: 0.0465 - within_eps_0_1: 0.0929 - val_log_cosh: 0.1021 - val_loss: 0.0304 - val_within_eps_0_005: 0.0108 - val_within_eps_0_01: 0.0211 - val_within_eps_0_02: 0.0417 - val_within_eps_0_05: 0.1034 - val_within_eps_0_1: 0.2028\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - log_cosh: 0.1659 - loss: 0.0445 - within_eps_0_005: 0.0066 - within_eps_0_01: 0.0130 - within_eps_0_02: 0.0260 - within_eps_0_05: 0.0649 - within_eps_0_1: 0.1291 - val_log_cosh: 0.0863 - val_loss: 0.0267 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0231 - val_within_eps_0_02: 0.0461 - val_within_eps_0_05: 0.1154 - val_within_eps_0_1: 0.2302\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0896 - loss: 0.0303 - within_eps_0_005: 0.0093 - within_eps_0_01: 0.0187 - within_eps_0_02: 0.0372 - within_eps_0_05: 0.0925 - within_eps_0_1: 0.1837 - val_log_cosh: 0.0890 - val_loss: 0.0270 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0244 - val_within_eps_0_02: 0.0488 - val_within_eps_0_05: 0.1215 - val_within_eps_0_1: 0.2380\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0297 - loss: 0.0150 - within_eps_0_005: 0.0168 - within_eps_0_01: 0.0335 - within_eps_0_02: 0.0673 - within_eps_0_05: 0.1670 - within_eps_0_1: 0.3260 - val_log_cosh: 0.0896 - val_loss: 0.0268 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0540 - val_within_eps_0_05: 0.1372 - val_within_eps_0_1: 0.2691\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - log_cosh: 0.0092 - loss: 0.0066 - within_eps_0_005: 0.0316 - within_eps_0_01: 0.0631 - within_eps_0_02: 0.1253 - within_eps_0_05: 0.3055 - within_eps_0_1: 0.5629 - val_log_cosh: 0.0862 - val_loss: 0.0261 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0531 - val_within_eps_0_05: 0.1335 - val_within_eps_0_1: 0.2662\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0046 - loss: 0.0038 - within_eps_0_005: 0.0452 - within_eps_0_01: 0.0901 - within_eps_0_02: 0.1789 - within_eps_0_05: 0.4253 - within_eps_0_1: 0.7280 - val_log_cosh: 0.0964 - val_loss: 0.0283 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0244 - val_within_eps_0_02: 0.0486 - val_within_eps_0_05: 0.1254 - val_within_eps_0_1: 0.2627\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0036 - loss: 0.0032 - within_eps_0_005: 0.0517 - within_eps_0_01: 0.1035 - within_eps_0_02: 0.2042 - within_eps_0_05: 0.4780 - within_eps_0_1: 0.7832 - val_log_cosh: 0.0792 - val_loss: 0.0244 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0596 - val_within_eps_0_05: 0.1521 - val_within_eps_0_1: 0.2979\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0033 - loss: 0.0029 - within_eps_0_005: 0.0533 - within_eps_0_01: 0.1065 - within_eps_0_02: 0.2113 - within_eps_0_05: 0.4928 - within_eps_0_1: 0.8007 - val_log_cosh: 0.0969 - val_loss: 0.0292 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0565 - val_within_eps_0_05: 0.1337 - val_within_eps_0_1: 0.2463\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0030 - loss: 0.0026 - within_eps_0_005: 0.0585 - within_eps_0_01: 0.1164 - within_eps_0_02: 0.2298 - within_eps_0_05: 0.5276 - within_eps_0_1: 0.8270 - val_log_cosh: 0.1049 - val_loss: 0.0317 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0227 - val_within_eps_0_02: 0.0457 - val_within_eps_0_05: 0.1114 - val_within_eps_0_1: 0.2076\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0027 - loss: 0.0024 - within_eps_0_005: 0.0616 - within_eps_0_01: 0.1229 - within_eps_0_02: 0.2424 - within_eps_0_05: 0.5497 - within_eps_0_1: 0.8440 - val_log_cosh: 0.1128 - val_loss: 0.0343 - val_within_eps_0_005: 0.0058 - val_within_eps_0_01: 0.0115 - val_within_eps_0_02: 0.0235 - val_within_eps_0_05: 0.0643 - val_within_eps_0_1: 0.1472\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0027 - loss: 0.0024 - within_eps_0_005: 0.0609 - within_eps_0_01: 0.1212 - within_eps_0_02: 0.2398 - within_eps_0_05: 0.5494 - within_eps_0_1: 0.8471 - val_log_cosh: 0.1120 - val_loss: 0.0346 - val_within_eps_0_005: 0.0042 - val_within_eps_0_01: 0.0088 - val_within_eps_0_02: 0.0178 - val_within_eps_0_05: 0.0502 - val_within_eps_0_1: 0.1263\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0024 - loss: 0.0022 - within_eps_0_005: 0.0667 - within_eps_0_01: 0.1326 - within_eps_0_02: 0.2593 - within_eps_0_05: 0.5791 - within_eps_0_1: 0.8659 - val_log_cosh: 0.1084 - val_loss: 0.0336 - val_within_eps_0_005: 0.0055 - val_within_eps_0_01: 0.0109 - val_within_eps_0_02: 0.0223 - val_within_eps_0_05: 0.0604 - val_within_eps_0_1: 0.1414\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0022 - loss: 0.0021 - within_eps_0_005: 0.0685 - within_eps_0_01: 0.1366 - within_eps_0_02: 0.2681 - within_eps_0_05: 0.5952 - within_eps_0_1: 0.8765 - val_log_cosh: 0.0977 - val_loss: 0.0309 - val_within_eps_0_005: 0.0065 - val_within_eps_0_01: 0.0128 - val_within_eps_0_02: 0.0261 - val_within_eps_0_05: 0.0736 - val_within_eps_0_1: 0.1784\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0021 - loss: 0.0019 - within_eps_0_005: 0.0722 - within_eps_0_01: 0.1433 - within_eps_0_02: 0.2810 - within_eps_0_05: 0.6185 - within_eps_0_1: 0.8905 - val_log_cosh: 0.1026 - val_loss: 0.0323 - val_within_eps_0_005: 0.0066 - val_within_eps_0_01: 0.0130 - val_within_eps_0_02: 0.0261 - val_within_eps_0_05: 0.0692 - val_within_eps_0_1: 0.1610\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0021 - loss: 0.0019 - within_eps_0_005: 0.0709 - within_eps_0_01: 0.1410 - within_eps_0_02: 0.2759 - within_eps_0_05: 0.6082 - within_eps_0_1: 0.8863 - val_log_cosh: 0.1034 - val_loss: 0.0324 - val_within_eps_0_005: 0.0064 - val_within_eps_0_01: 0.0131 - val_within_eps_0_02: 0.0265 - val_within_eps_0_05: 0.0717 - val_within_eps_0_1: 0.1564\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0019 - loss: 0.0017 - within_eps_0_005: 0.0777 - within_eps_0_01: 0.1538 - within_eps_0_02: 0.2995 - within_eps_0_05: 0.6443 - within_eps_0_1: 0.9031 - val_log_cosh: 0.1005 - val_loss: 0.0315 - val_within_eps_0_005: 0.0075 - val_within_eps_0_01: 0.0151 - val_within_eps_0_02: 0.0305 - val_within_eps_0_05: 0.0817 - val_within_eps_0_1: 0.1751\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - log_cosh: 0.0019 - loss: 0.0017 - within_eps_0_005: 0.0762 - within_eps_0_01: 0.1515 - within_eps_0_02: 0.2962 - within_eps_0_05: 0.6401 - within_eps_0_1: 0.9047 - val_log_cosh: 0.1018 - val_loss: 0.0321 - val_within_eps_0_005: 0.0061 - val_within_eps_0_01: 0.0124 - val_within_eps_0_02: 0.0249 - val_within_eps_0_05: 0.0657 - val_within_eps_0_1: 0.1499\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0784 - within_eps_0_01: 0.1557 - within_eps_0_02: 0.3039 - within_eps_0_05: 0.6520 - within_eps_0_1: 0.9094 - val_log_cosh: 0.1070 - val_loss: 0.0335 - val_within_eps_0_005: 0.0060 - val_within_eps_0_01: 0.0119 - val_within_eps_0_02: 0.0238 - val_within_eps_0_05: 0.0630 - val_within_eps_0_1: 0.1378\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0800 - within_eps_0_01: 0.1586 - within_eps_0_02: 0.3079 - within_eps_0_05: 0.6557 - within_eps_0_1: 0.9101 - val_log_cosh: 0.1061 - val_loss: 0.0335 - val_within_eps_0_005: 0.0052 - val_within_eps_0_01: 0.0106 - val_within_eps_0_02: 0.0221 - val_within_eps_0_05: 0.0600 - val_within_eps_0_1: 0.1329\n",
      "Epoch 20/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0017 - loss: 0.0016 - within_eps_0_005: 0.0812 - within_eps_0_01: 0.1615 - within_eps_0_02: 0.3146 - within_eps_0_05: 0.6685 - within_eps_0_1: 0.9177 - val_log_cosh: 0.0947 - val_loss: 0.0304 - val_within_eps_0_005: 0.0076 - val_within_eps_0_01: 0.0154 - val_within_eps_0_02: 0.0312 - val_within_eps_0_05: 0.0829 - val_within_eps_0_1: 0.1796\n",
      "Epoch 21/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0017 - loss: 0.0016 - within_eps_0_005: 0.0797 - within_eps_0_01: 0.1583 - within_eps_0_02: 0.3093 - within_eps_0_05: 0.6607 - within_eps_0_1: 0.9147 - val_log_cosh: 0.0933 - val_loss: 0.0297 - val_within_eps_0_005: 0.0086 - val_within_eps_0_01: 0.0174 - val_within_eps_0_02: 0.0356 - val_within_eps_0_05: 0.0935 - val_within_eps_0_1: 0.1918\n",
      "Epoch 22/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - log_cosh: 0.0016 - loss: 0.0015 - within_eps_0_005: 0.0817 - within_eps_0_01: 0.1622 - within_eps_0_02: 0.3157 - within_eps_0_05: 0.6709 - within_eps_0_1: 0.9212 - val_log_cosh: 0.1011 - val_loss: 0.0321 - val_within_eps_0_005: 0.0065 - val_within_eps_0_01: 0.0135 - val_within_eps_0_02: 0.0272 - val_within_eps_0_05: 0.0713 - val_within_eps_0_1: 0.1568\n",
      "  -> val_loss(min) δ=0.1: 0.024402048439\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - log_cosh: 0.3147 - loss: 0.1481 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0095 - within_eps_0_02: 0.0190 - within_eps_0_05: 0.0473 - within_eps_0_1: 0.0948 - val_log_cosh: 0.0781 - val_loss: 0.0488 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0500 - val_within_eps_0_05: 0.1237 - val_within_eps_0_1: 0.2402\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.1466 - loss: 0.0873 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0139 - within_eps_0_02: 0.0278 - within_eps_0_05: 0.0695 - within_eps_0_1: 0.1388 - val_log_cosh: 0.0911 - val_loss: 0.0553 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0250 - val_within_eps_0_02: 0.0500 - val_within_eps_0_05: 0.1236 - val_within_eps_0_1: 0.2348\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0661 - loss: 0.0486 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0216 - within_eps_0_02: 0.0437 - within_eps_0_05: 0.1091 - within_eps_0_1: 0.2156 - val_log_cosh: 0.0811 - val_loss: 0.0495 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0535 - val_within_eps_0_05: 0.1318 - val_within_eps_0_1: 0.2566\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - log_cosh: 0.0230 - loss: 0.0207 - within_eps_0_005: 0.0193 - within_eps_0_01: 0.0387 - within_eps_0_02: 0.0771 - within_eps_0_05: 0.1908 - within_eps_0_1: 0.3693 - val_log_cosh: 0.0999 - val_loss: 0.0593 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0222 - val_within_eps_0_02: 0.0450 - val_within_eps_0_05: 0.1157 - val_within_eps_0_1: 0.2326\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - log_cosh: 0.0081 - loss: 0.0080 - within_eps_0_005: 0.0330 - within_eps_0_01: 0.0659 - within_eps_0_02: 0.1318 - within_eps_0_05: 0.3206 - within_eps_0_1: 0.5872 - val_log_cosh: 0.0959 - val_loss: 0.0573 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0502 - val_within_eps_0_05: 0.1295 - val_within_eps_0_1: 0.2536\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0046 - loss: 0.0046 - within_eps_0_005: 0.0447 - within_eps_0_01: 0.0891 - within_eps_0_02: 0.1771 - within_eps_0_05: 0.4215 - within_eps_0_1: 0.7244 - val_log_cosh: 0.0976 - val_loss: 0.0583 - val_within_eps_0_005: 0.0108 - val_within_eps_0_01: 0.0219 - val_within_eps_0_02: 0.0437 - val_within_eps_0_05: 0.1141 - val_within_eps_0_1: 0.2430\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - log_cosh: 0.0036 - loss: 0.0036 - within_eps_0_005: 0.0503 - within_eps_0_01: 0.1010 - within_eps_0_02: 0.2009 - within_eps_0_05: 0.4718 - within_eps_0_1: 0.7800 - val_log_cosh: 0.0846 - val_loss: 0.0514 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0576 - val_within_eps_0_05: 0.1396 - val_within_eps_0_1: 0.2740\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - log_cosh: 0.0033 - loss: 0.0033 - within_eps_0_005: 0.0531 - within_eps_0_01: 0.1064 - within_eps_0_02: 0.2105 - within_eps_0_05: 0.4904 - within_eps_0_1: 0.7981 - val_log_cosh: 0.0974 - val_loss: 0.0587 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0246 - val_within_eps_0_02: 0.0489 - val_within_eps_0_05: 0.1222 - val_within_eps_0_1: 0.2499\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0030 - loss: 0.0030 - within_eps_0_005: 0.0565 - within_eps_0_01: 0.1132 - within_eps_0_02: 0.2235 - within_eps_0_05: 0.5168 - within_eps_0_1: 0.8192 - val_log_cosh: 0.0951 - val_loss: 0.0574 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0240 - val_within_eps_0_02: 0.0487 - val_within_eps_0_05: 0.1241 - val_within_eps_0_1: 0.2523\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0028 - loss: 0.0028 - within_eps_0_005: 0.0587 - within_eps_0_01: 0.1167 - within_eps_0_02: 0.2303 - within_eps_0_05: 0.5297 - within_eps_0_1: 0.8337 - val_log_cosh: 0.0937 - val_loss: 0.0567 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0237 - val_within_eps_0_02: 0.0484 - val_within_eps_0_05: 0.1248 - val_within_eps_0_1: 0.2525\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - log_cosh: 0.0027 - loss: 0.0027 - within_eps_0_005: 0.0598 - within_eps_0_01: 0.1193 - within_eps_0_02: 0.2355 - within_eps_0_05: 0.5404 - within_eps_0_1: 0.8411 - val_log_cosh: 0.0930 - val_loss: 0.0562 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0271 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1286 - val_within_eps_0_1: 0.2559\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0026 - loss: 0.0026 - within_eps_0_005: 0.0615 - within_eps_0_01: 0.1231 - within_eps_0_02: 0.2425 - within_eps_0_05: 0.5525 - within_eps_0_1: 0.8505 - val_log_cosh: 0.0878 - val_loss: 0.0534 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0254 - val_within_eps_0_02: 0.0512 - val_within_eps_0_05: 0.1330 - val_within_eps_0_1: 0.2663\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0025 - loss: 0.0025 - within_eps_0_005: 0.0639 - within_eps_0_01: 0.1276 - within_eps_0_02: 0.2517 - within_eps_0_05: 0.5669 - within_eps_0_1: 0.8576 - val_log_cosh: 0.0900 - val_loss: 0.0545 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0246 - val_within_eps_0_02: 0.0489 - val_within_eps_0_05: 0.1262 - val_within_eps_0_1: 0.2611\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0023 - loss: 0.0023 - within_eps_0_005: 0.0661 - within_eps_0_01: 0.1312 - within_eps_0_02: 0.2582 - within_eps_0_05: 0.5791 - within_eps_0_1: 0.8689 - val_log_cosh: 0.0903 - val_loss: 0.0546 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0236 - val_within_eps_0_02: 0.0472 - val_within_eps_0_05: 0.1254 - val_within_eps_0_1: 0.2620\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0671 - within_eps_0_01: 0.1331 - within_eps_0_02: 0.2619 - within_eps_0_05: 0.5877 - within_eps_0_1: 0.8751 - val_log_cosh: 0.0865 - val_loss: 0.0530 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0575 - val_within_eps_0_05: 0.1465 - val_within_eps_0_1: 0.2894\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0677 - within_eps_0_01: 0.1350 - within_eps_0_02: 0.2644 - within_eps_0_05: 0.5909 - within_eps_0_1: 0.8802 - val_log_cosh: 0.0895 - val_loss: 0.0545 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0632 - val_within_eps_0_05: 0.1496 - val_within_eps_0_1: 0.2693\n",
      "  -> val_loss(min) δ=0.25: 0.048839326948\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - log_cosh: 0.3091 - loss: 0.2445 - within_eps_0_005: 0.0048 - within_eps_0_01: 0.0096 - within_eps_0_02: 0.0192 - within_eps_0_05: 0.0478 - within_eps_0_1: 0.0956 - val_log_cosh: 0.0837 - val_loss: 0.0733 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0243 - val_within_eps_0_02: 0.0488 - val_within_eps_0_05: 0.1190 - val_within_eps_0_1: 0.2325\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - log_cosh: 0.1461 - loss: 0.1323 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0140 - within_eps_0_02: 0.0280 - within_eps_0_05: 0.0700 - within_eps_0_1: 0.1396 - val_log_cosh: 0.0915 - val_loss: 0.0807 - val_within_eps_0_005: 0.0108 - val_within_eps_0_01: 0.0215 - val_within_eps_0_02: 0.0427 - val_within_eps_0_05: 0.1072 - val_within_eps_0_1: 0.2134\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - log_cosh: 0.0614 - loss: 0.0608 - within_eps_0_005: 0.0114 - within_eps_0_01: 0.0230 - within_eps_0_02: 0.0458 - within_eps_0_05: 0.1140 - within_eps_0_1: 0.2247 - val_log_cosh: 0.0821 - val_loss: 0.0719 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0264 - val_within_eps_0_02: 0.0527 - val_within_eps_0_05: 0.1312 - val_within_eps_0_1: 0.2551\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - log_cosh: 0.0225 - loss: 0.0229 - within_eps_0_005: 0.0192 - within_eps_0_01: 0.0384 - within_eps_0_02: 0.0771 - within_eps_0_05: 0.1906 - within_eps_0_1: 0.3701 - val_log_cosh: 0.0972 - val_loss: 0.0852 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0247 - val_within_eps_0_02: 0.0479 - val_within_eps_0_05: 0.1179 - val_within_eps_0_1: 0.2248\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - log_cosh: 0.0097 - loss: 0.0098 - within_eps_0_005: 0.0297 - within_eps_0_01: 0.0595 - within_eps_0_02: 0.1184 - within_eps_0_05: 0.2901 - within_eps_0_1: 0.5399 - val_log_cosh: 0.0812 - val_loss: 0.0708 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0269 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1336 - val_within_eps_0_1: 0.2671\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - log_cosh: 0.0054 - loss: 0.0055 - within_eps_0_005: 0.0402 - within_eps_0_01: 0.0803 - within_eps_0_02: 0.1601 - within_eps_0_05: 0.3857 - within_eps_0_1: 0.6808 - val_log_cosh: 0.0830 - val_loss: 0.0726 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0225 - val_within_eps_0_02: 0.0456 - val_within_eps_0_05: 0.1216 - val_within_eps_0_1: 0.2550\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - log_cosh: 0.0042 - loss: 0.0042 - within_eps_0_005: 0.0470 - within_eps_0_01: 0.0935 - within_eps_0_02: 0.1863 - within_eps_0_05: 0.4411 - within_eps_0_1: 0.7475 - val_log_cosh: 0.0941 - val_loss: 0.0826 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0222 - val_within_eps_0_02: 0.0450 - val_within_eps_0_05: 0.1205 - val_within_eps_0_1: 0.2463\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0036 - loss: 0.0036 - within_eps_0_005: 0.0517 - within_eps_0_01: 0.1030 - within_eps_0_02: 0.2035 - within_eps_0_05: 0.4775 - within_eps_0_1: 0.7845 - val_log_cosh: 0.0888 - val_loss: 0.0780 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0247 - val_within_eps_0_02: 0.0475 - val_within_eps_0_05: 0.1109 - val_within_eps_0_1: 0.2269\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - log_cosh: 0.0034 - loss: 0.0034 - within_eps_0_005: 0.0526 - within_eps_0_01: 0.1045 - within_eps_0_02: 0.2073 - within_eps_0_05: 0.4852 - within_eps_0_1: 0.7937 - val_log_cosh: 0.1061 - val_loss: 0.0931 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0202 - val_within_eps_0_02: 0.0408 - val_within_eps_0_05: 0.1088 - val_within_eps_0_1: 0.2266\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - log_cosh: 0.0031 - loss: 0.0032 - within_eps_0_005: 0.0551 - within_eps_0_01: 0.1103 - within_eps_0_02: 0.2178 - within_eps_0_05: 0.5054 - within_eps_0_1: 0.8120 - val_log_cosh: 0.0871 - val_loss: 0.0767 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1355 - val_within_eps_0_1: 0.2615\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0029 - loss: 0.0029 - within_eps_0_005: 0.0579 - within_eps_0_01: 0.1155 - within_eps_0_02: 0.2270 - within_eps_0_05: 0.5222 - within_eps_0_1: 0.8259 - val_log_cosh: 0.0926 - val_loss: 0.0812 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0227 - val_within_eps_0_02: 0.0460 - val_within_eps_0_05: 0.1152 - val_within_eps_0_1: 0.2352\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0027 - loss: 0.0027 - within_eps_0_005: 0.0600 - within_eps_0_01: 0.1193 - within_eps_0_02: 0.2353 - within_eps_0_05: 0.5395 - within_eps_0_1: 0.8407 - val_log_cosh: 0.0976 - val_loss: 0.0858 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0530 - val_within_eps_0_05: 0.1289 - val_within_eps_0_1: 0.2424\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - log_cosh: 0.0026 - loss: 0.0026 - within_eps_0_005: 0.0616 - within_eps_0_01: 0.1220 - within_eps_0_02: 0.2414 - within_eps_0_05: 0.5513 - within_eps_0_1: 0.8489 - val_log_cosh: 0.0929 - val_loss: 0.0815 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0491 - val_within_eps_0_05: 0.1221 - val_within_eps_0_1: 0.2456\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0025 - loss: 0.0025 - within_eps_0_005: 0.0639 - within_eps_0_01: 0.1268 - within_eps_0_02: 0.2497 - within_eps_0_05: 0.5659 - within_eps_0_1: 0.8612 - val_log_cosh: 0.0947 - val_loss: 0.0832 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0242 - val_within_eps_0_02: 0.0486 - val_within_eps_0_05: 0.1211 - val_within_eps_0_1: 0.2370\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - log_cosh: 0.0024 - loss: 0.0024 - within_eps_0_005: 0.0656 - within_eps_0_01: 0.1304 - within_eps_0_02: 0.2569 - within_eps_0_05: 0.5784 - within_eps_0_1: 0.8675 - val_log_cosh: 0.1182 - val_loss: 0.1043 - val_within_eps_0_005: 0.0098 - val_within_eps_0_01: 0.0197 - val_within_eps_0_02: 0.0398 - val_within_eps_0_05: 0.0983 - val_within_eps_0_1: 0.1803\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - log_cosh: 0.0026 - loss: 0.0026 - within_eps_0_005: 0.0613 - within_eps_0_01: 0.1223 - within_eps_0_02: 0.2404 - within_eps_0_05: 0.5486 - within_eps_0_1: 0.8488 - val_log_cosh: 0.0929 - val_loss: 0.0816 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0243 - val_within_eps_0_02: 0.0495 - val_within_eps_0_05: 0.1235 - val_within_eps_0_1: 0.2441\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - log_cosh: 0.0022 - loss: 0.0022 - within_eps_0_005: 0.0678 - within_eps_0_01: 0.1349 - within_eps_0_02: 0.2651 - within_eps_0_05: 0.5923 - within_eps_0_1: 0.8789 - val_log_cosh: 0.1160 - val_loss: 0.1030 - val_within_eps_0_005: 0.0104 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0423 - val_within_eps_0_05: 0.0996 - val_within_eps_0_1: 0.1775\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - log_cosh: 0.0026 - loss: 0.0027 - within_eps_0_005: 0.0586 - within_eps_0_01: 0.1171 - within_eps_0_02: 0.2312 - within_eps_0_05: 0.5343 - within_eps_0_1: 0.8434 - val_log_cosh: 0.1129 - val_loss: 0.1010 - val_within_eps_0_005: 0.0091 - val_within_eps_0_01: 0.0181 - val_within_eps_0_02: 0.0365 - val_within_eps_0_05: 0.0877 - val_within_eps_0_1: 0.1698\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - log_cosh: 0.0020 - loss: 0.0020 - within_eps_0_005: 0.0714 - within_eps_0_01: 0.1427 - within_eps_0_02: 0.2798 - within_eps_0_05: 0.6171 - within_eps_0_1: 0.8925 - val_log_cosh: 0.1096 - val_loss: 0.0977 - val_within_eps_0_005: 0.0092 - val_within_eps_0_01: 0.0183 - val_within_eps_0_02: 0.0369 - val_within_eps_0_05: 0.0929 - val_within_eps_0_1: 0.1854\n",
      "Epoch 20/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - log_cosh: 0.0020 - loss: 0.0020 - within_eps_0_005: 0.0733 - within_eps_0_01: 0.1461 - within_eps_0_02: 0.2864 - within_eps_0_05: 0.6242 - within_eps_0_1: 0.8962 - val_log_cosh: 0.1174 - val_loss: 0.1050 - val_within_eps_0_005: 0.0074 - val_within_eps_0_01: 0.0149 - val_within_eps_0_02: 0.0305 - val_within_eps_0_05: 0.0838 - val_within_eps_0_1: 0.1652\n",
      "  -> val_loss(min) δ=0.5: 0.070799596608\n",
      "\n",
      "Tabla val_loss(min) por δ (orden asc):\n",
      "  δ=0.01: 0.002726405161\n",
      "  δ=0.02: 0.005330707412\n",
      "  δ=0.05: 0.013284153305\n",
      "  δ= 0.1: 0.024402048439\n",
      "  δ=0.25: 0.048839326948\n",
      "  δ= 0.5: 0.070799596608\n",
      "\n",
      ">>> Mejor δ por tu regla: 0.01 (val_loss=0.002726405161)\n",
      "\n",
      "Resultados TEST - Escenario L (CNN)\n",
      "  loss (Huber):              0.020478\n",
      "  log_cosh:                  1.636242\n",
      "  within_eps_0_005          : 0.003574\n",
      "  within_eps_0_01           : 0.007167\n",
      "  within_eps_0_02           : 0.014708\n",
      "  within_eps_0_05           : 0.037784\n",
      "  within_eps_0_1            : 0.077366\n",
      "  AUTC[0.005–0.100]:         0.040025\n",
      "\n",
      "=== Mejor delta por escenario (CNN) ===\n",
      "  S: 0.01  -> ./models_cnn_huber_sweep/cnn_huber_w20_h1_delta0_01_S.keras\n",
      "  M: 0.01  -> ./models_cnn_huber_sweep/cnn_huber_w60_h5_delta0_01_M.keras\n",
      "  L: 0.01  -> ./models_cnn_huber_sweep/cnn_huber_w120_h20_delta0_01_L.keras\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CNN + Huber (sweep delta)\n",
    "# Selección de δ basada en métrica común: val_log_cosh\n",
    "# Grid de δ calibrado con cuantiles de |e| (baseline persistencia) en VAL\n",
    "# =========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import List, Tuple\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, Dropout, Dense, Reshape, LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ---------- Scaler único (MinMax) ----------\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    from joblib import load\n",
    "    scaler = load(\"scaler_modelos.joblib\")\n",
    "\n",
    "# ---------- Config ----------\n",
    "MODEL_DIR = \"./models_cnn_huber_sweep\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# EPS para métricas within (escala normalizada [0,1])\n",
    "EPS_LIST = [0.005, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def infer_shapes_from_dataset(ds: tf.data.Dataset) -> Tuple[int, int, int]:\n",
    "    for xb, yb in ds.take(1):\n",
    "        w = int(xb.shape[1])\n",
    "        f = int(xb.shape[2])\n",
    "        h = int(yb.shape[1])\n",
    "        return w, f, h\n",
    "    raise ValueError(\"Dataset vacío\")\n",
    "\n",
    "def _eps_tag(x: float) -> str:\n",
    "    s = f\"{x:.10g}\"\n",
    "    s = s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "    return s.replace('.', '_')\n",
    "\n",
    "# ---------- Métricas ----------\n",
    "def log_cosh_metric(y_true, y_pred):\n",
    "    e = tf.cast(y_pred, tf.float32) - tf.cast(y_true, tf.float32)\n",
    "    ae = tf.abs(e)\n",
    "    return tf.reduce_mean(ae + tf.nn.softplus(-2.0 * ae) - tf.math.log(2.0))\n",
    "log_cosh_metric.__name__ = \"log_cosh\"\n",
    "\n",
    "def make_within_eps_vector_metric(eps_vec: np.ndarray, tag: str):\n",
    "    eps_tf = tf.constant(eps_vec.astype(np.float32), dtype=tf.float32)  # (F,)\n",
    "    def within_eps(y_true, y_pred):\n",
    "        diff = tf.abs(tf.cast(y_pred, tf.float32) - tf.cast(y_true, tf.float32))  # (B,H,F)\n",
    "        thr  = eps_tf[tf.newaxis, tf.newaxis, :]\n",
    "        hit  = tf.cast(diff <= thr, tf.float32)\n",
    "        return tf.reduce_mean(hit)\n",
    "    within_eps.__name__ = tag\n",
    "    return within_eps\n",
    "\n",
    "def build_within_metrics_minmax(scaler, eps_list: List[float], n_features: int):\n",
    "    if not hasattr(scaler, \"data_range_\"):\n",
    "        raise ValueError(\"Se esperaba MinMaxScaler con data_range_.\")\n",
    "    if len(scaler.data_range_) != n_features:\n",
    "        raise ValueError(\"scaler.data_range_ no coincide con n_features.\")\n",
    "    metrics = [log_cosh_metric]\n",
    "    for e in eps_list:\n",
    "        eps_vec = np.full((n_features,), float(e), dtype=np.float32)\n",
    "        tag = f\"within_eps_{_eps_tag(e)}\"\n",
    "        metrics.append(make_within_eps_vector_metric(eps_vec, tag))\n",
    "    return metrics\n",
    "\n",
    "def compute_autc_from_results(res: dict, eps_list: List[float]) -> float:\n",
    "    eps = np.array(sorted(eps_list), dtype=np.float32)\n",
    "    acc = np.array([res.get(f\"within_eps_{_eps_tag(e)}\", np.nan) for e in eps], dtype=np.float32)\n",
    "    mask = np.isfinite(acc)\n",
    "    if mask.sum() < 2:\n",
    "        return float(\"nan\")\n",
    "    return float(np.trapz(acc[mask], eps[mask]) / (eps[mask][-1] - eps[mask][0]))\n",
    "\n",
    "# ---------- Modelo CNN (sin Flatten; Reshape explícito) ----------\n",
    "def build_cnn_point_model(window: int, n_features: int, horizon: int,\n",
    "                          f1: int = 128, k1: int = 5, d1: float = 0.2,\n",
    "                          f2: int = 64,  k2: int = 3, d2: float = 0.2) -> Model:\n",
    "    \"\"\"\n",
    "    Conv1D causal -> LN -> Dropout -> Conv1D causal -> LN -> Dropout\n",
    "    -> Reshape((window*f2,)) -> Dense(horizon*n_features) -> Reshape((horizon, n_features))\n",
    "    \"\"\"\n",
    "    inp = Input(shape=(window, n_features))\n",
    "    x = Conv1D(f1, k1, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(d1)(x)\n",
    "\n",
    "    x = Conv1D(f2, k2, padding=\"causal\", activation=\"relu\")(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(d2)(x)\n",
    "\n",
    "    x = Reshape((window * f2,))(x)\n",
    "    x = Dense(horizon * n_features)(x)\n",
    "    out = Reshape((horizon, n_features))(x)\n",
    "    return Model(inp, out, name=f\"CNN_POINT_H{horizon}_F{n_features}\")\n",
    "\n",
    "# ---------- Pérdida Huber ----------\n",
    "def make_huber_loss(delta: float):\n",
    "    base = tf.keras.losses.Huber(delta=float(delta))\n",
    "    def huber_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32); y_pred = tf.cast(y_pred, tf.float32)\n",
    "        return base(y_true, y_pred)\n",
    "    huber_loss.__name__ = f\"huber_delta_{_eps_tag(delta)}\"\n",
    "    return huber_loss\n",
    "\n",
    "# ---------- Calibración del grid de δ (cuantiles de |e| con baseline persistencia) ----------\n",
    "def estimate_error_quantiles_persistence(val_ds: tf.data.Dataset, max_batches: int = 256):\n",
    "    \"\"\"Cuantiles de |e| en VAL usando baseline de persistencia (y_hat = último paso repetido).\"\"\"\n",
    "    errs = []\n",
    "    taken = 0\n",
    "    for xb, yb in val_ds:\n",
    "        yhat = tf.repeat(xb[:, -1:, :], repeats=tf.shape(yb)[1], axis=1)  # (B,H,F)\n",
    "        e = tf.abs(tf.cast(yb, tf.float32) - tf.cast(yhat, tf.float32)).numpy().ravel()\n",
    "        errs.append(e)\n",
    "        taken += 1\n",
    "        if taken >= max_batches:\n",
    "            break\n",
    "    if not errs:\n",
    "        return [0.01, 0.02, 0.05, 0.1]\n",
    "    e = np.concatenate(errs)\n",
    "    qs = np.quantile(e, [0.5, 0.75, 0.9, 0.95])  # p50, p75, p90, p95\n",
    "    return list(qs)\n",
    "\n",
    "def build_delta_grid(val_ds: tf.data.Dataset):\n",
    "    base = [0.01, 0.02, 0.05, 0.1]\n",
    "    qs = estimate_error_quantiles_persistence(val_ds, max_batches=256)\n",
    "    cand = sorted(set(base + qs))\n",
    "    cand = [float(np.clip(c, 1e-4, 0.5)) for c in cand]\n",
    "    cand = sorted(set(cand))\n",
    "    print(\"\\nGrid δ (calibrado con cuantiles |e| en VAL):\", cand)\n",
    "    return cand\n",
    "\n",
    "# ---------- Entrenamiento para un δ (callbacks en val_log_cosh) ----------\n",
    "def train_for_delta(train_ds: tf.data.Dataset,\n",
    "                    val_ds: tf.data.Dataset,\n",
    "                    delta: float,\n",
    "                    scenario_tag: str,\n",
    "                    scaler) -> tuple[Model, float, str]:\n",
    "    w, f, h = infer_shapes_from_dataset(train_ds)\n",
    "    model = build_cnn_point_model(w, f, h)\n",
    "    metrics = build_within_metrics_minmax(scaler, EPS_LIST, n_features=f)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
    "        loss=make_huber_loss(delta),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    ckpt_path = os.path.join(\n",
    "        MODEL_DIR, f\"cnn_huber_w{w}_h{h}_delta{_eps_tag(delta)}{scenario_tag}.keras\"\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        EarlyStopping(monitor=\"val_log_cosh\", mode=\"min\", patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(ckpt_path, monitor=\"val_log_cosh\", mode=\"min\", save_best_only=True),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=160, callbacks=callbacks, verbose=1)\n",
    "    vlc = np.array(hist.history.get(\"val_log_cosh\", []), dtype=np.float32)\n",
    "    vlc = vlc[np.isfinite(vlc)]\n",
    "    best_val_logcosh = float(np.min(vlc)) if vlc.size > 0 else np.inf\n",
    "    return model, best_val_logcosh, ckpt_path\n",
    "\n",
    "# ---------- Barrido de deltas (selección por val_log_cosh) ----------\n",
    "def sweep_deltas(train_ds, val_ds, scenario_tag: str, scaler) -> tuple[Model, float, str]:\n",
    "    deltas = build_delta_grid(val_ds)\n",
    "    print(f\"\\n=== Barrido Huber delta {scenario_tag} (CNN) ===\")\n",
    "    results = []  # (delta, best_val_logcosh, ckpt_path)\n",
    "\n",
    "    best_score = np.inf; best_ckpt=None; best_delta=None; best_model=None\n",
    "    for d in deltas:\n",
    "        print(f\"\\n--- Entrenando δ={d} ---\")\n",
    "        model, val_logcosh, ckpt_path = train_for_delta(train_ds, val_ds, d, scenario_tag, scaler)\n",
    "        print(f\"  -> val_log_cosh(min) δ={d}: {val_logcosh:.12f}\")\n",
    "        results.append((d, val_logcosh, ckpt_path))\n",
    "        if val_logcosh < best_score:\n",
    "            best_score, best_ckpt, best_delta, best_model = val_logcosh, ckpt_path, d, model\n",
    "\n",
    "    if best_ckpt:\n",
    "        best_model = tf.keras.models.load_model(best_ckpt, compile=False)\n",
    "\n",
    "    results_sorted = sorted(results, key=lambda x: x[1])\n",
    "    print(\"\\nTabla val_log_cosh(min) por δ (orden asc):\")\n",
    "    for d, v, _ in results_sorted:\n",
    "        print(f\"  δ={d:>5}: {v:.12f}\")\n",
    "    print(f\"\\n>>> Mejor δ por val_log_cosh: {best_delta} (val_log_cosh={best_score:.12f})\")\n",
    "    return best_model, best_delta, best_ckpt\n",
    "\n",
    "# ---------- Evaluación en TEST ----------\n",
    "def evaluate_on_test(model: tf.keras.Model, ds: tf.data.Dataset, best_delta: float, scaler):\n",
    "    if (model is None) or (best_delta is None) or (not np.isfinite(best_delta)):\n",
    "        print(\"  [AVISO] No se pudo entrenar un modelo válido.\")\n",
    "        return\n",
    "    _, f, _ = infer_shapes_from_dataset(ds)\n",
    "    metrics = build_within_metrics_minmax(scaler, EPS_LIST, n_features=f)\n",
    "    model.compile(optimizer=\"adam\", loss=make_huber_loss(best_delta), metrics=metrics)\n",
    "\n",
    "    res = model.evaluate(ds, return_dict=True, verbose=0)\n",
    "    print(\"  loss (Huber):              {:.6f}\".format(res.get(\"loss\", float(\"nan\"))))\n",
    "    print(\"  log_cosh:                  {:.6f}\".format(res.get(\"log_cosh\", float(\"nan\"))))\n",
    "    for e in EPS_LIST:\n",
    "        key = f\"within_eps_{_eps_tag(e)}\"\n",
    "        print(f\"  {key:26s}: {res.get(key, float('nan')):.6f}\")\n",
    "    autc = compute_autc_from_results(res, EPS_LIST)\n",
    "    eps_min, eps_max = float(min(EPS_LIST)), float(max(EPS_LIST))\n",
    "    print(f\"  AUTC[{eps_min:.3f}–{eps_max:.3f}]:         {autc:.6f}\")\n",
    "\n",
    "# ================== EJECUCIÓN: TRES ESCENARIOS ==================\n",
    "# Usa tus datasets ya creados (sin shuffle en val/test):\n",
    "#   train_dss/val_dss/test_dss, train_dsm/val_dsm/test_dsm, train_dsl/val_dsl/test_dsl\n",
    "\n",
    "# Escenario S (20→1)\n",
    "model_s, delta_s, path_s = sweep_deltas(train_dss, val_dss, scenario_tag=\"_S\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario S (CNN)\")\n",
    "evaluate_on_test(model_s, test_dss, best_delta=delta_s, scaler=scaler)\n",
    "\n",
    "# Escenario M (60→5)\n",
    "model_m, delta_m, path_m = sweep_deltas(train_dsm, val_dsm, scenario_tag=\"_M\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario M (CNN)\")\n",
    "evaluate_on_test(model_m, test_dsm, best_delta=delta_m, scaler=scaler)\n",
    "\n",
    "# Escenario L (120→20)\n",
    "model_l, delta_l, path_l = sweep_deltas(train_dsl, val_dsl, scenario_tag=\"_L\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario L (CNN)\")\n",
    "evaluate_on_test(model_l, test_dsl, best_delta=delta_l, scaler=scaler)\n",
    "\n",
    "print(\"\\n=== Mejor δ por escenario (CNN, métrica común: val_log_cosh) ===\")\n",
    "print(f\"  S: {delta_s}  -> {path_s}\")\n",
    "print(f\"  M: {delta_m}  -> {path_m}\")\n",
    "print(f\"  L: {delta_l}  -> {path_l}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709940dd-ebc2-4b8c-927b-f0097086df01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
