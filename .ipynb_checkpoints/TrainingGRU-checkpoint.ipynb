{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a4b0a-47cf-4396-95ab-7e0487eccd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descarga de índices bursátiles desde Yahoo Finances.\n",
    "# -- Sólo descomentar una vez, el resto de usos se pueden hacer desde el fichero descargado\n",
    "\"\"\"\n",
    "import yfinance as yf\n",
    "\n",
    "tickers = [\n",
    "    \"^GSPC\",\"^IXIC\",\"^DJI\",\"^RUT\",\n",
    "    \"^FTSE\",\"^GDAXI\",\"^FCHI\",\"^125904-USD-STRD\",\"^IBEX\",\n",
    "    \"^N225\",\"^HSI\",\"000001.SS\",\"^KS11\",\"^BSESN\",\n",
    "    \"^GSPTSE\",\"^BVSP\",\"^MXX\",\"^MERV\",\n",
    "    \"^AXJO\",\"^NZ50\",\n",
    "    \"ES=F\",\"NQ=F\",\"YM=F\",\"ZT=F\",\"^VIX\"\n",
    "]\n",
    "\n",
    "# Descarga de cierres diarios sin agrupar por ticker\n",
    "data = yf.download(\n",
    "    tickers,\n",
    "    start=\"2005-01-01\",\n",
    "    end=\"2025-01-02\"\n",
    ")\n",
    "\n",
    "cierres = data[\"Close\"]  # DataFrame con cada ticker como columna\n",
    "cierres.to_csv(\"./data/cierres_diarios_2005_2025.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05862f1-fb1c-4236-9c58-1a0e046e3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso de los datos descargados para entrenamiento\n",
    "# -- Asegurarse de enrutamiento y nombre de fichero correctos\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/cierres_diarios_2005_2025n.csv', parse_dates=['Date'], index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb36505-858a-4807-a89f-187cc92e26df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 07:26:04.852182: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-09-18 07:26:04.852220: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-09-18 07:26:04.852225: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-09-18 07:26:04.852258: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-18 07:26:04.852267: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Preparación de los datos\n",
    "\n",
    "# Eliminación de nulos\n",
    "df.ffill(inplace=True)\n",
    "df.bfill(inplace=True)\n",
    "\n",
    "# Split en crudo (¡antes de escalar!)\n",
    "n = len(df)\n",
    "train_raw = df.iloc[:int(n*0.7)]\n",
    "val_raw   = df.iloc[int(n*0.7):int(n*0.9)]\n",
    "test_raw  = df.iloc[int(n*0.9):]\n",
    "\n",
    "# Ajustar scaler SOLO con TRAIN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_raw)  # <- fit solo con train\n",
    "\n",
    "# Transformar cada split con ese scaler\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(scaler.transform(train_raw), index=train_raw.index, columns=train_raw.columns).astype(\"float32\")\n",
    "val_df   = pd.DataFrame(scaler.transform(val_raw),   index=val_raw.index,   columns=val_raw.columns).astype(\"float32\")\n",
    "test_df  = pd.DataFrame(scaler.transform(test_raw),  index=test_raw.index,  columns=test_raw.columns).astype(\"float32\")\n",
    "\n",
    "# Guardar scaler para escenarios S/M/L\n",
    "dump(scaler, \"scaler_modelos.joblib\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_dataset(data, window_size, horizon, batch_size=32, shuffle=True):\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        data=data.values,\n",
    "        targets=None,\n",
    "        sequence_length=window_size + horizon,\n",
    "        sequence_stride=1,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return ds.map(\n",
    "        lambda seq: (\n",
    "            tf.cast(seq[:, :window_size, :], tf.float32),\n",
    "            tf.cast(seq[:, window_size:, :], tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Recreamos datasets con shuffle=False para val/test:\n",
    "train_dss = make_dataset(train_df, window_size=20,  horizon=1,  batch_size=32, shuffle=True)\n",
    "val_dss   = make_dataset(val_df,   window_size=20,  horizon=1,  batch_size=32, shuffle=False)\n",
    "test_dss  = make_dataset(test_df,  window_size=20,  horizon=1,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_dsm = make_dataset(train_df, window_size=60,  horizon=5,  batch_size=32, shuffle=True)\n",
    "val_dsm   = make_dataset(val_df,   window_size=60,  horizon=5,  batch_size=32, shuffle=False)\n",
    "test_dsm  = make_dataset(test_df,  window_size=60,  horizon=5,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_dsl = make_dataset(train_df, window_size=120, horizon=20, batch_size=32, shuffle=True)\n",
    "val_dsl   = make_dataset(val_df,   window_size=120, horizon=20, batch_size=32, shuffle=False)\n",
    "test_dsl  = make_dataset(test_df,  window_size=120, horizon=20, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9213bc-f932-446e-9cf6-93a2ac2b6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid δ (calibrado con cuantiles |e| en VAL): [0.00853496789932251, 0.01, 0.017357412725687027, 0.02, 0.03049677610397339, 0.04116208553314208, 0.05, 0.1]\n",
      "\n",
      "=== Barrido Huber delta _S (GRU) ===\n",
      "\n",
      "--- Entrenando δ=0.00853496789932251 ---\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 07:26:15.395114: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-09-18 07:26:15.917127: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - log_cosh: 0.3023 - loss: 0.0058 - within_eps_0_005: 0.0045 - within_eps_0_01: 0.0097 - within_eps_0_02: 0.0194 - within_eps_0_05: 0.0486 - within_eps_0_1: 0.0965 - val_log_cosh: 0.1390 - val_loss: 0.0036 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0215 - val_within_eps_0_02: 0.0421 - val_within_eps_0_05: 0.1012 - val_within_eps_0_1: 0.1963\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.1280 - loss: 0.0036 - within_eps_0_005: 0.0076 - within_eps_0_01: 0.0153 - within_eps_0_02: 0.0303 - within_eps_0_05: 0.0757 - within_eps_0_1: 0.1511 - val_log_cosh: 0.1008 - val_loss: 0.0029 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0298 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1272 - val_within_eps_0_1: 0.2302\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0879 - loss: 0.0029 - within_eps_0_005: 0.0102 - within_eps_0_01: 0.0202 - within_eps_0_02: 0.0397 - within_eps_0_05: 0.0962 - within_eps_0_1: 0.1873 - val_log_cosh: 0.0886 - val_loss: 0.0027 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0323 - val_within_eps_0_02: 0.0630 - val_within_eps_0_05: 0.1492 - val_within_eps_0_1: 0.2596\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0598 - loss: 0.0024 - within_eps_0_005: 0.0111 - within_eps_0_01: 0.0228 - within_eps_0_02: 0.0461 - within_eps_0_05: 0.1161 - within_eps_0_1: 0.2315 - val_log_cosh: 0.0768 - val_loss: 0.0025 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1306 - val_within_eps_0_1: 0.2542\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0397 - loss: 0.0019 - within_eps_0_005: 0.0157 - within_eps_0_01: 0.0310 - within_eps_0_02: 0.0604 - within_eps_0_05: 0.1498 - within_eps_0_1: 0.2931 - val_log_cosh: 0.0693 - val_loss: 0.0023 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0340 - val_within_eps_0_02: 0.0675 - val_within_eps_0_05: 0.1562 - val_within_eps_0_1: 0.2821\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0255 - loss: 0.0015 - within_eps_0_005: 0.0197 - within_eps_0_01: 0.0389 - within_eps_0_02: 0.0756 - within_eps_0_05: 0.1882 - within_eps_0_1: 0.3612 - val_log_cosh: 0.0653 - val_loss: 0.0022 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0366 - val_within_eps_0_02: 0.0704 - val_within_eps_0_05: 0.1697 - val_within_eps_0_1: 0.3095\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0167 - loss: 0.0012 - within_eps_0_005: 0.0241 - within_eps_0_01: 0.0479 - within_eps_0_02: 0.0964 - within_eps_0_05: 0.2355 - within_eps_0_1: 0.4482 - val_log_cosh: 0.0602 - val_loss: 0.0020 - val_within_eps_0_005: 0.0185 - val_within_eps_0_01: 0.0357 - val_within_eps_0_02: 0.0711 - val_within_eps_0_05: 0.1828 - val_within_eps_0_1: 0.3494\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0114 - loss: 9.6253e-04 - within_eps_0_005: 0.0299 - within_eps_0_01: 0.0599 - within_eps_0_02: 0.1176 - within_eps_0_05: 0.2841 - within_eps_0_1: 0.5311 - val_log_cosh: 0.0588 - val_loss: 0.0020 - val_within_eps_0_005: 0.0234 - val_within_eps_0_01: 0.0475 - val_within_eps_0_02: 0.0890 - val_within_eps_0_05: 0.2032 - val_within_eps_0_1: 0.3588\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0088 - loss: 8.3247e-04 - within_eps_0_005: 0.0334 - within_eps_0_01: 0.0685 - within_eps_0_02: 0.1363 - within_eps_0_05: 0.3313 - within_eps_0_1: 0.5951 - val_log_cosh: 0.0588 - val_loss: 0.0020 - val_within_eps_0_005: 0.0206 - val_within_eps_0_01: 0.0421 - val_within_eps_0_02: 0.0794 - val_within_eps_0_05: 0.2011 - val_within_eps_0_1: 0.3761\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0069 - loss: 7.3599e-04 - within_eps_0_005: 0.0385 - within_eps_0_01: 0.0778 - within_eps_0_02: 0.1543 - within_eps_0_05: 0.3672 - within_eps_0_1: 0.6458 - val_log_cosh: 0.0650 - val_loss: 0.0022 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0358 - val_within_eps_0_02: 0.0733 - val_within_eps_0_05: 0.1870 - val_within_eps_0_1: 0.3341\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0060 - loss: 6.7430e-04 - within_eps_0_005: 0.0427 - within_eps_0_01: 0.0863 - within_eps_0_02: 0.1669 - within_eps_0_05: 0.3987 - within_eps_0_1: 0.6884 - val_log_cosh: 0.0753 - val_loss: 0.0024 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0359 - val_within_eps_0_02: 0.0712 - val_within_eps_0_05: 0.1727 - val_within_eps_0_1: 0.3120\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0057 - loss: 6.5535e-04 - within_eps_0_005: 0.0441 - within_eps_0_01: 0.0877 - within_eps_0_02: 0.1758 - within_eps_0_05: 0.4121 - within_eps_0_1: 0.6991 - val_log_cosh: 0.0511 - val_loss: 0.0018 - val_within_eps_0_005: 0.0234 - val_within_eps_0_01: 0.0461 - val_within_eps_0_02: 0.0921 - val_within_eps_0_05: 0.2254 - val_within_eps_0_1: 0.3902\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0050 - loss: 6.0858e-04 - within_eps_0_005: 0.0493 - within_eps_0_01: 0.0977 - within_eps_0_02: 0.1894 - within_eps_0_05: 0.4426 - within_eps_0_1: 0.7292 - val_log_cosh: 0.0651 - val_loss: 0.0022 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0331 - val_within_eps_0_02: 0.0665 - val_within_eps_0_05: 0.1689 - val_within_eps_0_1: 0.3337\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0046 - loss: 5.7959e-04 - within_eps_0_005: 0.0523 - within_eps_0_01: 0.1023 - within_eps_0_02: 0.2001 - within_eps_0_05: 0.4629 - within_eps_0_1: 0.7525 - val_log_cosh: 0.0576 - val_loss: 0.0020 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0331 - val_within_eps_0_02: 0.0710 - val_within_eps_0_05: 0.1929 - val_within_eps_0_1: 0.3569\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0043 - loss: 5.5735e-04 - within_eps_0_005: 0.0516 - within_eps_0_01: 0.1036 - within_eps_0_02: 0.2054 - within_eps_0_05: 0.4735 - within_eps_0_1: 0.7643 - val_log_cosh: 0.0562 - val_loss: 0.0020 - val_within_eps_0_005: 0.0195 - val_within_eps_0_01: 0.0402 - val_within_eps_0_02: 0.0813 - val_within_eps_0_05: 0.2033 - val_within_eps_0_1: 0.3674\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0040 - loss: 5.3718e-04 - within_eps_0_005: 0.0547 - within_eps_0_01: 0.1092 - within_eps_0_02: 0.2155 - within_eps_0_05: 0.4931 - within_eps_0_1: 0.7783 - val_log_cosh: 0.0596 - val_loss: 0.0021 - val_within_eps_0_005: 0.0170 - val_within_eps_0_01: 0.0327 - val_within_eps_0_02: 0.0663 - val_within_eps_0_05: 0.1772 - val_within_eps_0_1: 0.3409\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0038 - loss: 5.2054e-04 - within_eps_0_005: 0.0577 - within_eps_0_01: 0.1140 - within_eps_0_02: 0.2229 - within_eps_0_05: 0.5021 - within_eps_0_1: 0.7888 - val_log_cosh: 0.0556 - val_loss: 0.0020 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0371 - val_within_eps_0_02: 0.0776 - val_within_eps_0_05: 0.1954 - val_within_eps_0_1: 0.3590\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0036 - loss: 5.0675e-04 - within_eps_0_005: 0.0576 - within_eps_0_01: 0.1148 - within_eps_0_02: 0.2259 - within_eps_0_05: 0.5107 - within_eps_0_1: 0.7992 - val_log_cosh: 0.0509 - val_loss: 0.0019 - val_within_eps_0_005: 0.0215 - val_within_eps_0_01: 0.0438 - val_within_eps_0_02: 0.0852 - val_within_eps_0_05: 0.2180 - val_within_eps_0_1: 0.3819\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0035 - loss: 4.9824e-04 - within_eps_0_005: 0.0586 - within_eps_0_01: 0.1164 - within_eps_0_02: 0.2311 - within_eps_0_05: 0.5208 - within_eps_0_1: 0.8066 - val_log_cosh: 0.0487 - val_loss: 0.0018 - val_within_eps_0_005: 0.0245 - val_within_eps_0_01: 0.0508 - val_within_eps_0_02: 0.1007 - val_within_eps_0_05: 0.2348 - val_within_eps_0_1: 0.3882\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0033 - loss: 4.8564e-04 - within_eps_0_005: 0.0591 - within_eps_0_01: 0.1190 - within_eps_0_02: 0.2351 - within_eps_0_05: 0.5292 - within_eps_0_1: 0.8131 - val_log_cosh: 0.0540 - val_loss: 0.0020 - val_within_eps_0_005: 0.0232 - val_within_eps_0_01: 0.0437 - val_within_eps_0_02: 0.0850 - val_within_eps_0_05: 0.1978 - val_within_eps_0_1: 0.3469\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0032 - loss: 4.7053e-04 - within_eps_0_005: 0.0632 - within_eps_0_01: 0.1235 - within_eps_0_02: 0.2449 - within_eps_0_05: 0.5415 - within_eps_0_1: 0.8248 - val_log_cosh: 0.0437 - val_loss: 0.0017 - val_within_eps_0_005: 0.0286 - val_within_eps_0_01: 0.0559 - val_within_eps_0_02: 0.1086 - val_within_eps_0_05: 0.2415 - val_within_eps_0_1: 0.4001\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0031 - loss: 4.6281e-04 - within_eps_0_005: 0.0618 - within_eps_0_01: 0.1253 - within_eps_0_02: 0.2478 - within_eps_0_05: 0.5499 - within_eps_0_1: 0.8306 - val_log_cosh: 0.0515 - val_loss: 0.0019 - val_within_eps_0_005: 0.0246 - val_within_eps_0_01: 0.0483 - val_within_eps_0_02: 0.0970 - val_within_eps_0_05: 0.2249 - val_within_eps_0_1: 0.3784\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0029 - loss: 4.4979e-04 - within_eps_0_005: 0.0647 - within_eps_0_01: 0.1291 - within_eps_0_02: 0.2520 - within_eps_0_05: 0.5606 - within_eps_0_1: 0.8378 - val_log_cosh: 0.0489 - val_loss: 0.0018 - val_within_eps_0_005: 0.0221 - val_within_eps_0_01: 0.0468 - val_within_eps_0_02: 0.0913 - val_within_eps_0_05: 0.2256 - val_within_eps_0_1: 0.3795\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0029 - loss: 4.5032e-04 - within_eps_0_005: 0.0638 - within_eps_0_01: 0.1282 - within_eps_0_02: 0.2546 - within_eps_0_05: 0.5599 - within_eps_0_1: 0.8376 - val_log_cosh: 0.0548 - val_loss: 0.0020 - val_within_eps_0_005: 0.0217 - val_within_eps_0_01: 0.0417 - val_within_eps_0_02: 0.0829 - val_within_eps_0_05: 0.1906 - val_within_eps_0_1: 0.3511\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0027 - loss: 4.3299e-04 - within_eps_0_005: 0.0686 - within_eps_0_01: 0.1336 - within_eps_0_02: 0.2612 - within_eps_0_05: 0.5748 - within_eps_0_1: 0.8535 - val_log_cosh: 0.0528 - val_loss: 0.0020 - val_within_eps_0_005: 0.0230 - val_within_eps_0_01: 0.0463 - val_within_eps_0_02: 0.0903 - val_within_eps_0_05: 0.2024 - val_within_eps_0_1: 0.3508\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - log_cosh: 0.0027 - loss: 4.2446e-04 - within_eps_0_005: 0.0687 - within_eps_0_01: 0.1362 - within_eps_0_02: 0.2696 - within_eps_0_05: 0.5875 - within_eps_0_1: 0.8559 - val_log_cosh: 0.0543 - val_loss: 0.0020 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0426 - val_within_eps_0_02: 0.0830 - val_within_eps_0_05: 0.2061 - val_within_eps_0_1: 0.3619\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0026 - loss: 4.2097e-04 - within_eps_0_005: 0.0698 - within_eps_0_01: 0.1374 - within_eps_0_02: 0.2711 - within_eps_0_05: 0.5910 - within_eps_0_1: 0.8571 - val_log_cosh: 0.0444 - val_loss: 0.0017 - val_within_eps_0_005: 0.0297 - val_within_eps_0_01: 0.0594 - val_within_eps_0_02: 0.1129 - val_within_eps_0_05: 0.2291 - val_within_eps_0_1: 0.3910\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0025 - loss: 4.1471e-04 - within_eps_0_005: 0.0714 - within_eps_0_01: 0.1412 - within_eps_0_02: 0.2721 - within_eps_0_05: 0.5913 - within_eps_0_1: 0.8613 - val_log_cosh: 0.0503 - val_loss: 0.0019 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0487 - val_within_eps_0_02: 0.0952 - val_within_eps_0_05: 0.2229 - val_within_eps_0_1: 0.3680\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0023 - loss: 3.9602e-04 - within_eps_0_005: 0.0749 - within_eps_0_01: 0.1480 - within_eps_0_02: 0.2856 - within_eps_0_05: 0.6107 - within_eps_0_1: 0.8735 - val_log_cosh: 0.0552 - val_loss: 0.0020 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0405 - val_within_eps_0_02: 0.0808 - val_within_eps_0_05: 0.1847 - val_within_eps_0_1: 0.3357\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0024 - loss: 4.0007e-04 - within_eps_0_005: 0.0727 - within_eps_0_01: 0.1442 - within_eps_0_02: 0.2793 - within_eps_0_05: 0.6114 - within_eps_0_1: 0.8740 - val_log_cosh: 0.0500 - val_loss: 0.0019 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0484 - val_within_eps_0_02: 0.0962 - val_within_eps_0_05: 0.2178 - val_within_eps_0_1: 0.3659\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0022 - loss: 3.8310e-04 - within_eps_0_005: 0.0747 - within_eps_0_01: 0.1484 - within_eps_0_02: 0.2893 - within_eps_0_05: 0.6230 - within_eps_0_1: 0.8858 - val_log_cosh: 0.0529 - val_loss: 0.0020 - val_within_eps_0_005: 0.0178 - val_within_eps_0_01: 0.0363 - val_within_eps_0_02: 0.0758 - val_within_eps_0_05: 0.1946 - val_within_eps_0_1: 0.3494\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0023 - loss: 3.8614e-04 - within_eps_0_005: 0.0751 - within_eps_0_01: 0.1504 - within_eps_0_02: 0.2926 - within_eps_0_05: 0.6262 - within_eps_0_1: 0.8820 - val_log_cosh: 0.0448 - val_loss: 0.0017 - val_within_eps_0_005: 0.0252 - val_within_eps_0_01: 0.0518 - val_within_eps_0_02: 0.1075 - val_within_eps_0_05: 0.2505 - val_within_eps_0_1: 0.4012\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0021 - loss: 3.7814e-04 - within_eps_0_005: 0.0767 - within_eps_0_01: 0.1526 - within_eps_0_02: 0.2973 - within_eps_0_05: 0.6311 - within_eps_0_1: 0.8860 - val_log_cosh: 0.0495 - val_loss: 0.0019 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0476 - val_within_eps_0_02: 0.0946 - val_within_eps_0_05: 0.2199 - val_within_eps_0_1: 0.3680\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0021 - loss: 3.6688e-04 - within_eps_0_005: 0.0804 - within_eps_0_01: 0.1585 - within_eps_0_02: 0.3068 - within_eps_0_05: 0.6457 - within_eps_0_1: 0.8933 - val_log_cosh: 0.0525 - val_loss: 0.0019 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0471 - val_within_eps_0_02: 0.0935 - val_within_eps_0_05: 0.2180 - val_within_eps_0_1: 0.3578\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0021 - loss: 3.6746e-04 - within_eps_0_005: 0.0826 - within_eps_0_01: 0.1612 - within_eps_0_02: 0.3097 - within_eps_0_05: 0.6449 - within_eps_0_1: 0.8931 - val_log_cosh: 0.0518 - val_loss: 0.0019 - val_within_eps_0_005: 0.0230 - val_within_eps_0_01: 0.0438 - val_within_eps_0_02: 0.0879 - val_within_eps_0_05: 0.2041 - val_within_eps_0_1: 0.3683\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0021 - loss: 3.6742e-04 - within_eps_0_005: 0.0804 - within_eps_0_01: 0.1615 - within_eps_0_02: 0.3126 - within_eps_0_05: 0.6410 - within_eps_0_1: 0.8928 - val_log_cosh: 0.0565 - val_loss: 0.0020 - val_within_eps_0_005: 0.0260 - val_within_eps_0_01: 0.0482 - val_within_eps_0_02: 0.0915 - val_within_eps_0_05: 0.1972 - val_within_eps_0_1: 0.3471\n",
      "  -> val_log_cosh(min) δ=0.00853496789932251: 0.043731782585\n",
      "\n",
      "--- Entrenando δ=0.01 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - log_cosh: 0.3335 - loss: 0.0072 - within_eps_0_005: 0.0043 - within_eps_0_01: 0.0091 - within_eps_0_02: 0.0184 - within_eps_0_05: 0.0459 - within_eps_0_1: 0.0934 - val_log_cosh: 0.1479 - val_loss: 0.0045 - val_within_eps_0_005: 0.0068 - val_within_eps_0_01: 0.0147 - val_within_eps_0_02: 0.0286 - val_within_eps_0_05: 0.0672 - val_within_eps_0_1: 0.1326\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.1421 - loss: 0.0045 - within_eps_0_005: 0.0077 - within_eps_0_01: 0.0147 - within_eps_0_02: 0.0290 - within_eps_0_05: 0.0730 - within_eps_0_1: 0.1424 - val_log_cosh: 0.1110 - val_loss: 0.0036 - val_within_eps_0_005: 0.0082 - val_within_eps_0_01: 0.0170 - val_within_eps_0_02: 0.0361 - val_within_eps_0_05: 0.1007 - val_within_eps_0_1: 0.2054\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.1040 - loss: 0.0037 - within_eps_0_005: 0.0084 - within_eps_0_01: 0.0173 - within_eps_0_02: 0.0347 - within_eps_0_05: 0.0856 - within_eps_0_1: 0.1708 - val_log_cosh: 0.0816 - val_loss: 0.0029 - val_within_eps_0_005: 0.0182 - val_within_eps_0_01: 0.0359 - val_within_eps_0_02: 0.0660 - val_within_eps_0_05: 0.1573 - val_within_eps_0_1: 0.3064\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0753 - loss: 0.0031 - within_eps_0_005: 0.0105 - within_eps_0_01: 0.0201 - within_eps_0_02: 0.0406 - within_eps_0_05: 0.1033 - within_eps_0_1: 0.2054 - val_log_cosh: 0.0652 - val_loss: 0.0025 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0571 - val_within_eps_0_05: 0.1586 - val_within_eps_0_1: 0.3293\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0520 - loss: 0.0026 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0251 - within_eps_0_02: 0.0494 - within_eps_0_05: 0.1246 - within_eps_0_1: 0.2483 - val_log_cosh: 0.0617 - val_loss: 0.0025 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0365 - val_within_eps_0_02: 0.0750 - val_within_eps_0_05: 0.1771 - val_within_eps_0_1: 0.3368\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0345 - loss: 0.0020 - within_eps_0_005: 0.0154 - within_eps_0_01: 0.0318 - within_eps_0_02: 0.0649 - within_eps_0_05: 0.1588 - within_eps_0_1: 0.3137 - val_log_cosh: 0.0578 - val_loss: 0.0024 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1621 - val_within_eps_0_1: 0.3255\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0222 - loss: 0.0016 - within_eps_0_005: 0.0206 - within_eps_0_01: 0.0396 - within_eps_0_02: 0.0801 - within_eps_0_05: 0.2009 - within_eps_0_1: 0.3915 - val_log_cosh: 0.0547 - val_loss: 0.0023 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0353 - val_within_eps_0_02: 0.0693 - val_within_eps_0_05: 0.1881 - val_within_eps_0_1: 0.3420\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0150 - loss: 0.0013 - within_eps_0_005: 0.0254 - within_eps_0_01: 0.0507 - within_eps_0_02: 0.1014 - within_eps_0_05: 0.2457 - within_eps_0_1: 0.4623 - val_log_cosh: 0.0529 - val_loss: 0.0023 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0344 - val_within_eps_0_02: 0.0716 - val_within_eps_0_05: 0.1780 - val_within_eps_0_1: 0.3299\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0108 - loss: 0.0011 - within_eps_0_005: 0.0300 - within_eps_0_01: 0.0591 - within_eps_0_02: 0.1194 - within_eps_0_05: 0.2936 - within_eps_0_1: 0.5377 - val_log_cosh: 0.0522 - val_loss: 0.0023 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0415 - val_within_eps_0_02: 0.0756 - val_within_eps_0_05: 0.1856 - val_within_eps_0_1: 0.3256\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0080 - loss: 9.2478e-04 - within_eps_0_005: 0.0352 - within_eps_0_01: 0.0697 - within_eps_0_02: 0.1418 - within_eps_0_05: 0.3408 - within_eps_0_1: 0.6124 - val_log_cosh: 0.0476 - val_loss: 0.0022 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0407 - val_within_eps_0_02: 0.0763 - val_within_eps_0_05: 0.1864 - val_within_eps_0_1: 0.3436\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0065 - loss: 8.2293e-04 - within_eps_0_005: 0.0407 - within_eps_0_01: 0.0815 - within_eps_0_02: 0.1600 - within_eps_0_05: 0.3812 - within_eps_0_1: 0.6612 - val_log_cosh: 0.0498 - val_loss: 0.0022 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0755 - val_within_eps_0_05: 0.1823 - val_within_eps_0_1: 0.3292\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0058 - loss: 7.6580e-04 - within_eps_0_005: 0.0428 - within_eps_0_01: 0.0862 - within_eps_0_02: 0.1714 - within_eps_0_05: 0.4113 - within_eps_0_1: 0.6960 - val_log_cosh: 0.0505 - val_loss: 0.0022 - val_within_eps_0_005: 0.0207 - val_within_eps_0_01: 0.0417 - val_within_eps_0_02: 0.0802 - val_within_eps_0_05: 0.1817 - val_within_eps_0_1: 0.3304\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0050 - loss: 7.1096e-04 - within_eps_0_005: 0.0461 - within_eps_0_01: 0.0944 - within_eps_0_02: 0.1857 - within_eps_0_05: 0.4354 - within_eps_0_1: 0.7278 - val_log_cosh: 0.0436 - val_loss: 0.0020 - val_within_eps_0_005: 0.0228 - val_within_eps_0_01: 0.0476 - val_within_eps_0_02: 0.0937 - val_within_eps_0_05: 0.2113 - val_within_eps_0_1: 0.3718\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0048 - loss: 6.8502e-04 - within_eps_0_005: 0.0507 - within_eps_0_01: 0.0987 - within_eps_0_02: 0.1970 - within_eps_0_05: 0.4580 - within_eps_0_1: 0.7441 - val_log_cosh: 0.0464 - val_loss: 0.0021 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0766 - val_within_eps_0_05: 0.1940 - val_within_eps_0_1: 0.3567\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0043 - loss: 6.4915e-04 - within_eps_0_005: 0.0522 - within_eps_0_01: 0.1047 - within_eps_0_02: 0.2057 - within_eps_0_05: 0.4726 - within_eps_0_1: 0.7628 - val_log_cosh: 0.0432 - val_loss: 0.0020 - val_within_eps_0_005: 0.0207 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0852 - val_within_eps_0_05: 0.2097 - val_within_eps_0_1: 0.3829\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0041 - loss: 6.2440e-04 - within_eps_0_005: 0.0534 - within_eps_0_01: 0.1079 - within_eps_0_02: 0.2127 - within_eps_0_05: 0.4916 - within_eps_0_1: 0.7786 - val_log_cosh: 0.0399 - val_loss: 0.0019 - val_within_eps_0_005: 0.0248 - val_within_eps_0_01: 0.0494 - val_within_eps_0_02: 0.0956 - val_within_eps_0_05: 0.2297 - val_within_eps_0_1: 0.3919\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0039 - loss: 6.1038e-04 - within_eps_0_005: 0.0570 - within_eps_0_01: 0.1137 - within_eps_0_02: 0.2224 - within_eps_0_05: 0.5022 - within_eps_0_1: 0.7857 - val_log_cosh: 0.0461 - val_loss: 0.0021 - val_within_eps_0_005: 0.0220 - val_within_eps_0_01: 0.0434 - val_within_eps_0_02: 0.0866 - val_within_eps_0_05: 0.1962 - val_within_eps_0_1: 0.3640\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0037 - loss: 5.9057e-04 - within_eps_0_005: 0.0564 - within_eps_0_01: 0.1131 - within_eps_0_02: 0.2236 - within_eps_0_05: 0.5105 - within_eps_0_1: 0.7962 - val_log_cosh: 0.0431 - val_loss: 0.0020 - val_within_eps_0_005: 0.0223 - val_within_eps_0_01: 0.0459 - val_within_eps_0_02: 0.0925 - val_within_eps_0_05: 0.2242 - val_within_eps_0_1: 0.3854\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0037 - loss: 5.8631e-04 - within_eps_0_005: 0.0579 - within_eps_0_01: 0.1155 - within_eps_0_02: 0.2283 - within_eps_0_05: 0.5200 - within_eps_0_1: 0.8000 - val_log_cosh: 0.0429 - val_loss: 0.0020 - val_within_eps_0_005: 0.0246 - val_within_eps_0_01: 0.0501 - val_within_eps_0_02: 0.1022 - val_within_eps_0_05: 0.2308 - val_within_eps_0_1: 0.3869\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0034 - loss: 5.5927e-04 - within_eps_0_005: 0.0608 - within_eps_0_01: 0.1215 - within_eps_0_02: 0.2403 - within_eps_0_05: 0.5374 - within_eps_0_1: 0.8153 - val_log_cosh: 0.0506 - val_loss: 0.0022 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0366 - val_within_eps_0_02: 0.0743 - val_within_eps_0_05: 0.1810 - val_within_eps_0_1: 0.3463\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0033 - loss: 5.4653e-04 - within_eps_0_005: 0.0632 - within_eps_0_01: 0.1271 - within_eps_0_02: 0.2465 - within_eps_0_05: 0.5445 - within_eps_0_1: 0.8222 - val_log_cosh: 0.0428 - val_loss: 0.0019 - val_within_eps_0_005: 0.0241 - val_within_eps_0_01: 0.0507 - val_within_eps_0_02: 0.1045 - val_within_eps_0_05: 0.2379 - val_within_eps_0_1: 0.4014\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0033 - loss: 5.4371e-04 - within_eps_0_005: 0.0624 - within_eps_0_01: 0.1270 - within_eps_0_02: 0.2505 - within_eps_0_05: 0.5537 - within_eps_0_1: 0.8251 - val_log_cosh: 0.0461 - val_loss: 0.0021 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0480 - val_within_eps_0_02: 0.0969 - val_within_eps_0_05: 0.2111 - val_within_eps_0_1: 0.3729\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0030 - loss: 5.2119e-04 - within_eps_0_005: 0.0650 - within_eps_0_01: 0.1297 - within_eps_0_02: 0.2619 - within_eps_0_05: 0.5674 - within_eps_0_1: 0.8359 - val_log_cosh: 0.0422 - val_loss: 0.0019 - val_within_eps_0_005: 0.0262 - val_within_eps_0_01: 0.0504 - val_within_eps_0_02: 0.1023 - val_within_eps_0_05: 0.2355 - val_within_eps_0_1: 0.3993\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0029 - loss: 5.1225e-04 - within_eps_0_005: 0.0646 - within_eps_0_01: 0.1313 - within_eps_0_02: 0.2613 - within_eps_0_05: 0.5717 - within_eps_0_1: 0.8429 - val_log_cosh: 0.0442 - val_loss: 0.0020 - val_within_eps_0_005: 0.0255 - val_within_eps_0_01: 0.0512 - val_within_eps_0_02: 0.1000 - val_within_eps_0_05: 0.2243 - val_within_eps_0_1: 0.3890\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0028 - loss: 5.0159e-04 - within_eps_0_005: 0.0694 - within_eps_0_01: 0.1363 - within_eps_0_02: 0.2679 - within_eps_0_05: 0.5819 - within_eps_0_1: 0.8508 - val_log_cosh: 0.0465 - val_loss: 0.0021 - val_within_eps_0_005: 0.0248 - val_within_eps_0_01: 0.0482 - val_within_eps_0_02: 0.0909 - val_within_eps_0_05: 0.2087 - val_within_eps_0_1: 0.3731\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0027 - loss: 4.9229e-04 - within_eps_0_005: 0.0713 - within_eps_0_01: 0.1411 - within_eps_0_02: 0.2727 - within_eps_0_05: 0.5851 - within_eps_0_1: 0.8553 - val_log_cosh: 0.0452 - val_loss: 0.0020 - val_within_eps_0_005: 0.0278 - val_within_eps_0_01: 0.0558 - val_within_eps_0_02: 0.1023 - val_within_eps_0_05: 0.2174 - val_within_eps_0_1: 0.3911\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0027 - loss: 4.8807e-04 - within_eps_0_005: 0.0718 - within_eps_0_01: 0.1430 - within_eps_0_02: 0.2769 - within_eps_0_05: 0.5943 - within_eps_0_1: 0.8564 - val_log_cosh: 0.0447 - val_loss: 0.0020 - val_within_eps_0_005: 0.0262 - val_within_eps_0_01: 0.0541 - val_within_eps_0_02: 0.1073 - val_within_eps_0_05: 0.2391 - val_within_eps_0_1: 0.4075\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0026 - loss: 4.7319e-04 - within_eps_0_005: 0.0743 - within_eps_0_01: 0.1465 - within_eps_0_02: 0.2843 - within_eps_0_05: 0.6056 - within_eps_0_1: 0.8651 - val_log_cosh: 0.0436 - val_loss: 0.0020 - val_within_eps_0_005: 0.0244 - val_within_eps_0_01: 0.0507 - val_within_eps_0_02: 0.0993 - val_within_eps_0_05: 0.2307 - val_within_eps_0_1: 0.3927\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0026 - loss: 4.7468e-04 - within_eps_0_005: 0.0720 - within_eps_0_01: 0.1436 - within_eps_0_02: 0.2834 - within_eps_0_05: 0.6060 - within_eps_0_1: 0.8650 - val_log_cosh: 0.0416 - val_loss: 0.0019 - val_within_eps_0_005: 0.0287 - val_within_eps_0_01: 0.0559 - val_within_eps_0_02: 0.1108 - val_within_eps_0_05: 0.2591 - val_within_eps_0_1: 0.4300\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0024 - loss: 4.5968e-04 - within_eps_0_005: 0.0748 - within_eps_0_01: 0.1489 - within_eps_0_02: 0.2910 - within_eps_0_05: 0.6197 - within_eps_0_1: 0.8724 - val_log_cosh: 0.0433 - val_loss: 0.0020 - val_within_eps_0_005: 0.0289 - val_within_eps_0_01: 0.0563 - val_within_eps_0_02: 0.1073 - val_within_eps_0_05: 0.2365 - val_within_eps_0_1: 0.4142\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0023 - loss: 4.3872e-04 - within_eps_0_005: 0.0810 - within_eps_0_01: 0.1598 - within_eps_0_02: 0.3063 - within_eps_0_05: 0.6331 - within_eps_0_1: 0.8838 - val_log_cosh: 0.0441 - val_loss: 0.0020 - val_within_eps_0_005: 0.0315 - val_within_eps_0_01: 0.0611 - val_within_eps_0_02: 0.1131 - val_within_eps_0_05: 0.2337 - val_within_eps_0_1: 0.4117\n",
      "  -> val_log_cosh(min) δ=0.01: 0.039921592921\n",
      "\n",
      "--- Entrenando δ=0.017357412725687027 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - log_cosh: 0.2718 - loss: 0.0111 - within_eps_0_005: 0.0049 - within_eps_0_01: 0.0099 - within_eps_0_02: 0.0197 - within_eps_0_05: 0.0502 - within_eps_0_1: 0.1039 - val_log_cosh: 0.1172 - val_loss: 0.0063 - val_within_eps_0_005: 0.0098 - val_within_eps_0_01: 0.0204 - val_within_eps_0_02: 0.0427 - val_within_eps_0_05: 0.1083 - val_within_eps_0_1: 0.2266\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.1317 - loss: 0.0074 - within_eps_0_005: 0.0077 - within_eps_0_01: 0.0154 - within_eps_0_02: 0.0297 - within_eps_0_05: 0.0742 - within_eps_0_1: 0.1481 - val_log_cosh: 0.0974 - val_loss: 0.0056 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0264 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1379 - val_within_eps_0_1: 0.2800\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.1009 - loss: 0.0063 - within_eps_0_005: 0.0082 - within_eps_0_01: 0.0167 - within_eps_0_02: 0.0337 - within_eps_0_05: 0.0867 - within_eps_0_1: 0.1728 - val_log_cosh: 0.0842 - val_loss: 0.0051 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0226 - val_within_eps_0_02: 0.0456 - val_within_eps_0_05: 0.1229 - val_within_eps_0_1: 0.2681\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0747 - loss: 0.0054 - within_eps_0_005: 0.0103 - within_eps_0_01: 0.0206 - within_eps_0_02: 0.0414 - within_eps_0_05: 0.1024 - within_eps_0_1: 0.2018 - val_log_cosh: 0.0844 - val_loss: 0.0052 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0549 - val_within_eps_0_05: 0.1510 - val_within_eps_0_1: 0.2923\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0546 - loss: 0.0045 - within_eps_0_005: 0.0125 - within_eps_0_01: 0.0248 - within_eps_0_02: 0.0487 - within_eps_0_05: 0.1206 - within_eps_0_1: 0.2404 - val_log_cosh: 0.0822 - val_loss: 0.0051 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0237 - val_within_eps_0_02: 0.0476 - val_within_eps_0_05: 0.1161 - val_within_eps_0_1: 0.2408\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0383 - loss: 0.0037 - within_eps_0_005: 0.0150 - within_eps_0_01: 0.0302 - within_eps_0_02: 0.0607 - within_eps_0_05: 0.1493 - within_eps_0_1: 0.2917 - val_log_cosh: 0.0677 - val_loss: 0.0045 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0352 - val_within_eps_0_02: 0.0680 - val_within_eps_0_05: 0.1634 - val_within_eps_0_1: 0.3020\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0274 - loss: 0.0031 - within_eps_0_005: 0.0189 - within_eps_0_01: 0.0365 - within_eps_0_02: 0.0707 - within_eps_0_05: 0.1732 - within_eps_0_1: 0.3407 - val_log_cosh: 0.0680 - val_loss: 0.0044 - val_within_eps_0_005: 0.0159 - val_within_eps_0_01: 0.0326 - val_within_eps_0_02: 0.0636 - val_within_eps_0_05: 0.1645 - val_within_eps_0_1: 0.3272\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0188 - loss: 0.0025 - within_eps_0_005: 0.0219 - within_eps_0_01: 0.0441 - within_eps_0_02: 0.0883 - within_eps_0_05: 0.2191 - within_eps_0_1: 0.4185 - val_log_cosh: 0.0597 - val_loss: 0.0041 - val_within_eps_0_005: 0.0166 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0716 - val_within_eps_0_05: 0.1725 - val_within_eps_0_1: 0.3376\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0128 - loss: 0.0020 - within_eps_0_005: 0.0281 - within_eps_0_01: 0.0563 - within_eps_0_02: 0.1113 - within_eps_0_05: 0.2726 - within_eps_0_1: 0.5041 - val_log_cosh: 0.0657 - val_loss: 0.0045 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1624 - val_within_eps_0_1: 0.3125\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0091 - loss: 0.0017 - within_eps_0_005: 0.0347 - within_eps_0_01: 0.0673 - within_eps_0_02: 0.1320 - within_eps_0_05: 0.3226 - within_eps_0_1: 0.5824 - val_log_cosh: 0.0561 - val_loss: 0.0040 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0361 - val_within_eps_0_02: 0.0754 - val_within_eps_0_05: 0.1956 - val_within_eps_0_1: 0.3551\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0069 - loss: 0.0014 - within_eps_0_005: 0.0367 - within_eps_0_01: 0.0759 - within_eps_0_02: 0.1530 - within_eps_0_05: 0.3706 - within_eps_0_1: 0.6496 - val_log_cosh: 0.0551 - val_loss: 0.0040 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0390 - val_within_eps_0_02: 0.0781 - val_within_eps_0_05: 0.1911 - val_within_eps_0_1: 0.3454\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0060 - loss: 0.0013 - within_eps_0_005: 0.0436 - within_eps_0_01: 0.0874 - within_eps_0_02: 0.1712 - within_eps_0_05: 0.4056 - within_eps_0_1: 0.6894 - val_log_cosh: 0.0581 - val_loss: 0.0041 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0359 - val_within_eps_0_02: 0.0734 - val_within_eps_0_05: 0.1840 - val_within_eps_0_1: 0.3368\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0052 - loss: 0.0012 - within_eps_0_005: 0.0467 - within_eps_0_01: 0.0927 - within_eps_0_02: 0.1842 - within_eps_0_05: 0.4290 - within_eps_0_1: 0.7210 - val_log_cosh: 0.0545 - val_loss: 0.0040 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0799 - val_within_eps_0_05: 0.1866 - val_within_eps_0_1: 0.3352\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0046 - loss: 0.0011 - within_eps_0_005: 0.0502 - within_eps_0_01: 0.1008 - within_eps_0_02: 0.1975 - within_eps_0_05: 0.4592 - within_eps_0_1: 0.7482 - val_log_cosh: 0.0483 - val_loss: 0.0037 - val_within_eps_0_005: 0.0269 - val_within_eps_0_01: 0.0542 - val_within_eps_0_02: 0.1021 - val_within_eps_0_05: 0.2138 - val_within_eps_0_1: 0.3565\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0044 - loss: 0.0011 - within_eps_0_005: 0.0483 - within_eps_0_01: 0.0985 - within_eps_0_02: 0.1944 - within_eps_0_05: 0.4610 - within_eps_0_1: 0.7549 - val_log_cosh: 0.0478 - val_loss: 0.0037 - val_within_eps_0_005: 0.0248 - val_within_eps_0_01: 0.0487 - val_within_eps_0_02: 0.0948 - val_within_eps_0_05: 0.2087 - val_within_eps_0_1: 0.3545\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0040 - loss: 0.0010 - within_eps_0_005: 0.0542 - within_eps_0_01: 0.1073 - within_eps_0_02: 0.2130 - within_eps_0_05: 0.4867 - within_eps_0_1: 0.7773 - val_log_cosh: 0.0470 - val_loss: 0.0037 - val_within_eps_0_005: 0.0224 - val_within_eps_0_01: 0.0459 - val_within_eps_0_02: 0.0949 - val_within_eps_0_05: 0.2175 - val_within_eps_0_1: 0.3560\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0038 - loss: 9.9601e-04 - within_eps_0_005: 0.0535 - within_eps_0_01: 0.1092 - within_eps_0_02: 0.2148 - within_eps_0_05: 0.4946 - within_eps_0_1: 0.7876 - val_log_cosh: 0.0466 - val_loss: 0.0037 - val_within_eps_0_005: 0.0218 - val_within_eps_0_01: 0.0433 - val_within_eps_0_02: 0.0861 - val_within_eps_0_05: 0.2084 - val_within_eps_0_1: 0.3555\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0036 - loss: 9.5939e-04 - within_eps_0_005: 0.0555 - within_eps_0_01: 0.1117 - within_eps_0_02: 0.2237 - within_eps_0_05: 0.5140 - within_eps_0_1: 0.8007 - val_log_cosh: 0.0506 - val_loss: 0.0039 - val_within_eps_0_005: 0.0179 - val_within_eps_0_01: 0.0374 - val_within_eps_0_02: 0.0741 - val_within_eps_0_05: 0.1740 - val_within_eps_0_1: 0.3446\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0036 - loss: 9.5366e-04 - within_eps_0_005: 0.0569 - within_eps_0_01: 0.1145 - within_eps_0_02: 0.2261 - within_eps_0_05: 0.5194 - within_eps_0_1: 0.8026 - val_log_cosh: 0.0457 - val_loss: 0.0036 - val_within_eps_0_005: 0.0205 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0826 - val_within_eps_0_05: 0.2013 - val_within_eps_0_1: 0.3689\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0032 - loss: 8.9446e-04 - within_eps_0_005: 0.0617 - within_eps_0_01: 0.1237 - within_eps_0_02: 0.2419 - within_eps_0_05: 0.5419 - within_eps_0_1: 0.8234 - val_log_cosh: 0.0489 - val_loss: 0.0038 - val_within_eps_0_005: 0.0178 - val_within_eps_0_01: 0.0378 - val_within_eps_0_02: 0.0759 - val_within_eps_0_05: 0.1834 - val_within_eps_0_1: 0.3521\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0032 - loss: 8.8942e-04 - within_eps_0_005: 0.0620 - within_eps_0_01: 0.1234 - within_eps_0_02: 0.2414 - within_eps_0_05: 0.5434 - within_eps_0_1: 0.8237 - val_log_cosh: 0.0476 - val_loss: 0.0037 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0386 - val_within_eps_0_02: 0.0774 - val_within_eps_0_05: 0.1887 - val_within_eps_0_1: 0.3540\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0030 - loss: 8.5776e-04 - within_eps_0_005: 0.0645 - within_eps_0_01: 0.1291 - within_eps_0_02: 0.2502 - within_eps_0_05: 0.5583 - within_eps_0_1: 0.8340 - val_log_cosh: 0.0540 - val_loss: 0.0041 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0326 - val_within_eps_0_02: 0.0681 - val_within_eps_0_05: 0.1573 - val_within_eps_0_1: 0.3039\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0027 - loss: 8.0946e-04 - within_eps_0_005: 0.0695 - within_eps_0_01: 0.1355 - within_eps_0_02: 0.2636 - within_eps_0_05: 0.5792 - within_eps_0_1: 0.8499 - val_log_cosh: 0.0536 - val_loss: 0.0041 - val_within_eps_0_005: 0.0213 - val_within_eps_0_01: 0.0399 - val_within_eps_0_02: 0.0723 - val_within_eps_0_05: 0.1636 - val_within_eps_0_1: 0.3237\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0028 - loss: 8.1460e-04 - within_eps_0_005: 0.0664 - within_eps_0_01: 0.1341 - within_eps_0_02: 0.2646 - within_eps_0_05: 0.5779 - within_eps_0_1: 0.8495 - val_log_cosh: 0.0535 - val_loss: 0.0041 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0346 - val_within_eps_0_02: 0.0706 - val_within_eps_0_05: 0.1650 - val_within_eps_0_1: 0.3186\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0027 - loss: 8.0538e-04 - within_eps_0_005: 0.0693 - within_eps_0_01: 0.1350 - within_eps_0_02: 0.2637 - within_eps_0_05: 0.5823 - within_eps_0_1: 0.8520 - val_log_cosh: 0.0520 - val_loss: 0.0040 - val_within_eps_0_005: 0.0195 - val_within_eps_0_01: 0.0395 - val_within_eps_0_02: 0.0772 - val_within_eps_0_05: 0.1745 - val_within_eps_0_1: 0.3335\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0026 - loss: 7.7753e-04 - within_eps_0_005: 0.0684 - within_eps_0_01: 0.1373 - within_eps_0_02: 0.2744 - within_eps_0_05: 0.5969 - within_eps_0_1: 0.8621 - val_log_cosh: 0.0477 - val_loss: 0.0037 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0403 - val_within_eps_0_02: 0.0821 - val_within_eps_0_05: 0.2087 - val_within_eps_0_1: 0.3596\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0024 - loss: 7.5644e-04 - within_eps_0_005: 0.0723 - within_eps_0_01: 0.1422 - within_eps_0_02: 0.2778 - within_eps_0_05: 0.6044 - within_eps_0_1: 0.8693 - val_log_cosh: 0.0534 - val_loss: 0.0041 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0335 - val_within_eps_0_02: 0.0665 - val_within_eps_0_05: 0.1688 - val_within_eps_0_1: 0.3272\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0024 - loss: 7.4171e-04 - within_eps_0_005: 0.0743 - within_eps_0_01: 0.1464 - within_eps_0_02: 0.2880 - within_eps_0_05: 0.6151 - within_eps_0_1: 0.8744 - val_log_cosh: 0.0513 - val_loss: 0.0039 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0603 - val_within_eps_0_05: 0.1676 - val_within_eps_0_1: 0.3292\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0024 - loss: 7.4075e-04 - within_eps_0_005: 0.0730 - within_eps_0_01: 0.1479 - within_eps_0_02: 0.2890 - within_eps_0_05: 0.6154 - within_eps_0_1: 0.8733 - val_log_cosh: 0.0500 - val_loss: 0.0038 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0426 - val_within_eps_0_02: 0.0844 - val_within_eps_0_05: 0.1943 - val_within_eps_0_1: 0.3522\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0022 - loss: 7.0937e-04 - within_eps_0_005: 0.0756 - within_eps_0_01: 0.1504 - within_eps_0_02: 0.2980 - within_eps_0_05: 0.6284 - within_eps_0_1: 0.8854 - val_log_cosh: 0.0468 - val_loss: 0.0036 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0422 - val_within_eps_0_02: 0.0836 - val_within_eps_0_05: 0.2208 - val_within_eps_0_1: 0.3859\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0022 - loss: 7.0871e-04 - within_eps_0_005: 0.0761 - within_eps_0_01: 0.1526 - within_eps_0_02: 0.2989 - within_eps_0_05: 0.6313 - within_eps_0_1: 0.8840 - val_log_cosh: 0.0449 - val_loss: 0.0035 - val_within_eps_0_005: 0.0243 - val_within_eps_0_01: 0.0508 - val_within_eps_0_02: 0.0980 - val_within_eps_0_05: 0.2198 - val_within_eps_0_1: 0.3997\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0021 - loss: 6.9096e-04 - within_eps_0_005: 0.0782 - within_eps_0_01: 0.1565 - within_eps_0_02: 0.3037 - within_eps_0_05: 0.6385 - within_eps_0_1: 0.8898 - val_log_cosh: 0.0498 - val_loss: 0.0038 - val_within_eps_0_005: 0.0226 - val_within_eps_0_01: 0.0435 - val_within_eps_0_02: 0.0856 - val_within_eps_0_05: 0.2021 - val_within_eps_0_1: 0.3610\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0021 - loss: 6.9075e-04 - within_eps_0_005: 0.0761 - within_eps_0_01: 0.1532 - within_eps_0_02: 0.3028 - within_eps_0_05: 0.6402 - within_eps_0_1: 0.8906 - val_log_cosh: 0.0445 - val_loss: 0.0035 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0442 - val_within_eps_0_02: 0.0923 - val_within_eps_0_05: 0.2144 - val_within_eps_0_1: 0.3958\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0021 - loss: 6.7690e-04 - within_eps_0_005: 0.0818 - within_eps_0_01: 0.1590 - within_eps_0_02: 0.3077 - within_eps_0_05: 0.6492 - within_eps_0_1: 0.8962 - val_log_cosh: 0.0457 - val_loss: 0.0035 - val_within_eps_0_005: 0.0256 - val_within_eps_0_01: 0.0494 - val_within_eps_0_02: 0.0965 - val_within_eps_0_05: 0.2182 - val_within_eps_0_1: 0.3946\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0020 - loss: 6.6549e-04 - within_eps_0_005: 0.0815 - within_eps_0_01: 0.1611 - within_eps_0_02: 0.3106 - within_eps_0_05: 0.6503 - within_eps_0_1: 0.8982 - val_log_cosh: 0.0542 - val_loss: 0.0040 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0359 - val_within_eps_0_02: 0.0709 - val_within_eps_0_05: 0.1869 - val_within_eps_0_1: 0.3378\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0019 - loss: 6.4723e-04 - within_eps_0_005: 0.0828 - within_eps_0_01: 0.1675 - within_eps_0_02: 0.3222 - within_eps_0_05: 0.6618 - within_eps_0_1: 0.9042 - val_log_cosh: 0.0461 - val_loss: 0.0035 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0418 - val_within_eps_0_02: 0.0858 - val_within_eps_0_05: 0.2155 - val_within_eps_0_1: 0.3795\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 6.3624e-04 - within_eps_0_005: 0.0829 - within_eps_0_01: 0.1646 - within_eps_0_02: 0.3209 - within_eps_0_05: 0.6672 - within_eps_0_1: 0.9071 - val_log_cosh: 0.0492 - val_loss: 0.0037 - val_within_eps_0_005: 0.0210 - val_within_eps_0_01: 0.0415 - val_within_eps_0_02: 0.0818 - val_within_eps_0_05: 0.2038 - val_within_eps_0_1: 0.3594\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0019 - loss: 6.3379e-04 - within_eps_0_005: 0.0857 - within_eps_0_01: 0.1697 - within_eps_0_02: 0.3274 - within_eps_0_05: 0.6735 - within_eps_0_1: 0.9067 - val_log_cosh: 0.0487 - val_loss: 0.0037 - val_within_eps_0_005: 0.0248 - val_within_eps_0_01: 0.0505 - val_within_eps_0_02: 0.0976 - val_within_eps_0_05: 0.2160 - val_within_eps_0_1: 0.3750\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 6.1606e-04 - within_eps_0_005: 0.0908 - within_eps_0_01: 0.1775 - within_eps_0_02: 0.3378 - within_eps_0_05: 0.6811 - within_eps_0_1: 0.9124 - val_log_cosh: 0.0496 - val_loss: 0.0037 - val_within_eps_0_005: 0.0215 - val_within_eps_0_01: 0.0432 - val_within_eps_0_02: 0.0876 - val_within_eps_0_05: 0.2097 - val_within_eps_0_1: 0.3608\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0017 - loss: 6.0095e-04 - within_eps_0_005: 0.0890 - within_eps_0_01: 0.1765 - within_eps_0_02: 0.3414 - within_eps_0_05: 0.6895 - within_eps_0_1: 0.9174 - val_log_cosh: 0.0489 - val_loss: 0.0037 - val_within_eps_0_005: 0.0224 - val_within_eps_0_01: 0.0461 - val_within_eps_0_02: 0.0920 - val_within_eps_0_05: 0.2170 - val_within_eps_0_1: 0.3729\n",
      "Epoch 41/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 6.0726e-04 - within_eps_0_005: 0.0916 - within_eps_0_01: 0.1782 - within_eps_0_02: 0.3431 - within_eps_0_05: 0.6873 - within_eps_0_1: 0.9153 - val_log_cosh: 0.0496 - val_loss: 0.0037 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0450 - val_within_eps_0_02: 0.0891 - val_within_eps_0_05: 0.2070 - val_within_eps_0_1: 0.3665\n",
      "Epoch 42/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0017 - loss: 5.9816e-04 - within_eps_0_005: 0.0920 - within_eps_0_01: 0.1818 - within_eps_0_02: 0.3464 - within_eps_0_05: 0.6928 - within_eps_0_1: 0.9187 - val_log_cosh: 0.0487 - val_loss: 0.0037 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0441 - val_within_eps_0_02: 0.0876 - val_within_eps_0_05: 0.2050 - val_within_eps_0_1: 0.3743\n",
      "Epoch 43/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0016 - loss: 5.7827e-04 - within_eps_0_005: 0.0948 - within_eps_0_01: 0.1847 - within_eps_0_02: 0.3517 - within_eps_0_05: 0.7011 - within_eps_0_1: 0.9242 - val_log_cosh: 0.0495 - val_loss: 0.0037 - val_within_eps_0_005: 0.0248 - val_within_eps_0_01: 0.0471 - val_within_eps_0_02: 0.0923 - val_within_eps_0_05: 0.2126 - val_within_eps_0_1: 0.3773\n",
      "Epoch 44/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0016 - loss: 5.8003e-04 - within_eps_0_005: 0.0919 - within_eps_0_01: 0.1829 - within_eps_0_02: 0.3490 - within_eps_0_05: 0.6980 - within_eps_0_1: 0.9249 - val_log_cosh: 0.0495 - val_loss: 0.0037 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0403 - val_within_eps_0_02: 0.0795 - val_within_eps_0_05: 0.2025 - val_within_eps_0_1: 0.3658\n",
      "Epoch 45/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0016 - loss: 5.7976e-04 - within_eps_0_005: 0.0906 - within_eps_0_01: 0.1816 - within_eps_0_02: 0.3496 - within_eps_0_05: 0.7002 - within_eps_0_1: 0.9232 - val_log_cosh: 0.0452 - val_loss: 0.0034 - val_within_eps_0_005: 0.0243 - val_within_eps_0_01: 0.0505 - val_within_eps_0_02: 0.0972 - val_within_eps_0_05: 0.2261 - val_within_eps_0_1: 0.4092\n",
      "Epoch 46/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0015 - loss: 5.7201e-04 - within_eps_0_005: 0.0933 - within_eps_0_01: 0.1828 - within_eps_0_02: 0.3501 - within_eps_0_05: 0.7034 - within_eps_0_1: 0.9280 - val_log_cosh: 0.0459 - val_loss: 0.0035 - val_within_eps_0_005: 0.0249 - val_within_eps_0_01: 0.0505 - val_within_eps_0_02: 0.0999 - val_within_eps_0_05: 0.2236 - val_within_eps_0_1: 0.4012\n",
      "Epoch 47/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0015 - loss: 5.6684e-04 - within_eps_0_005: 0.0948 - within_eps_0_01: 0.1872 - within_eps_0_02: 0.3584 - within_eps_0_05: 0.7081 - within_eps_0_1: 0.9266 - val_log_cosh: 0.0476 - val_loss: 0.0036 - val_within_eps_0_005: 0.0227 - val_within_eps_0_01: 0.0447 - val_within_eps_0_02: 0.0898 - val_within_eps_0_05: 0.2157 - val_within_eps_0_1: 0.3811\n",
      "Epoch 48/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0015 - loss: 5.5616e-04 - within_eps_0_005: 0.0963 - within_eps_0_01: 0.1883 - within_eps_0_02: 0.3611 - within_eps_0_05: 0.7162 - within_eps_0_1: 0.9304 - val_log_cosh: 0.0488 - val_loss: 0.0036 - val_within_eps_0_005: 0.0217 - val_within_eps_0_01: 0.0450 - val_within_eps_0_02: 0.0879 - val_within_eps_0_05: 0.2139 - val_within_eps_0_1: 0.3751\n",
      "  -> val_log_cosh(min) δ=0.017357412725687027: 0.044514026493\n",
      "\n",
      "--- Entrenando δ=0.02 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - log_cosh: 0.3253 - loss: 0.0142 - within_eps_0_005: 0.0045 - within_eps_0_01: 0.0093 - within_eps_0_02: 0.0199 - within_eps_0_05: 0.0491 - within_eps_0_1: 0.0971 - val_log_cosh: 0.1434 - val_loss: 0.0083 - val_within_eps_0_005: 0.0102 - val_within_eps_0_01: 0.0202 - val_within_eps_0_02: 0.0410 - val_within_eps_0_05: 0.1009 - val_within_eps_0_1: 0.1987\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.1422 - loss: 0.0088 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0140 - within_eps_0_02: 0.0288 - within_eps_0_05: 0.0705 - within_eps_0_1: 0.1408 - val_log_cosh: 0.0934 - val_loss: 0.0063 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0555 - val_within_eps_0_05: 0.1408 - val_within_eps_0_1: 0.2655\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.1054 - loss: 0.0075 - within_eps_0_005: 0.0086 - within_eps_0_01: 0.0167 - within_eps_0_02: 0.0334 - within_eps_0_05: 0.0826 - within_eps_0_1: 0.1665 - val_log_cosh: 0.0807 - val_loss: 0.0059 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0251 - val_within_eps_0_02: 0.0490 - val_within_eps_0_05: 0.1268 - val_within_eps_0_1: 0.2381\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0779 - loss: 0.0063 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0195 - within_eps_0_02: 0.0407 - within_eps_0_05: 0.1012 - within_eps_0_1: 0.1994 - val_log_cosh: 0.0761 - val_loss: 0.0057 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0206 - val_within_eps_0_02: 0.0421 - val_within_eps_0_05: 0.1141 - val_within_eps_0_1: 0.2547\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0566 - loss: 0.0053 - within_eps_0_005: 0.0121 - within_eps_0_01: 0.0233 - within_eps_0_02: 0.0463 - within_eps_0_05: 0.1177 - within_eps_0_1: 0.2359 - val_log_cosh: 0.0741 - val_loss: 0.0055 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0576 - val_within_eps_0_05: 0.1452 - val_within_eps_0_1: 0.2727\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0396 - loss: 0.0043 - within_eps_0_005: 0.0154 - within_eps_0_01: 0.0301 - within_eps_0_02: 0.0593 - within_eps_0_05: 0.1438 - within_eps_0_1: 0.2830 - val_log_cosh: 0.0719 - val_loss: 0.0054 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0348 - val_within_eps_0_02: 0.0686 - val_within_eps_0_05: 0.1609 - val_within_eps_0_1: 0.2915\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0266 - loss: 0.0035 - within_eps_0_005: 0.0171 - within_eps_0_01: 0.0346 - within_eps_0_02: 0.0693 - within_eps_0_05: 0.1742 - within_eps_0_1: 0.3445 - val_log_cosh: 0.0748 - val_loss: 0.0055 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1390 - val_within_eps_0_1: 0.2931\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0168 - loss: 0.0027 - within_eps_0_005: 0.0234 - within_eps_0_01: 0.0462 - within_eps_0_02: 0.0929 - within_eps_0_05: 0.2307 - within_eps_0_1: 0.4400 - val_log_cosh: 0.0774 - val_loss: 0.0056 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0611 - val_within_eps_0_05: 0.1466 - val_within_eps_0_1: 0.2947\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0113 - loss: 0.0022 - within_eps_0_005: 0.0291 - within_eps_0_01: 0.0578 - within_eps_0_02: 0.1144 - within_eps_0_05: 0.2806 - within_eps_0_1: 0.5212 - val_log_cosh: 0.0658 - val_loss: 0.0050 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0373 - val_within_eps_0_02: 0.0722 - val_within_eps_0_05: 0.1689 - val_within_eps_0_1: 0.3108\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0085 - loss: 0.0018 - within_eps_0_005: 0.0331 - within_eps_0_01: 0.0665 - within_eps_0_02: 0.1361 - within_eps_0_05: 0.3279 - within_eps_0_1: 0.5903 - val_log_cosh: 0.0626 - val_loss: 0.0048 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0641 - val_within_eps_0_05: 0.1744 - val_within_eps_0_1: 0.3221\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0069 - loss: 0.0016 - within_eps_0_005: 0.0375 - within_eps_0_01: 0.0772 - within_eps_0_02: 0.1534 - within_eps_0_05: 0.3676 - within_eps_0_1: 0.6466 - val_log_cosh: 0.0604 - val_loss: 0.0047 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0419 - val_within_eps_0_02: 0.0832 - val_within_eps_0_05: 0.1918 - val_within_eps_0_1: 0.3261\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0061 - loss: 0.0015 - within_eps_0_005: 0.0414 - within_eps_0_01: 0.0819 - within_eps_0_02: 0.1640 - within_eps_0_05: 0.3927 - within_eps_0_1: 0.6779 - val_log_cosh: 0.0615 - val_loss: 0.0048 - val_within_eps_0_005: 0.0187 - val_within_eps_0_01: 0.0368 - val_within_eps_0_02: 0.0759 - val_within_eps_0_05: 0.1796 - val_within_eps_0_1: 0.3399\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0054 - loss: 0.0014 - within_eps_0_005: 0.0442 - within_eps_0_01: 0.0902 - within_eps_0_02: 0.1809 - within_eps_0_05: 0.4229 - within_eps_0_1: 0.7151 - val_log_cosh: 0.0602 - val_loss: 0.0047 - val_within_eps_0_005: 0.0205 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0757 - val_within_eps_0_05: 0.1853 - val_within_eps_0_1: 0.3440\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0049 - loss: 0.0013 - within_eps_0_005: 0.0474 - within_eps_0_01: 0.0950 - within_eps_0_02: 0.1896 - within_eps_0_05: 0.4413 - within_eps_0_1: 0.7334 - val_log_cosh: 0.0558 - val_loss: 0.0045 - val_within_eps_0_005: 0.0216 - val_within_eps_0_01: 0.0423 - val_within_eps_0_02: 0.0818 - val_within_eps_0_05: 0.2055 - val_within_eps_0_1: 0.3773\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0045 - loss: 0.0012 - within_eps_0_005: 0.0511 - within_eps_0_01: 0.1011 - within_eps_0_02: 0.2021 - within_eps_0_05: 0.4650 - within_eps_0_1: 0.7528 - val_log_cosh: 0.0544 - val_loss: 0.0044 - val_within_eps_0_005: 0.0207 - val_within_eps_0_01: 0.0419 - val_within_eps_0_02: 0.0845 - val_within_eps_0_05: 0.2123 - val_within_eps_0_1: 0.3801\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0043 - loss: 0.0012 - within_eps_0_005: 0.0509 - within_eps_0_01: 0.1043 - within_eps_0_02: 0.2066 - within_eps_0_05: 0.4766 - within_eps_0_1: 0.7655 - val_log_cosh: 0.0526 - val_loss: 0.0043 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0412 - val_within_eps_0_02: 0.0829 - val_within_eps_0_05: 0.2083 - val_within_eps_0_1: 0.3823\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0039 - loss: 0.0011 - within_eps_0_005: 0.0553 - within_eps_0_01: 0.1095 - within_eps_0_02: 0.2152 - within_eps_0_05: 0.4991 - within_eps_0_1: 0.7851 - val_log_cosh: 0.0469 - val_loss: 0.0040 - val_within_eps_0_005: 0.0215 - val_within_eps_0_01: 0.0445 - val_within_eps_0_02: 0.0903 - val_within_eps_0_05: 0.2205 - val_within_eps_0_1: 0.4080\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0039 - loss: 0.0011 - within_eps_0_005: 0.0557 - within_eps_0_01: 0.1108 - within_eps_0_02: 0.2172 - within_eps_0_05: 0.4998 - within_eps_0_1: 0.7872 - val_log_cosh: 0.0568 - val_loss: 0.0046 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0396 - val_within_eps_0_02: 0.0816 - val_within_eps_0_05: 0.1858 - val_within_eps_0_1: 0.3449\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0037 - loss: 0.0011 - within_eps_0_005: 0.0570 - within_eps_0_01: 0.1135 - within_eps_0_02: 0.2266 - within_eps_0_05: 0.5132 - within_eps_0_1: 0.7972 - val_log_cosh: 0.0469 - val_loss: 0.0040 - val_within_eps_0_005: 0.0249 - val_within_eps_0_01: 0.0507 - val_within_eps_0_02: 0.0987 - val_within_eps_0_05: 0.2298 - val_within_eps_0_1: 0.3978\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0033 - loss: 0.0010 - within_eps_0_005: 0.0611 - within_eps_0_01: 0.1212 - within_eps_0_02: 0.2390 - within_eps_0_05: 0.5367 - within_eps_0_1: 0.8181 - val_log_cosh: 0.0501 - val_loss: 0.0042 - val_within_eps_0_005: 0.0218 - val_within_eps_0_01: 0.0446 - val_within_eps_0_02: 0.0923 - val_within_eps_0_05: 0.2127 - val_within_eps_0_1: 0.3827\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0031 - loss: 9.8208e-04 - within_eps_0_005: 0.0633 - within_eps_0_01: 0.1243 - within_eps_0_02: 0.2451 - within_eps_0_05: 0.5533 - within_eps_0_1: 0.8324 - val_log_cosh: 0.0469 - val_loss: 0.0041 - val_within_eps_0_005: 0.0229 - val_within_eps_0_01: 0.0439 - val_within_eps_0_02: 0.0871 - val_within_eps_0_05: 0.2266 - val_within_eps_0_1: 0.3998\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0031 - loss: 9.8171e-04 - within_eps_0_005: 0.0621 - within_eps_0_01: 0.1272 - within_eps_0_02: 0.2485 - within_eps_0_05: 0.5525 - within_eps_0_1: 0.8306 - val_log_cosh: 0.0480 - val_loss: 0.0042 - val_within_eps_0_005: 0.0213 - val_within_eps_0_01: 0.0426 - val_within_eps_0_02: 0.0832 - val_within_eps_0_05: 0.2129 - val_within_eps_0_1: 0.3866\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0029 - loss: 9.4951e-04 - within_eps_0_005: 0.0656 - within_eps_0_01: 0.1295 - within_eps_0_02: 0.2567 - within_eps_0_05: 0.5637 - within_eps_0_1: 0.8403 - val_log_cosh: 0.0465 - val_loss: 0.0041 - val_within_eps_0_005: 0.0197 - val_within_eps_0_01: 0.0400 - val_within_eps_0_02: 0.0852 - val_within_eps_0_05: 0.2167 - val_within_eps_0_1: 0.3880\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0028 - loss: 9.0957e-04 - within_eps_0_005: 0.0679 - within_eps_0_01: 0.1360 - within_eps_0_02: 0.2662 - within_eps_0_05: 0.5814 - within_eps_0_1: 0.8535 - val_log_cosh: 0.0489 - val_loss: 0.0042 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0433 - val_within_eps_0_02: 0.0861 - val_within_eps_0_05: 0.2152 - val_within_eps_0_1: 0.3807\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0027 - loss: 9.0570e-04 - within_eps_0_005: 0.0682 - within_eps_0_01: 0.1370 - within_eps_0_02: 0.2693 - within_eps_0_05: 0.5862 - within_eps_0_1: 0.8510 - val_log_cosh: 0.0497 - val_loss: 0.0043 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0420 - val_within_eps_0_02: 0.0871 - val_within_eps_0_05: 0.2152 - val_within_eps_0_1: 0.3813\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0025 - loss: 8.6132e-04 - within_eps_0_005: 0.0710 - within_eps_0_01: 0.1403 - within_eps_0_02: 0.2746 - within_eps_0_05: 0.6019 - within_eps_0_1: 0.8651 - val_log_cosh: 0.0483 - val_loss: 0.0042 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0438 - val_within_eps_0_02: 0.0856 - val_within_eps_0_05: 0.2132 - val_within_eps_0_1: 0.3850\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0025 - loss: 8.6937e-04 - within_eps_0_005: 0.0705 - within_eps_0_01: 0.1401 - within_eps_0_02: 0.2741 - within_eps_0_05: 0.5975 - within_eps_0_1: 0.8626 - val_log_cosh: 0.0522 - val_loss: 0.0044 - val_within_eps_0_005: 0.0210 - val_within_eps_0_01: 0.0413 - val_within_eps_0_02: 0.0845 - val_within_eps_0_05: 0.1994 - val_within_eps_0_1: 0.3648\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0025 - loss: 8.5619e-04 - within_eps_0_005: 0.0724 - within_eps_0_01: 0.1446 - within_eps_0_02: 0.2808 - within_eps_0_05: 0.6022 - within_eps_0_1: 0.8670 - val_log_cosh: 0.0468 - val_loss: 0.0041 - val_within_eps_0_005: 0.0209 - val_within_eps_0_01: 0.0425 - val_within_eps_0_02: 0.0875 - val_within_eps_0_05: 0.2159 - val_within_eps_0_1: 0.3932\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0024 - loss: 8.3536e-04 - within_eps_0_005: 0.0725 - within_eps_0_01: 0.1450 - within_eps_0_02: 0.2857 - within_eps_0_05: 0.6126 - within_eps_0_1: 0.8718 - val_log_cosh: 0.0456 - val_loss: 0.0040 - val_within_eps_0_005: 0.0219 - val_within_eps_0_01: 0.0423 - val_within_eps_0_02: 0.0885 - val_within_eps_0_05: 0.2216 - val_within_eps_0_1: 0.4033\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0023 - loss: 8.1035e-04 - within_eps_0_005: 0.0775 - within_eps_0_01: 0.1519 - within_eps_0_02: 0.2974 - within_eps_0_05: 0.6264 - within_eps_0_1: 0.8801 - val_log_cosh: 0.0472 - val_loss: 0.0041 - val_within_eps_0_005: 0.0206 - val_within_eps_0_01: 0.0433 - val_within_eps_0_02: 0.0916 - val_within_eps_0_05: 0.2177 - val_within_eps_0_1: 0.3905\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0022 - loss: 7.9057e-04 - within_eps_0_005: 0.0781 - within_eps_0_01: 0.1558 - within_eps_0_02: 0.2994 - within_eps_0_05: 0.6339 - within_eps_0_1: 0.8849 - val_log_cosh: 0.0455 - val_loss: 0.0040 - val_within_eps_0_005: 0.0245 - val_within_eps_0_01: 0.0478 - val_within_eps_0_02: 0.0919 - val_within_eps_0_05: 0.2277 - val_within_eps_0_1: 0.4102\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0022 - loss: 7.8754e-04 - within_eps_0_005: 0.0791 - within_eps_0_01: 0.1572 - within_eps_0_02: 0.3010 - within_eps_0_05: 0.6345 - within_eps_0_1: 0.8854 - val_log_cosh: 0.0459 - val_loss: 0.0041 - val_within_eps_0_005: 0.0247 - val_within_eps_0_01: 0.0470 - val_within_eps_0_02: 0.0906 - val_within_eps_0_05: 0.2158 - val_within_eps_0_1: 0.3947\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0021 - loss: 7.6536e-04 - within_eps_0_005: 0.0789 - within_eps_0_01: 0.1582 - within_eps_0_02: 0.3082 - within_eps_0_05: 0.6460 - within_eps_0_1: 0.8918 - val_log_cosh: 0.0496 - val_loss: 0.0043 - val_within_eps_0_005: 0.0211 - val_within_eps_0_01: 0.0413 - val_within_eps_0_02: 0.0800 - val_within_eps_0_05: 0.1907 - val_within_eps_0_1: 0.3522\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0020 - loss: 7.5982e-04 - within_eps_0_005: 0.0788 - within_eps_0_01: 0.1574 - within_eps_0_02: 0.3041 - within_eps_0_05: 0.6461 - within_eps_0_1: 0.8943 - val_log_cosh: 0.0520 - val_loss: 0.0044 - val_within_eps_0_005: 0.0224 - val_within_eps_0_01: 0.0426 - val_within_eps_0_02: 0.0837 - val_within_eps_0_05: 0.1994 - val_within_eps_0_1: 0.3633\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0020 - loss: 7.4555e-04 - within_eps_0_005: 0.0801 - within_eps_0_01: 0.1612 - within_eps_0_02: 0.3131 - within_eps_0_05: 0.6538 - within_eps_0_1: 0.8990 - val_log_cosh: 0.0455 - val_loss: 0.0040 - val_within_eps_0_005: 0.0226 - val_within_eps_0_01: 0.0455 - val_within_eps_0_02: 0.0894 - val_within_eps_0_05: 0.2254 - val_within_eps_0_1: 0.3958\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0020 - loss: 7.3081e-04 - within_eps_0_005: 0.0851 - within_eps_0_01: 0.1688 - within_eps_0_02: 0.3225 - within_eps_0_05: 0.6635 - within_eps_0_1: 0.9020 - val_log_cosh: 0.0469 - val_loss: 0.0041 - val_within_eps_0_005: 0.0223 - val_within_eps_0_01: 0.0431 - val_within_eps_0_02: 0.0848 - val_within_eps_0_05: 0.2029 - val_within_eps_0_1: 0.3803\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0019 - loss: 7.2304e-04 - within_eps_0_005: 0.0827 - within_eps_0_01: 0.1669 - within_eps_0_02: 0.3252 - within_eps_0_05: 0.6635 - within_eps_0_1: 0.9031 - val_log_cosh: 0.0480 - val_loss: 0.0041 - val_within_eps_0_005: 0.0219 - val_within_eps_0_01: 0.0448 - val_within_eps_0_02: 0.0906 - val_within_eps_0_05: 0.2115 - val_within_eps_0_1: 0.3924\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0019 - loss: 7.0858e-04 - within_eps_0_005: 0.0873 - within_eps_0_01: 0.1715 - within_eps_0_02: 0.3282 - within_eps_0_05: 0.6731 - within_eps_0_1: 0.9074 - val_log_cosh: 0.0459 - val_loss: 0.0040 - val_within_eps_0_005: 0.0233 - val_within_eps_0_01: 0.0470 - val_within_eps_0_02: 0.0916 - val_within_eps_0_05: 0.2162 - val_within_eps_0_1: 0.4048\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 7.0718e-04 - within_eps_0_005: 0.0883 - within_eps_0_01: 0.1717 - within_eps_0_02: 0.3264 - within_eps_0_05: 0.6746 - within_eps_0_1: 0.9077 - val_log_cosh: 0.0544 - val_loss: 0.0046 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0691 - val_within_eps_0_05: 0.1740 - val_within_eps_0_1: 0.3310\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 7.0024e-04 - within_eps_0_005: 0.0867 - within_eps_0_01: 0.1715 - within_eps_0_02: 0.3328 - within_eps_0_05: 0.6772 - within_eps_0_1: 0.9093 - val_log_cosh: 0.0488 - val_loss: 0.0043 - val_within_eps_0_005: 0.0219 - val_within_eps_0_01: 0.0436 - val_within_eps_0_02: 0.0819 - val_within_eps_0_05: 0.1879 - val_within_eps_0_1: 0.3556\n",
      "Epoch 41/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0017 - loss: 6.7901e-04 - within_eps_0_005: 0.0893 - within_eps_0_01: 0.1778 - within_eps_0_02: 0.3423 - within_eps_0_05: 0.6831 - within_eps_0_1: 0.9146 - val_log_cosh: 0.0438 - val_loss: 0.0040 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0409 - val_within_eps_0_02: 0.0824 - val_within_eps_0_05: 0.2062 - val_within_eps_0_1: 0.3837\n",
      "Epoch 42/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0017 - loss: 6.7365e-04 - within_eps_0_005: 0.0918 - within_eps_0_01: 0.1806 - within_eps_0_02: 0.3434 - within_eps_0_05: 0.6889 - within_eps_0_1: 0.9161 - val_log_cosh: 0.0490 - val_loss: 0.0043 - val_within_eps_0_005: 0.0229 - val_within_eps_0_01: 0.0434 - val_within_eps_0_02: 0.0825 - val_within_eps_0_05: 0.1870 - val_within_eps_0_1: 0.3621\n",
      "Epoch 43/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0017 - loss: 6.6481e-04 - within_eps_0_005: 0.0917 - within_eps_0_01: 0.1812 - within_eps_0_02: 0.3462 - within_eps_0_05: 0.6937 - within_eps_0_1: 0.9196 - val_log_cosh: 0.0474 - val_loss: 0.0042 - val_within_eps_0_005: 0.0185 - val_within_eps_0_01: 0.0381 - val_within_eps_0_02: 0.0740 - val_within_eps_0_05: 0.1825 - val_within_eps_0_1: 0.3531\n",
      "Epoch 44/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0016 - loss: 6.4610e-04 - within_eps_0_005: 0.0946 - within_eps_0_01: 0.1843 - within_eps_0_02: 0.3523 - within_eps_0_05: 0.7015 - within_eps_0_1: 0.9244 - val_log_cosh: 0.0453 - val_loss: 0.0040 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0470 - val_within_eps_0_02: 0.0898 - val_within_eps_0_05: 0.2031 - val_within_eps_0_1: 0.3851\n",
      "Epoch 45/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0016 - loss: 6.4231e-04 - within_eps_0_005: 0.0944 - within_eps_0_01: 0.1846 - within_eps_0_02: 0.3534 - within_eps_0_05: 0.7038 - within_eps_0_1: 0.9269 - val_log_cosh: 0.0479 - val_loss: 0.0042 - val_within_eps_0_005: 0.0213 - val_within_eps_0_01: 0.0436 - val_within_eps_0_02: 0.0838 - val_within_eps_0_05: 0.1969 - val_within_eps_0_1: 0.3754\n",
      "Epoch 46/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0015 - loss: 6.1606e-04 - within_eps_0_005: 0.1003 - within_eps_0_01: 0.1942 - within_eps_0_02: 0.3686 - within_eps_0_05: 0.7207 - within_eps_0_1: 0.9300 - val_log_cosh: 0.0498 - val_loss: 0.0044 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0376 - val_within_eps_0_02: 0.0737 - val_within_eps_0_05: 0.1768 - val_within_eps_0_1: 0.3446\n",
      "Epoch 47/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0016 - loss: 6.3619e-04 - within_eps_0_005: 0.0962 - within_eps_0_01: 0.1898 - within_eps_0_02: 0.3620 - within_eps_0_05: 0.7096 - within_eps_0_1: 0.9246 - val_log_cosh: 0.0469 - val_loss: 0.0042 - val_within_eps_0_005: 0.0235 - val_within_eps_0_01: 0.0471 - val_within_eps_0_02: 0.0906 - val_within_eps_0_05: 0.1992 - val_within_eps_0_1: 0.3764\n",
      "Epoch 48/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0015 - loss: 6.2342e-04 - within_eps_0_005: 0.0974 - within_eps_0_01: 0.1889 - within_eps_0_02: 0.3645 - within_eps_0_05: 0.7148 - within_eps_0_1: 0.9311 - val_log_cosh: 0.0476 - val_loss: 0.0042 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0449 - val_within_eps_0_02: 0.0894 - val_within_eps_0_05: 0.2123 - val_within_eps_0_1: 0.3791\n",
      "Epoch 49/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0016 - loss: 6.2908e-04 - within_eps_0_005: 0.0962 - within_eps_0_01: 0.1924 - within_eps_0_02: 0.3671 - within_eps_0_05: 0.7141 - within_eps_0_1: 0.9269 - val_log_cosh: 0.0513 - val_loss: 0.0045 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0373 - val_within_eps_0_02: 0.0735 - val_within_eps_0_05: 0.1770 - val_within_eps_0_1: 0.3393\n",
      "Epoch 50/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0014 - loss: 5.9306e-04 - within_eps_0_005: 0.0997 - within_eps_0_01: 0.1979 - within_eps_0_02: 0.3797 - within_eps_0_05: 0.7313 - within_eps_0_1: 0.9354 - val_log_cosh: 0.0486 - val_loss: 0.0043 - val_within_eps_0_005: 0.0185 - val_within_eps_0_01: 0.0394 - val_within_eps_0_02: 0.0791 - val_within_eps_0_05: 0.1936 - val_within_eps_0_1: 0.3606\n",
      "Epoch 51/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0014 - loss: 5.9308e-04 - within_eps_0_005: 0.1025 - within_eps_0_01: 0.2005 - within_eps_0_02: 0.3787 - within_eps_0_05: 0.7345 - within_eps_0_1: 0.9361 - val_log_cosh: 0.0604 - val_loss: 0.0050 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0277 - val_within_eps_0_02: 0.0550 - val_within_eps_0_05: 0.1451 - val_within_eps_0_1: 0.2836\n",
      "Epoch 52/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0014 - loss: 5.8650e-04 - within_eps_0_005: 0.1039 - within_eps_0_01: 0.2035 - within_eps_0_02: 0.3810 - within_eps_0_05: 0.7351 - within_eps_0_1: 0.9392 - val_log_cosh: 0.0495 - val_loss: 0.0043 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0381 - val_within_eps_0_02: 0.0762 - val_within_eps_0_05: 0.1904 - val_within_eps_0_1: 0.3586\n",
      "Epoch 53/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0014 - loss: 5.7893e-04 - within_eps_0_005: 0.1039 - within_eps_0_01: 0.2028 - within_eps_0_02: 0.3868 - within_eps_0_05: 0.7393 - within_eps_0_1: 0.9405 - val_log_cosh: 0.0577 - val_loss: 0.0049 - val_within_eps_0_005: 0.0108 - val_within_eps_0_01: 0.0215 - val_within_eps_0_02: 0.0448 - val_within_eps_0_05: 0.1303 - val_within_eps_0_1: 0.2830\n",
      "Epoch 54/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0014 - loss: 5.8585e-04 - within_eps_0_005: 0.0990 - within_eps_0_01: 0.2011 - within_eps_0_02: 0.3816 - within_eps_0_05: 0.7314 - within_eps_0_1: 0.9385 - val_log_cosh: 0.0531 - val_loss: 0.0046 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0366 - val_within_eps_0_02: 0.0724 - val_within_eps_0_05: 0.1711 - val_within_eps_0_1: 0.3309\n",
      "Epoch 55/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0013 - loss: 5.7373e-04 - within_eps_0_005: 0.1017 - within_eps_0_01: 0.2023 - within_eps_0_02: 0.3841 - within_eps_0_05: 0.7396 - within_eps_0_1: 0.9426 - val_log_cosh: 0.0490 - val_loss: 0.0043 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0377 - val_within_eps_0_02: 0.0781 - val_within_eps_0_05: 0.1936 - val_within_eps_0_1: 0.3648\n",
      "Epoch 56/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0014 - loss: 5.7855e-04 - within_eps_0_005: 0.1028 - within_eps_0_01: 0.2040 - within_eps_0_02: 0.3876 - within_eps_0_05: 0.7415 - within_eps_0_1: 0.9391 - val_log_cosh: 0.0524 - val_loss: 0.0045 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0373 - val_within_eps_0_02: 0.0714 - val_within_eps_0_05: 0.1763 - val_within_eps_0_1: 0.3317\n",
      "  -> val_log_cosh(min) δ=0.02: 0.043790385127\n",
      "\n",
      "--- Entrenando δ=0.03049677610397339 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - log_cosh: 0.2607 - loss: 0.0188 - within_eps_0_005: 0.0052 - within_eps_0_01: 0.0107 - within_eps_0_02: 0.0208 - within_eps_0_05: 0.0523 - within_eps_0_1: 0.1061 - val_log_cosh: 0.1382 - val_loss: 0.0122 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0195 - val_within_eps_0_02: 0.0371 - val_within_eps_0_05: 0.0884 - val_within_eps_0_1: 0.1740\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.1348 - loss: 0.0129 - within_eps_0_005: 0.0069 - within_eps_0_01: 0.0143 - within_eps_0_02: 0.0285 - within_eps_0_05: 0.0725 - within_eps_0_1: 0.1451 - val_log_cosh: 0.1053 - val_loss: 0.0101 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0217 - val_within_eps_0_02: 0.0439 - val_within_eps_0_05: 0.1084 - val_within_eps_0_1: 0.2161\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0967 - loss: 0.0107 - within_eps_0_005: 0.0084 - within_eps_0_01: 0.0170 - within_eps_0_02: 0.0345 - within_eps_0_05: 0.0878 - within_eps_0_1: 0.1748 - val_log_cosh: 0.0816 - val_loss: 0.0087 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1260 - val_within_eps_0_1: 0.2557\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0704 - loss: 0.0089 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0217 - within_eps_0_02: 0.0424 - within_eps_0_05: 0.1059 - within_eps_0_1: 0.2082 - val_log_cosh: 0.0764 - val_loss: 0.0082 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0278 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1625 - val_within_eps_0_1: 0.2943\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0488 - loss: 0.0072 - within_eps_0_005: 0.0138 - within_eps_0_01: 0.0265 - within_eps_0_02: 0.0516 - within_eps_0_05: 0.1286 - within_eps_0_1: 0.2545 - val_log_cosh: 0.0692 - val_loss: 0.0077 - val_within_eps_0_005: 0.0176 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0667 - val_within_eps_0_05: 0.1663 - val_within_eps_0_1: 0.3045\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0334 - loss: 0.0058 - within_eps_0_005: 0.0167 - within_eps_0_01: 0.0332 - within_eps_0_02: 0.0665 - within_eps_0_05: 0.1613 - within_eps_0_1: 0.3169 - val_log_cosh: 0.0609 - val_loss: 0.0072 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0363 - val_within_eps_0_02: 0.0696 - val_within_eps_0_05: 0.1706 - val_within_eps_0_1: 0.3106\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0229 - loss: 0.0047 - within_eps_0_005: 0.0208 - within_eps_0_01: 0.0411 - within_eps_0_02: 0.0823 - within_eps_0_05: 0.2007 - within_eps_0_1: 0.3835 - val_log_cosh: 0.0600 - val_loss: 0.0071 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0376 - val_within_eps_0_02: 0.0795 - val_within_eps_0_05: 0.1820 - val_within_eps_0_1: 0.3257\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0156 - loss: 0.0038 - within_eps_0_005: 0.0246 - within_eps_0_01: 0.0500 - within_eps_0_02: 0.0993 - within_eps_0_05: 0.2421 - within_eps_0_1: 0.4599 - val_log_cosh: 0.0650 - val_loss: 0.0075 - val_within_eps_0_005: 0.0183 - val_within_eps_0_01: 0.0356 - val_within_eps_0_02: 0.0702 - val_within_eps_0_05: 0.1770 - val_within_eps_0_1: 0.3264\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0114 - loss: 0.0031 - within_eps_0_005: 0.0292 - within_eps_0_01: 0.0588 - within_eps_0_02: 0.1161 - within_eps_0_05: 0.2841 - within_eps_0_1: 0.5269 - val_log_cosh: 0.0700 - val_loss: 0.0079 - val_within_eps_0_005: 0.0182 - val_within_eps_0_01: 0.0346 - val_within_eps_0_02: 0.0664 - val_within_eps_0_05: 0.1621 - val_within_eps_0_1: 0.3138\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0084 - loss: 0.0026 - within_eps_0_005: 0.0360 - within_eps_0_01: 0.0719 - within_eps_0_02: 0.1403 - within_eps_0_05: 0.3359 - within_eps_0_1: 0.5989 - val_log_cosh: 0.0583 - val_loss: 0.0070 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0392 - val_within_eps_0_02: 0.0739 - val_within_eps_0_05: 0.1734 - val_within_eps_0_1: 0.3349\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0065 - loss: 0.0022 - within_eps_0_005: 0.0389 - within_eps_0_01: 0.0797 - within_eps_0_02: 0.1596 - within_eps_0_05: 0.3781 - within_eps_0_1: 0.6571 - val_log_cosh: 0.0664 - val_loss: 0.0077 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0383 - val_within_eps_0_02: 0.0754 - val_within_eps_0_05: 0.1725 - val_within_eps_0_1: 0.3217\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0057 - loss: 0.0021 - within_eps_0_005: 0.0436 - within_eps_0_01: 0.0867 - within_eps_0_02: 0.1711 - within_eps_0_05: 0.4064 - within_eps_0_1: 0.6950 - val_log_cosh: 0.0595 - val_loss: 0.0071 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0328 - val_within_eps_0_02: 0.0689 - val_within_eps_0_05: 0.1768 - val_within_eps_0_1: 0.3513\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0052 - loss: 0.0019 - within_eps_0_005: 0.0466 - within_eps_0_01: 0.0942 - within_eps_0_02: 0.1851 - within_eps_0_05: 0.4316 - within_eps_0_1: 0.7193 - val_log_cosh: 0.0560 - val_loss: 0.0068 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0790 - val_within_eps_0_05: 0.1883 - val_within_eps_0_1: 0.3674\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0045 - loss: 0.0018 - within_eps_0_005: 0.0505 - within_eps_0_01: 0.1005 - within_eps_0_02: 0.1973 - within_eps_0_05: 0.4593 - within_eps_0_1: 0.7503 - val_log_cosh: 0.0479 - val_loss: 0.0062 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0482 - val_within_eps_0_02: 0.0974 - val_within_eps_0_05: 0.2212 - val_within_eps_0_1: 0.3791\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0042 - loss: 0.0017 - within_eps_0_005: 0.0518 - within_eps_0_01: 0.1047 - within_eps_0_02: 0.2032 - within_eps_0_05: 0.4723 - within_eps_0_1: 0.7664 - val_log_cosh: 0.0530 - val_loss: 0.0066 - val_within_eps_0_005: 0.0210 - val_within_eps_0_01: 0.0438 - val_within_eps_0_02: 0.0857 - val_within_eps_0_05: 0.2131 - val_within_eps_0_1: 0.3895\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0040 - loss: 0.0016 - within_eps_0_005: 0.0523 - within_eps_0_01: 0.1041 - within_eps_0_02: 0.2100 - within_eps_0_05: 0.4844 - within_eps_0_1: 0.7780 - val_log_cosh: 0.0574 - val_loss: 0.0069 - val_within_eps_0_005: 0.0208 - val_within_eps_0_01: 0.0411 - val_within_eps_0_02: 0.0834 - val_within_eps_0_05: 0.1977 - val_within_eps_0_1: 0.3729\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0037 - loss: 0.0016 - within_eps_0_005: 0.0563 - within_eps_0_01: 0.1110 - within_eps_0_02: 0.2190 - within_eps_0_05: 0.4995 - within_eps_0_1: 0.7886 - val_log_cosh: 0.0465 - val_loss: 0.0061 - val_within_eps_0_005: 0.0232 - val_within_eps_0_01: 0.0460 - val_within_eps_0_02: 0.0915 - val_within_eps_0_05: 0.2252 - val_within_eps_0_1: 0.3858\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0036 - loss: 0.0015 - within_eps_0_005: 0.0594 - within_eps_0_01: 0.1158 - within_eps_0_02: 0.2289 - within_eps_0_05: 0.5092 - within_eps_0_1: 0.8000 - val_log_cosh: 0.0484 - val_loss: 0.0062 - val_within_eps_0_005: 0.0237 - val_within_eps_0_01: 0.0473 - val_within_eps_0_02: 0.0942 - val_within_eps_0_05: 0.2349 - val_within_eps_0_1: 0.3932\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0033 - loss: 0.0015 - within_eps_0_005: 0.0590 - within_eps_0_01: 0.1204 - within_eps_0_02: 0.2340 - within_eps_0_05: 0.5257 - within_eps_0_1: 0.8098 - val_log_cosh: 0.0527 - val_loss: 0.0066 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0410 - val_within_eps_0_02: 0.0852 - val_within_eps_0_05: 0.2025 - val_within_eps_0_1: 0.3694\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0033 - loss: 0.0014 - within_eps_0_005: 0.0584 - within_eps_0_01: 0.1194 - within_eps_0_02: 0.2376 - within_eps_0_05: 0.5321 - within_eps_0_1: 0.8149 - val_log_cosh: 0.0513 - val_loss: 0.0065 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0410 - val_within_eps_0_02: 0.0805 - val_within_eps_0_05: 0.2044 - val_within_eps_0_1: 0.3766\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0030 - loss: 0.0014 - within_eps_0_005: 0.0655 - within_eps_0_01: 0.1264 - within_eps_0_02: 0.2527 - within_eps_0_05: 0.5500 - within_eps_0_1: 0.8286 - val_log_cosh: 0.0522 - val_loss: 0.0066 - val_within_eps_0_005: 0.0213 - val_within_eps_0_01: 0.0450 - val_within_eps_0_02: 0.0886 - val_within_eps_0_05: 0.2077 - val_within_eps_0_1: 0.3798\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0029 - loss: 0.0013 - within_eps_0_005: 0.0656 - within_eps_0_01: 0.1325 - within_eps_0_02: 0.2582 - within_eps_0_05: 0.5658 - within_eps_0_1: 0.8400 - val_log_cosh: 0.0620 - val_loss: 0.0076 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0637 - val_within_eps_0_05: 0.1564 - val_within_eps_0_1: 0.2899\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0029 - loss: 0.0013 - within_eps_0_005: 0.0660 - within_eps_0_01: 0.1321 - within_eps_0_02: 0.2603 - within_eps_0_05: 0.5711 - within_eps_0_1: 0.8442 - val_log_cosh: 0.0460 - val_loss: 0.0061 - val_within_eps_0_005: 0.0243 - val_within_eps_0_01: 0.0471 - val_within_eps_0_02: 0.0917 - val_within_eps_0_05: 0.2069 - val_within_eps_0_1: 0.3837\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0025 - loss: 0.0012 - within_eps_0_005: 0.0710 - within_eps_0_01: 0.1401 - within_eps_0_02: 0.2743 - within_eps_0_05: 0.5927 - within_eps_0_1: 0.8612 - val_log_cosh: 0.0501 - val_loss: 0.0064 - val_within_eps_0_005: 0.0218 - val_within_eps_0_01: 0.0392 - val_within_eps_0_02: 0.0798 - val_within_eps_0_05: 0.2001 - val_within_eps_0_1: 0.3644\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0026 - loss: 0.0012 - within_eps_0_005: 0.0697 - within_eps_0_01: 0.1407 - within_eps_0_02: 0.2716 - within_eps_0_05: 0.5890 - within_eps_0_1: 0.8554 - val_log_cosh: 0.0527 - val_loss: 0.0067 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0327 - val_within_eps_0_02: 0.0694 - val_within_eps_0_05: 0.1860 - val_within_eps_0_1: 0.3423\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0024 - loss: 0.0012 - within_eps_0_005: 0.0713 - within_eps_0_01: 0.1426 - within_eps_0_02: 0.2798 - within_eps_0_05: 0.6006 - within_eps_0_1: 0.8659 - val_log_cosh: 0.0532 - val_loss: 0.0067 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0348 - val_within_eps_0_02: 0.0690 - val_within_eps_0_05: 0.1806 - val_within_eps_0_1: 0.3446\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0024 - loss: 0.0012 - within_eps_0_005: 0.0741 - within_eps_0_01: 0.1451 - within_eps_0_02: 0.2822 - within_eps_0_05: 0.6083 - within_eps_0_1: 0.8732 - val_log_cosh: 0.0549 - val_loss: 0.0069 - val_within_eps_0_005: 0.0170 - val_within_eps_0_01: 0.0358 - val_within_eps_0_02: 0.0737 - val_within_eps_0_05: 0.1815 - val_within_eps_0_1: 0.3392\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - log_cosh: 0.0023 - loss: 0.0011 - within_eps_0_005: 0.0778 - within_eps_0_01: 0.1534 - within_eps_0_02: 0.2913 - within_eps_0_05: 0.6187 - within_eps_0_1: 0.8763 - val_log_cosh: 0.0593 - val_loss: 0.0073 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0631 - val_within_eps_0_05: 0.1629 - val_within_eps_0_1: 0.3023\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0023 - loss: 0.0011 - within_eps_0_005: 0.0754 - within_eps_0_01: 0.1509 - within_eps_0_02: 0.2937 - within_eps_0_05: 0.6235 - within_eps_0_1: 0.8767 - val_log_cosh: 0.0470 - val_loss: 0.0062 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0429 - val_within_eps_0_02: 0.0849 - val_within_eps_0_05: 0.2167 - val_within_eps_0_1: 0.3907\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0022 - loss: 0.0011 - within_eps_0_005: 0.0771 - within_eps_0_01: 0.1543 - within_eps_0_02: 0.2952 - within_eps_0_05: 0.6288 - within_eps_0_1: 0.8815 - val_log_cosh: 0.0526 - val_loss: 0.0067 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0756 - val_within_eps_0_05: 0.1962 - val_within_eps_0_1: 0.3616\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0021 - loss: 0.0011 - within_eps_0_005: 0.0808 - within_eps_0_01: 0.1591 - within_eps_0_02: 0.3087 - within_eps_0_05: 0.6370 - within_eps_0_1: 0.8885 - val_log_cosh: 0.0532 - val_loss: 0.0067 - val_within_eps_0_005: 0.0202 - val_within_eps_0_01: 0.0381 - val_within_eps_0_02: 0.0784 - val_within_eps_0_05: 0.1938 - val_within_eps_0_1: 0.3559\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0020 - loss: 0.0010 - within_eps_0_005: 0.0849 - within_eps_0_01: 0.1665 - within_eps_0_02: 0.3170 - within_eps_0_05: 0.6500 - within_eps_0_1: 0.8957 - val_log_cosh: 0.0483 - val_loss: 0.0062 - val_within_eps_0_005: 0.0226 - val_within_eps_0_01: 0.0450 - val_within_eps_0_02: 0.0932 - val_within_eps_0_05: 0.2195 - val_within_eps_0_1: 0.4024\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0021 - loss: 0.0010 - within_eps_0_005: 0.0815 - within_eps_0_01: 0.1623 - within_eps_0_02: 0.3128 - within_eps_0_05: 0.6457 - within_eps_0_1: 0.8916 - val_log_cosh: 0.0528 - val_loss: 0.0067 - val_within_eps_0_005: 0.0197 - val_within_eps_0_01: 0.0399 - val_within_eps_0_02: 0.0780 - val_within_eps_0_05: 0.1880 - val_within_eps_0_1: 0.3498\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0020 - loss: 0.0010 - within_eps_0_005: 0.0859 - within_eps_0_01: 0.1657 - within_eps_0_02: 0.3167 - within_eps_0_05: 0.6506 - within_eps_0_1: 0.8980 - val_log_cosh: 0.0480 - val_loss: 0.0062 - val_within_eps_0_005: 0.0241 - val_within_eps_0_01: 0.0460 - val_within_eps_0_02: 0.0911 - val_within_eps_0_05: 0.2219 - val_within_eps_0_1: 0.3905\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0020 - loss: 0.0010 - within_eps_0_005: 0.0853 - within_eps_0_01: 0.1705 - within_eps_0_02: 0.3223 - within_eps_0_05: 0.6529 - within_eps_0_1: 0.8938 - val_log_cosh: 0.0481 - val_loss: 0.0062 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0458 - val_within_eps_0_02: 0.0916 - val_within_eps_0_05: 0.2223 - val_within_eps_0_1: 0.3854\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0019 - loss: 9.8585e-04 - within_eps_0_005: 0.0848 - within_eps_0_01: 0.1719 - within_eps_0_02: 0.3283 - within_eps_0_05: 0.6656 - within_eps_0_1: 0.9005 - val_log_cosh: 0.0556 - val_loss: 0.0070 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0369 - val_within_eps_0_02: 0.0736 - val_within_eps_0_05: 0.1803 - val_within_eps_0_1: 0.3224\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0019 - loss: 9.8783e-04 - within_eps_0_005: 0.0837 - within_eps_0_01: 0.1679 - within_eps_0_02: 0.3253 - within_eps_0_05: 0.6617 - within_eps_0_1: 0.9027 - val_log_cosh: 0.0542 - val_loss: 0.0068 - val_within_eps_0_005: 0.0179 - val_within_eps_0_01: 0.0364 - val_within_eps_0_02: 0.0758 - val_within_eps_0_05: 0.1897 - val_within_eps_0_1: 0.3457\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0018 - loss: 9.4214e-04 - within_eps_0_005: 0.0867 - within_eps_0_01: 0.1729 - within_eps_0_02: 0.3382 - within_eps_0_05: 0.6786 - within_eps_0_1: 0.9086 - val_log_cosh: 0.0534 - val_loss: 0.0067 - val_within_eps_0_005: 0.0200 - val_within_eps_0_01: 0.0395 - val_within_eps_0_02: 0.0780 - val_within_eps_0_05: 0.1881 - val_within_eps_0_1: 0.3479\n",
      "  -> val_log_cosh(min) δ=0.03049677610397339: 0.045992057770\n",
      "\n",
      "--- Entrenando δ=0.04116208553314208 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - log_cosh: 0.2831 - loss: 0.0263 - within_eps_0_005: 0.0053 - within_eps_0_01: 0.0101 - within_eps_0_02: 0.0211 - within_eps_0_05: 0.0529 - within_eps_0_1: 0.1053 - val_log_cosh: 0.1283 - val_loss: 0.0158 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0537 - val_within_eps_0_05: 0.1214 - val_within_eps_0_1: 0.2229\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.1247 - loss: 0.0164 - within_eps_0_005: 0.0076 - within_eps_0_01: 0.0152 - within_eps_0_02: 0.0294 - within_eps_0_05: 0.0747 - within_eps_0_1: 0.1508 - val_log_cosh: 0.0799 - val_loss: 0.0116 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0581 - val_within_eps_0_05: 0.1358 - val_within_eps_0_1: 0.2561\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0909 - loss: 0.0136 - within_eps_0_005: 0.0095 - within_eps_0_01: 0.0189 - within_eps_0_02: 0.0372 - within_eps_0_05: 0.0956 - within_eps_0_1: 0.1873 - val_log_cosh: 0.0686 - val_loss: 0.0103 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1505 - val_within_eps_0_1: 0.2935\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0641 - loss: 0.0111 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0234 - within_eps_0_02: 0.0455 - within_eps_0_05: 0.1146 - within_eps_0_1: 0.2253 - val_log_cosh: 0.0580 - val_loss: 0.0093 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0600 - val_within_eps_0_05: 0.1553 - val_within_eps_0_1: 0.3196\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0421 - loss: 0.0087 - within_eps_0_005: 0.0143 - within_eps_0_01: 0.0288 - within_eps_0_02: 0.0590 - within_eps_0_05: 0.1456 - within_eps_0_1: 0.2875 - val_log_cosh: 0.0541 - val_loss: 0.0087 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0814 - val_within_eps_0_05: 0.1984 - val_within_eps_0_1: 0.3556\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0279 - loss: 0.0068 - within_eps_0_005: 0.0186 - within_eps_0_01: 0.0367 - within_eps_0_02: 0.0736 - within_eps_0_05: 0.1843 - within_eps_0_1: 0.3552 - val_log_cosh: 0.0500 - val_loss: 0.0084 - val_within_eps_0_005: 0.0202 - val_within_eps_0_01: 0.0400 - val_within_eps_0_02: 0.0775 - val_within_eps_0_05: 0.1834 - val_within_eps_0_1: 0.3455\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0192 - loss: 0.0055 - within_eps_0_005: 0.0243 - within_eps_0_01: 0.0474 - within_eps_0_02: 0.0921 - within_eps_0_05: 0.2265 - within_eps_0_1: 0.4294 - val_log_cosh: 0.0519 - val_loss: 0.0086 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0379 - val_within_eps_0_02: 0.0743 - val_within_eps_0_05: 0.1807 - val_within_eps_0_1: 0.3242\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0130 - loss: 0.0044 - within_eps_0_005: 0.0294 - within_eps_0_01: 0.0567 - within_eps_0_02: 0.1105 - within_eps_0_05: 0.2726 - within_eps_0_1: 0.5056 - val_log_cosh: 0.0487 - val_loss: 0.0082 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0395 - val_within_eps_0_02: 0.0759 - val_within_eps_0_05: 0.1868 - val_within_eps_0_1: 0.3452\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0095 - loss: 0.0036 - within_eps_0_005: 0.0338 - within_eps_0_01: 0.0647 - within_eps_0_02: 0.1297 - within_eps_0_05: 0.3153 - within_eps_0_1: 0.5767 - val_log_cosh: 0.0419 - val_loss: 0.0076 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0385 - val_within_eps_0_02: 0.0784 - val_within_eps_0_05: 0.1955 - val_within_eps_0_1: 0.3642\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0073 - loss: 0.0031 - within_eps_0_005: 0.0378 - within_eps_0_01: 0.0764 - within_eps_0_02: 0.1493 - within_eps_0_05: 0.3587 - within_eps_0_1: 0.6337 - val_log_cosh: 0.0491 - val_loss: 0.0083 - val_within_eps_0_005: 0.0209 - val_within_eps_0_01: 0.0447 - val_within_eps_0_02: 0.0853 - val_within_eps_0_05: 0.2033 - val_within_eps_0_1: 0.3548\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0062 - loss: 0.0027 - within_eps_0_005: 0.0408 - within_eps_0_01: 0.0833 - within_eps_0_02: 0.1667 - within_eps_0_05: 0.3980 - within_eps_0_1: 0.6789 - val_log_cosh: 0.0475 - val_loss: 0.0082 - val_within_eps_0_005: 0.0205 - val_within_eps_0_01: 0.0441 - val_within_eps_0_02: 0.0884 - val_within_eps_0_05: 0.1970 - val_within_eps_0_1: 0.3505\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0054 - loss: 0.0025 - within_eps_0_005: 0.0454 - within_eps_0_01: 0.0907 - within_eps_0_02: 0.1809 - within_eps_0_05: 0.4243 - within_eps_0_1: 0.7086 - val_log_cosh: 0.0428 - val_loss: 0.0077 - val_within_eps_0_005: 0.0229 - val_within_eps_0_01: 0.0461 - val_within_eps_0_02: 0.0912 - val_within_eps_0_05: 0.2198 - val_within_eps_0_1: 0.3701\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0049 - loss: 0.0023 - within_eps_0_005: 0.0483 - within_eps_0_01: 0.0969 - within_eps_0_02: 0.1940 - within_eps_0_05: 0.4455 - within_eps_0_1: 0.7352 - val_log_cosh: 0.0407 - val_loss: 0.0074 - val_within_eps_0_005: 0.0223 - val_within_eps_0_01: 0.0472 - val_within_eps_0_02: 0.0921 - val_within_eps_0_05: 0.2135 - val_within_eps_0_1: 0.3863\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0045 - loss: 0.0022 - within_eps_0_005: 0.0512 - within_eps_0_01: 0.1036 - within_eps_0_02: 0.2005 - within_eps_0_05: 0.4615 - within_eps_0_1: 0.7520 - val_log_cosh: 0.0391 - val_loss: 0.0072 - val_within_eps_0_005: 0.0229 - val_within_eps_0_01: 0.0442 - val_within_eps_0_02: 0.0907 - val_within_eps_0_05: 0.2263 - val_within_eps_0_1: 0.3924\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0042 - loss: 0.0021 - within_eps_0_005: 0.0529 - within_eps_0_01: 0.1063 - within_eps_0_02: 0.2101 - within_eps_0_05: 0.4856 - within_eps_0_1: 0.7718 - val_log_cosh: 0.0465 - val_loss: 0.0081 - val_within_eps_0_005: 0.0226 - val_within_eps_0_01: 0.0443 - val_within_eps_0_02: 0.0921 - val_within_eps_0_05: 0.2128 - val_within_eps_0_1: 0.3587\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0038 - loss: 0.0020 - within_eps_0_005: 0.0552 - within_eps_0_01: 0.1093 - within_eps_0_02: 0.2165 - within_eps_0_05: 0.4966 - within_eps_0_1: 0.7834 - val_log_cosh: 0.0400 - val_loss: 0.0072 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0478 - val_within_eps_0_02: 0.0945 - val_within_eps_0_05: 0.2304 - val_within_eps_0_1: 0.4078\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0038 - loss: 0.0020 - within_eps_0_005: 0.0577 - within_eps_0_01: 0.1155 - within_eps_0_02: 0.2233 - within_eps_0_05: 0.5050 - within_eps_0_1: 0.7884 - val_log_cosh: 0.0417 - val_loss: 0.0074 - val_within_eps_0_005: 0.0274 - val_within_eps_0_01: 0.0523 - val_within_eps_0_02: 0.1033 - val_within_eps_0_05: 0.2271 - val_within_eps_0_1: 0.3963\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0034 - loss: 0.0018 - within_eps_0_005: 0.0598 - within_eps_0_01: 0.1182 - within_eps_0_02: 0.2326 - within_eps_0_05: 0.5214 - within_eps_0_1: 0.8039 - val_log_cosh: 0.0372 - val_loss: 0.0069 - val_within_eps_0_005: 0.0258 - val_within_eps_0_01: 0.0518 - val_within_eps_0_02: 0.1028 - val_within_eps_0_05: 0.2491 - val_within_eps_0_1: 0.4332\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0034 - loss: 0.0018 - within_eps_0_005: 0.0592 - within_eps_0_01: 0.1200 - within_eps_0_02: 0.2380 - within_eps_0_05: 0.5294 - within_eps_0_1: 0.8071 - val_log_cosh: 0.0434 - val_loss: 0.0076 - val_within_eps_0_005: 0.0253 - val_within_eps_0_01: 0.0513 - val_within_eps_0_02: 0.1019 - val_within_eps_0_05: 0.2274 - val_within_eps_0_1: 0.3914\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0032 - loss: 0.0017 - within_eps_0_005: 0.0648 - within_eps_0_01: 0.1275 - within_eps_0_02: 0.2471 - within_eps_0_05: 0.5445 - within_eps_0_1: 0.8228 - val_log_cosh: 0.0413 - val_loss: 0.0073 - val_within_eps_0_005: 0.0300 - val_within_eps_0_01: 0.0578 - val_within_eps_0_02: 0.1113 - val_within_eps_0_05: 0.2442 - val_within_eps_0_1: 0.4083\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0031 - loss: 0.0017 - within_eps_0_005: 0.0632 - within_eps_0_01: 0.1236 - within_eps_0_02: 0.2452 - within_eps_0_05: 0.5461 - within_eps_0_1: 0.8243 - val_log_cosh: 0.0476 - val_loss: 0.0081 - val_within_eps_0_005: 0.0249 - val_within_eps_0_01: 0.0511 - val_within_eps_0_02: 0.0978 - val_within_eps_0_05: 0.2057 - val_within_eps_0_1: 0.3683\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0029 - loss: 0.0016 - within_eps_0_005: 0.0660 - within_eps_0_01: 0.1313 - within_eps_0_02: 0.2563 - within_eps_0_05: 0.5637 - within_eps_0_1: 0.8394 - val_log_cosh: 0.0445 - val_loss: 0.0077 - val_within_eps_0_005: 0.0280 - val_within_eps_0_01: 0.0577 - val_within_eps_0_02: 0.1128 - val_within_eps_0_05: 0.2326 - val_within_eps_0_1: 0.3974\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0028 - loss: 0.0016 - within_eps_0_005: 0.0666 - within_eps_0_01: 0.1344 - within_eps_0_02: 0.2635 - within_eps_0_05: 0.5772 - within_eps_0_1: 0.8479 - val_log_cosh: 0.0444 - val_loss: 0.0076 - val_within_eps_0_005: 0.0252 - val_within_eps_0_01: 0.0508 - val_within_eps_0_02: 0.1000 - val_within_eps_0_05: 0.2422 - val_within_eps_0_1: 0.3890\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0027 - loss: 0.0016 - within_eps_0_005: 0.0684 - within_eps_0_01: 0.1390 - within_eps_0_02: 0.2707 - within_eps_0_05: 0.5815 - within_eps_0_1: 0.8487 - val_log_cosh: 0.0376 - val_loss: 0.0068 - val_within_eps_0_005: 0.0300 - val_within_eps_0_01: 0.0590 - val_within_eps_0_02: 0.1134 - val_within_eps_0_05: 0.2524 - val_within_eps_0_1: 0.4393\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0026 - loss: 0.0015 - within_eps_0_005: 0.0696 - within_eps_0_01: 0.1371 - within_eps_0_02: 0.2685 - within_eps_0_05: 0.5849 - within_eps_0_1: 0.8558 - val_log_cosh: 0.0438 - val_loss: 0.0075 - val_within_eps_0_005: 0.0276 - val_within_eps_0_01: 0.0531 - val_within_eps_0_02: 0.1011 - val_within_eps_0_05: 0.2388 - val_within_eps_0_1: 0.3974\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0024 - loss: 0.0014 - within_eps_0_005: 0.0731 - within_eps_0_01: 0.1448 - within_eps_0_02: 0.2833 - within_eps_0_05: 0.6051 - within_eps_0_1: 0.8676 - val_log_cosh: 0.0419 - val_loss: 0.0073 - val_within_eps_0_005: 0.0239 - val_within_eps_0_01: 0.0488 - val_within_eps_0_02: 0.0997 - val_within_eps_0_05: 0.2507 - val_within_eps_0_1: 0.4004\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0025 - loss: 0.0015 - within_eps_0_005: 0.0720 - within_eps_0_01: 0.1429 - within_eps_0_02: 0.2816 - within_eps_0_05: 0.6020 - within_eps_0_1: 0.8647 - val_log_cosh: 0.0434 - val_loss: 0.0074 - val_within_eps_0_005: 0.0219 - val_within_eps_0_01: 0.0454 - val_within_eps_0_02: 0.0947 - val_within_eps_0_05: 0.2416 - val_within_eps_0_1: 0.4002\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0023 - loss: 0.0014 - within_eps_0_005: 0.0746 - within_eps_0_01: 0.1479 - within_eps_0_02: 0.2834 - within_eps_0_05: 0.6103 - within_eps_0_1: 0.8725 - val_log_cosh: 0.0465 - val_loss: 0.0079 - val_within_eps_0_005: 0.0275 - val_within_eps_0_01: 0.0555 - val_within_eps_0_02: 0.1060 - val_within_eps_0_05: 0.2270 - val_within_eps_0_1: 0.3979\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0022 - loss: 0.0014 - within_eps_0_005: 0.0767 - within_eps_0_01: 0.1518 - within_eps_0_02: 0.2923 - within_eps_0_05: 0.6187 - within_eps_0_1: 0.8793 - val_log_cosh: 0.0471 - val_loss: 0.0079 - val_within_eps_0_005: 0.0236 - val_within_eps_0_01: 0.0460 - val_within_eps_0_02: 0.0923 - val_within_eps_0_05: 0.2263 - val_within_eps_0_1: 0.3970\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0022 - loss: 0.0014 - within_eps_0_005: 0.0753 - within_eps_0_01: 0.1506 - within_eps_0_02: 0.2914 - within_eps_0_05: 0.6201 - within_eps_0_1: 0.8789 - val_log_cosh: 0.0432 - val_loss: 0.0074 - val_within_eps_0_005: 0.0249 - val_within_eps_0_01: 0.0530 - val_within_eps_0_02: 0.1042 - val_within_eps_0_05: 0.2475 - val_within_eps_0_1: 0.3984\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0021 - loss: 0.0013 - within_eps_0_005: 0.0790 - within_eps_0_01: 0.1563 - within_eps_0_02: 0.3014 - within_eps_0_05: 0.6341 - within_eps_0_1: 0.8880 - val_log_cosh: 0.0419 - val_loss: 0.0073 - val_within_eps_0_005: 0.0283 - val_within_eps_0_01: 0.0571 - val_within_eps_0_02: 0.1154 - val_within_eps_0_05: 0.2607 - val_within_eps_0_1: 0.4162\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0021 - loss: 0.0013 - within_eps_0_005: 0.0775 - within_eps_0_01: 0.1575 - within_eps_0_02: 0.3050 - within_eps_0_05: 0.6341 - within_eps_0_1: 0.8861 - val_log_cosh: 0.0503 - val_loss: 0.0083 - val_within_eps_0_005: 0.0233 - val_within_eps_0_01: 0.0454 - val_within_eps_0_02: 0.0894 - val_within_eps_0_05: 0.2022 - val_within_eps_0_1: 0.3777\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0021 - loss: 0.0013 - within_eps_0_005: 0.0780 - within_eps_0_01: 0.1557 - within_eps_0_02: 0.3045 - within_eps_0_05: 0.6410 - within_eps_0_1: 0.8890 - val_log_cosh: 0.0446 - val_loss: 0.0076 - val_within_eps_0_005: 0.0243 - val_within_eps_0_01: 0.0494 - val_within_eps_0_02: 0.0964 - val_within_eps_0_05: 0.2383 - val_within_eps_0_1: 0.4028\n",
      "  -> val_log_cosh(min) δ=0.04116208553314208: 0.037210494280\n",
      "\n",
      "--- Entrenando δ=0.05 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - log_cosh: 0.2985 - loss: 0.0329 - within_eps_0_005: 0.0048 - within_eps_0_01: 0.0101 - within_eps_0_02: 0.0205 - within_eps_0_05: 0.0506 - within_eps_0_1: 0.1001 - val_log_cosh: 0.1222 - val_loss: 0.0187 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0239 - val_within_eps_0_02: 0.0449 - val_within_eps_0_05: 0.1024 - val_within_eps_0_1: 0.1839\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.1382 - loss: 0.0211 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0141 - within_eps_0_02: 0.0283 - within_eps_0_05: 0.0710 - within_eps_0_1: 0.1406 - val_log_cosh: 0.0899 - val_loss: 0.0149 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0229 - val_within_eps_0_02: 0.0471 - val_within_eps_0_05: 0.1206 - val_within_eps_0_1: 0.2462\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.1032 - loss: 0.0177 - within_eps_0_005: 0.0079 - within_eps_0_01: 0.0169 - within_eps_0_02: 0.0328 - within_eps_0_05: 0.0845 - within_eps_0_1: 0.1687 - val_log_cosh: 0.0742 - val_loss: 0.0130 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0329 - val_within_eps_0_02: 0.0637 - val_within_eps_0_05: 0.1506 - val_within_eps_0_1: 0.2967\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0757 - loss: 0.0148 - within_eps_0_005: 0.0099 - within_eps_0_01: 0.0197 - within_eps_0_02: 0.0394 - within_eps_0_05: 0.1002 - within_eps_0_1: 0.1983 - val_log_cosh: 0.0692 - val_loss: 0.0123 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0633 - val_within_eps_0_05: 0.1618 - val_within_eps_0_1: 0.3047\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0557 - loss: 0.0124 - within_eps_0_005: 0.0122 - within_eps_0_01: 0.0236 - within_eps_0_02: 0.0479 - within_eps_0_05: 0.1182 - within_eps_0_1: 0.2352 - val_log_cosh: 0.0719 - val_loss: 0.0126 - val_within_eps_0_005: 0.0176 - val_within_eps_0_01: 0.0345 - val_within_eps_0_02: 0.0677 - val_within_eps_0_05: 0.1593 - val_within_eps_0_1: 0.3003\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0380 - loss: 0.0099 - within_eps_0_005: 0.0151 - within_eps_0_01: 0.0303 - within_eps_0_02: 0.0595 - within_eps_0_05: 0.1496 - within_eps_0_1: 0.2925 - val_log_cosh: 0.0673 - val_loss: 0.0120 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0339 - val_within_eps_0_02: 0.0660 - val_within_eps_0_05: 0.1619 - val_within_eps_0_1: 0.3038\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0255 - loss: 0.0078 - within_eps_0_005: 0.0185 - within_eps_0_01: 0.0369 - within_eps_0_02: 0.0737 - within_eps_0_05: 0.1812 - within_eps_0_1: 0.3541 - val_log_cosh: 0.0598 - val_loss: 0.0111 - val_within_eps_0_005: 0.0177 - val_within_eps_0_01: 0.0378 - val_within_eps_0_02: 0.0786 - val_within_eps_0_05: 0.1914 - val_within_eps_0_1: 0.3411\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0169 - loss: 0.0061 - within_eps_0_005: 0.0228 - within_eps_0_01: 0.0460 - within_eps_0_02: 0.0917 - within_eps_0_05: 0.2299 - within_eps_0_1: 0.4360 - val_log_cosh: 0.0600 - val_loss: 0.0111 - val_within_eps_0_005: 0.0178 - val_within_eps_0_01: 0.0374 - val_within_eps_0_02: 0.0740 - val_within_eps_0_05: 0.1799 - val_within_eps_0_1: 0.3283\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0117 - loss: 0.0048 - within_eps_0_005: 0.0293 - within_eps_0_01: 0.0577 - within_eps_0_02: 0.1134 - within_eps_0_05: 0.2818 - within_eps_0_1: 0.5213 - val_log_cosh: 0.0584 - val_loss: 0.0109 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0358 - val_within_eps_0_02: 0.0723 - val_within_eps_0_05: 0.1784 - val_within_eps_0_1: 0.3431\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0088 - loss: 0.0040 - within_eps_0_005: 0.0333 - within_eps_0_01: 0.0671 - within_eps_0_02: 0.1341 - within_eps_0_05: 0.3261 - within_eps_0_1: 0.5888 - val_log_cosh: 0.0554 - val_loss: 0.0105 - val_within_eps_0_005: 0.0172 - val_within_eps_0_01: 0.0351 - val_within_eps_0_02: 0.0729 - val_within_eps_0_05: 0.1865 - val_within_eps_0_1: 0.3588\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0069 - loss: 0.0034 - within_eps_0_005: 0.0398 - within_eps_0_01: 0.0797 - within_eps_0_02: 0.1571 - within_eps_0_05: 0.3680 - within_eps_0_1: 0.6530 - val_log_cosh: 0.0560 - val_loss: 0.0106 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0694 - val_within_eps_0_05: 0.1828 - val_within_eps_0_1: 0.3569\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0059 - loss: 0.0031 - within_eps_0_005: 0.0433 - within_eps_0_01: 0.0852 - within_eps_0_02: 0.1695 - within_eps_0_05: 0.3996 - within_eps_0_1: 0.6884 - val_log_cosh: 0.0597 - val_loss: 0.0111 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0671 - val_within_eps_0_05: 0.1790 - val_within_eps_0_1: 0.3529\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0050 - loss: 0.0027 - within_eps_0_005: 0.0447 - within_eps_0_01: 0.0906 - within_eps_0_02: 0.1819 - within_eps_0_05: 0.4343 - within_eps_0_1: 0.7259 - val_log_cosh: 0.0602 - val_loss: 0.0111 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0799 - val_within_eps_0_05: 0.1889 - val_within_eps_0_1: 0.3523\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0047 - loss: 0.0026 - within_eps_0_005: 0.0492 - within_eps_0_01: 0.0968 - within_eps_0_02: 0.1920 - within_eps_0_05: 0.4521 - within_eps_0_1: 0.7454 - val_log_cosh: 0.0539 - val_loss: 0.0104 - val_within_eps_0_005: 0.0222 - val_within_eps_0_01: 0.0451 - val_within_eps_0_02: 0.0918 - val_within_eps_0_05: 0.2051 - val_within_eps_0_1: 0.3583\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0043 - loss: 0.0025 - within_eps_0_005: 0.0515 - within_eps_0_01: 0.1027 - within_eps_0_02: 0.2008 - within_eps_0_05: 0.4684 - within_eps_0_1: 0.7576 - val_log_cosh: 0.0641 - val_loss: 0.0118 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0392 - val_within_eps_0_02: 0.0759 - val_within_eps_0_05: 0.1754 - val_within_eps_0_1: 0.3274\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0041 - loss: 0.0024 - within_eps_0_005: 0.0541 - within_eps_0_01: 0.1073 - within_eps_0_02: 0.2090 - within_eps_0_05: 0.4822 - within_eps_0_1: 0.7735 - val_log_cosh: 0.0614 - val_loss: 0.0115 - val_within_eps_0_005: 0.0183 - val_within_eps_0_01: 0.0347 - val_within_eps_0_02: 0.0695 - val_within_eps_0_05: 0.1844 - val_within_eps_0_1: 0.3348\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0036 - loss: 0.0022 - within_eps_0_005: 0.0561 - within_eps_0_01: 0.1126 - within_eps_0_02: 0.2200 - within_eps_0_05: 0.5023 - within_eps_0_1: 0.7942 - val_log_cosh: 0.0520 - val_loss: 0.0103 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0410 - val_within_eps_0_02: 0.0824 - val_within_eps_0_05: 0.2043 - val_within_eps_0_1: 0.3480\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0037 - loss: 0.0022 - within_eps_0_005: 0.0556 - within_eps_0_01: 0.1083 - within_eps_0_02: 0.2184 - within_eps_0_05: 0.5005 - within_eps_0_1: 0.7960 - val_log_cosh: 0.0552 - val_loss: 0.0105 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0800 - val_within_eps_0_05: 0.2026 - val_within_eps_0_1: 0.3578\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0036 - loss: 0.0022 - within_eps_0_005: 0.0596 - within_eps_0_01: 0.1156 - within_eps_0_02: 0.2266 - within_eps_0_05: 0.5098 - within_eps_0_1: 0.7985 - val_log_cosh: 0.0530 - val_loss: 0.0102 - val_within_eps_0_005: 0.0271 - val_within_eps_0_01: 0.0525 - val_within_eps_0_02: 0.0975 - val_within_eps_0_05: 0.2141 - val_within_eps_0_1: 0.3642\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0033 - loss: 0.0020 - within_eps_0_005: 0.0598 - within_eps_0_01: 0.1190 - within_eps_0_02: 0.2340 - within_eps_0_05: 0.5300 - within_eps_0_1: 0.8152 - val_log_cosh: 0.0503 - val_loss: 0.0099 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0485 - val_within_eps_0_02: 0.0977 - val_within_eps_0_05: 0.2197 - val_within_eps_0_1: 0.3727\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0030 - loss: 0.0019 - within_eps_0_005: 0.0625 - within_eps_0_01: 0.1242 - within_eps_0_02: 0.2442 - within_eps_0_05: 0.5481 - within_eps_0_1: 0.8311 - val_log_cosh: 0.0496 - val_loss: 0.0098 - val_within_eps_0_005: 0.0266 - val_within_eps_0_01: 0.0540 - val_within_eps_0_02: 0.1066 - val_within_eps_0_05: 0.2265 - val_within_eps_0_1: 0.3782\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0030 - loss: 0.0019 - within_eps_0_005: 0.0634 - within_eps_0_01: 0.1270 - within_eps_0_02: 0.2467 - within_eps_0_05: 0.5483 - within_eps_0_1: 0.8328 - val_log_cosh: 0.0508 - val_loss: 0.0099 - val_within_eps_0_005: 0.0282 - val_within_eps_0_01: 0.0544 - val_within_eps_0_02: 0.1047 - val_within_eps_0_05: 0.2280 - val_within_eps_0_1: 0.3797\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0030 - loss: 0.0019 - within_eps_0_005: 0.0639 - within_eps_0_01: 0.1263 - within_eps_0_02: 0.2492 - within_eps_0_05: 0.5542 - within_eps_0_1: 0.8361 - val_log_cosh: 0.0537 - val_loss: 0.0103 - val_within_eps_0_005: 0.0247 - val_within_eps_0_01: 0.0492 - val_within_eps_0_02: 0.0930 - val_within_eps_0_05: 0.2155 - val_within_eps_0_1: 0.3709\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0027 - loss: 0.0017 - within_eps_0_005: 0.0666 - within_eps_0_01: 0.1342 - within_eps_0_02: 0.2622 - within_eps_0_05: 0.5814 - within_eps_0_1: 0.8559 - val_log_cosh: 0.0500 - val_loss: 0.0098 - val_within_eps_0_005: 0.0280 - val_within_eps_0_01: 0.0537 - val_within_eps_0_02: 0.1034 - val_within_eps_0_05: 0.2262 - val_within_eps_0_1: 0.3820\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0026 - loss: 0.0017 - within_eps_0_005: 0.0696 - within_eps_0_01: 0.1355 - within_eps_0_02: 0.2661 - within_eps_0_05: 0.5835 - within_eps_0_1: 0.8577 - val_log_cosh: 0.0490 - val_loss: 0.0096 - val_within_eps_0_005: 0.0251 - val_within_eps_0_01: 0.0492 - val_within_eps_0_02: 0.0999 - val_within_eps_0_05: 0.2275 - val_within_eps_0_1: 0.3851\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0025 - loss: 0.0017 - within_eps_0_005: 0.0684 - within_eps_0_01: 0.1373 - within_eps_0_02: 0.2698 - within_eps_0_05: 0.5897 - within_eps_0_1: 0.8633 - val_log_cosh: 0.0510 - val_loss: 0.0098 - val_within_eps_0_005: 0.0237 - val_within_eps_0_01: 0.0479 - val_within_eps_0_02: 0.0998 - val_within_eps_0_05: 0.2308 - val_within_eps_0_1: 0.3820\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0023 - loss: 0.0016 - within_eps_0_005: 0.0742 - within_eps_0_01: 0.1432 - within_eps_0_02: 0.2758 - within_eps_0_05: 0.6037 - within_eps_0_1: 0.8730 - val_log_cosh: 0.0502 - val_loss: 0.0098 - val_within_eps_0_005: 0.0262 - val_within_eps_0_01: 0.0526 - val_within_eps_0_02: 0.1017 - val_within_eps_0_05: 0.2262 - val_within_eps_0_1: 0.3768\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0024 - loss: 0.0016 - within_eps_0_005: 0.0688 - within_eps_0_01: 0.1414 - within_eps_0_02: 0.2736 - within_eps_0_05: 0.5982 - within_eps_0_1: 0.8689 - val_log_cosh: 0.0465 - val_loss: 0.0092 - val_within_eps_0_005: 0.0231 - val_within_eps_0_01: 0.0488 - val_within_eps_0_02: 0.1028 - val_within_eps_0_05: 0.2359 - val_within_eps_0_1: 0.4097\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0024 - loss: 0.0016 - within_eps_0_005: 0.0717 - within_eps_0_01: 0.1418 - within_eps_0_02: 0.2785 - within_eps_0_05: 0.6035 - within_eps_0_1: 0.8733 - val_log_cosh: 0.0480 - val_loss: 0.0094 - val_within_eps_0_005: 0.0253 - val_within_eps_0_01: 0.0494 - val_within_eps_0_02: 0.0988 - val_within_eps_0_05: 0.2325 - val_within_eps_0_1: 0.4057\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0021 - loss: 0.0015 - within_eps_0_005: 0.0737 - within_eps_0_01: 0.1485 - within_eps_0_02: 0.2902 - within_eps_0_05: 0.6247 - within_eps_0_1: 0.8849 - val_log_cosh: 0.0600 - val_loss: 0.0112 - val_within_eps_0_005: 0.0230 - val_within_eps_0_01: 0.0449 - val_within_eps_0_02: 0.0876 - val_within_eps_0_05: 0.2005 - val_within_eps_0_1: 0.3451\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0023 - loss: 0.0015 - within_eps_0_005: 0.0766 - within_eps_0_01: 0.1484 - within_eps_0_02: 0.2896 - within_eps_0_05: 0.6192 - within_eps_0_1: 0.8796 - val_log_cosh: 0.0534 - val_loss: 0.0102 - val_within_eps_0_005: 0.0224 - val_within_eps_0_01: 0.0453 - val_within_eps_0_02: 0.0920 - val_within_eps_0_05: 0.2191 - val_within_eps_0_1: 0.3680\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0021 - loss: 0.0015 - within_eps_0_005: 0.0788 - within_eps_0_01: 0.1551 - within_eps_0_02: 0.2972 - within_eps_0_05: 0.6325 - within_eps_0_1: 0.8890 - val_log_cosh: 0.0465 - val_loss: 0.0092 - val_within_eps_0_005: 0.0258 - val_within_eps_0_01: 0.0499 - val_within_eps_0_02: 0.1017 - val_within_eps_0_05: 0.2472 - val_within_eps_0_1: 0.4099\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0020 - loss: 0.0014 - within_eps_0_005: 0.0777 - within_eps_0_01: 0.1551 - within_eps_0_02: 0.3057 - within_eps_0_05: 0.6480 - within_eps_0_1: 0.8979 - val_log_cosh: 0.0483 - val_loss: 0.0095 - val_within_eps_0_005: 0.0260 - val_within_eps_0_01: 0.0501 - val_within_eps_0_02: 0.0988 - val_within_eps_0_05: 0.2357 - val_within_eps_0_1: 0.4077\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0020 - loss: 0.0014 - within_eps_0_005: 0.0804 - within_eps_0_01: 0.1587 - within_eps_0_02: 0.3060 - within_eps_0_05: 0.6437 - within_eps_0_1: 0.8969 - val_log_cosh: 0.0476 - val_loss: 0.0093 - val_within_eps_0_005: 0.0296 - val_within_eps_0_01: 0.0585 - val_within_eps_0_02: 0.1135 - val_within_eps_0_05: 0.2569 - val_within_eps_0_1: 0.4204\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0019 - loss: 0.0014 - within_eps_0_005: 0.0808 - within_eps_0_01: 0.1612 - within_eps_0_02: 0.3082 - within_eps_0_05: 0.6508 - within_eps_0_1: 0.9003 - val_log_cosh: 0.0449 - val_loss: 0.0089 - val_within_eps_0_005: 0.0289 - val_within_eps_0_01: 0.0574 - val_within_eps_0_02: 0.1095 - val_within_eps_0_05: 0.2517 - val_within_eps_0_1: 0.4294\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0019 - loss: 0.0013 - within_eps_0_005: 0.0834 - within_eps_0_01: 0.1673 - within_eps_0_02: 0.3187 - within_eps_0_05: 0.6605 - within_eps_0_1: 0.9054 - val_log_cosh: 0.0525 - val_loss: 0.0100 - val_within_eps_0_005: 0.0267 - val_within_eps_0_01: 0.0523 - val_within_eps_0_02: 0.1012 - val_within_eps_0_05: 0.2309 - val_within_eps_0_1: 0.3925\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0018 - loss: 0.0013 - within_eps_0_005: 0.0850 - within_eps_0_01: 0.1691 - within_eps_0_02: 0.3265 - within_eps_0_05: 0.6725 - within_eps_0_1: 0.9105 - val_log_cosh: 0.0497 - val_loss: 0.0096 - val_within_eps_0_005: 0.0268 - val_within_eps_0_01: 0.0543 - val_within_eps_0_02: 0.1089 - val_within_eps_0_05: 0.2562 - val_within_eps_0_1: 0.4159\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0018 - loss: 0.0013 - within_eps_0_005: 0.0820 - within_eps_0_01: 0.1652 - within_eps_0_02: 0.3195 - within_eps_0_05: 0.6648 - within_eps_0_1: 0.9093 - val_log_cosh: 0.0488 - val_loss: 0.0094 - val_within_eps_0_005: 0.0266 - val_within_eps_0_01: 0.0549 - val_within_eps_0_02: 0.1116 - val_within_eps_0_05: 0.2566 - val_within_eps_0_1: 0.4144\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - log_cosh: 0.0017 - loss: 0.0012 - within_eps_0_005: 0.0874 - within_eps_0_01: 0.1709 - within_eps_0_02: 0.3305 - within_eps_0_05: 0.6823 - within_eps_0_1: 0.9154 - val_log_cosh: 0.0496 - val_loss: 0.0095 - val_within_eps_0_005: 0.0256 - val_within_eps_0_01: 0.0530 - val_within_eps_0_02: 0.1027 - val_within_eps_0_05: 0.2483 - val_within_eps_0_1: 0.4138\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0017 - loss: 0.0012 - within_eps_0_005: 0.0887 - within_eps_0_01: 0.1733 - within_eps_0_02: 0.3338 - within_eps_0_05: 0.6848 - within_eps_0_1: 0.9167 - val_log_cosh: 0.0557 - val_loss: 0.0105 - val_within_eps_0_005: 0.0244 - val_within_eps_0_01: 0.0479 - val_within_eps_0_02: 0.0931 - val_within_eps_0_05: 0.2177 - val_within_eps_0_1: 0.3759\n",
      "Epoch 41/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0017 - loss: 0.0012 - within_eps_0_005: 0.0852 - within_eps_0_01: 0.1684 - within_eps_0_02: 0.3280 - within_eps_0_05: 0.6794 - within_eps_0_1: 0.9150 - val_log_cosh: 0.0569 - val_loss: 0.0107 - val_within_eps_0_005: 0.0221 - val_within_eps_0_01: 0.0450 - val_within_eps_0_02: 0.0898 - val_within_eps_0_05: 0.2161 - val_within_eps_0_1: 0.3779\n",
      "Epoch 42/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0891 - within_eps_0_01: 0.1779 - within_eps_0_02: 0.3410 - within_eps_0_05: 0.6935 - within_eps_0_1: 0.9219 - val_log_cosh: 0.0533 - val_loss: 0.0101 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0506 - val_within_eps_0_02: 0.0996 - val_within_eps_0_05: 0.2350 - val_within_eps_0_1: 0.3912\n",
      "Epoch 43/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0911 - within_eps_0_01: 0.1814 - within_eps_0_02: 0.3450 - within_eps_0_05: 0.6954 - within_eps_0_1: 0.9229 - val_log_cosh: 0.0514 - val_loss: 0.0098 - val_within_eps_0_005: 0.0283 - val_within_eps_0_01: 0.0543 - val_within_eps_0_02: 0.1075 - val_within_eps_0_05: 0.2548 - val_within_eps_0_1: 0.4120\n",
      "Epoch 44/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0902 - within_eps_0_01: 0.1766 - within_eps_0_02: 0.3384 - within_eps_0_05: 0.6877 - within_eps_0_1: 0.9229 - val_log_cosh: 0.0531 - val_loss: 0.0101 - val_within_eps_0_005: 0.0239 - val_within_eps_0_01: 0.0492 - val_within_eps_0_02: 0.0968 - val_within_eps_0_05: 0.2309 - val_within_eps_0_1: 0.3881\n",
      "Epoch 45/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0914 - within_eps_0_01: 0.1811 - within_eps_0_02: 0.3468 - within_eps_0_05: 0.7031 - within_eps_0_1: 0.9244 - val_log_cosh: 0.0526 - val_loss: 0.0101 - val_within_eps_0_005: 0.0225 - val_within_eps_0_01: 0.0472 - val_within_eps_0_02: 0.0965 - val_within_eps_0_05: 0.2266 - val_within_eps_0_1: 0.3867\n",
      "Epoch 46/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0016 - loss: 0.0012 - within_eps_0_005: 0.0931 - within_eps_0_01: 0.1852 - within_eps_0_02: 0.3504 - within_eps_0_05: 0.6989 - within_eps_0_1: 0.9235 - val_log_cosh: 0.0530 - val_loss: 0.0101 - val_within_eps_0_005: 0.0217 - val_within_eps_0_01: 0.0427 - val_within_eps_0_02: 0.0876 - val_within_eps_0_05: 0.2183 - val_within_eps_0_1: 0.3847\n",
      "Epoch 47/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0015 - loss: 0.0011 - within_eps_0_005: 0.0933 - within_eps_0_01: 0.1865 - within_eps_0_02: 0.3546 - within_eps_0_05: 0.7089 - within_eps_0_1: 0.9273 - val_log_cosh: 0.0510 - val_loss: 0.0097 - val_within_eps_0_005: 0.0253 - val_within_eps_0_01: 0.0523 - val_within_eps_0_02: 0.1014 - val_within_eps_0_05: 0.2474 - val_within_eps_0_1: 0.4097\n",
      "Epoch 48/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0014 - loss: 0.0011 - within_eps_0_005: 0.0974 - within_eps_0_01: 0.1926 - within_eps_0_02: 0.3621 - within_eps_0_05: 0.7138 - within_eps_0_1: 0.9346 - val_log_cosh: 0.0531 - val_loss: 0.0101 - val_within_eps_0_005: 0.0225 - val_within_eps_0_01: 0.0469 - val_within_eps_0_02: 0.0963 - val_within_eps_0_05: 0.2297 - val_within_eps_0_1: 0.3960\n",
      "Epoch 49/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0014 - loss: 0.0010 - within_eps_0_005: 0.0970 - within_eps_0_01: 0.1916 - within_eps_0_02: 0.3667 - within_eps_0_05: 0.7265 - within_eps_0_1: 0.9379 - val_log_cosh: 0.0595 - val_loss: 0.0111 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0816 - val_within_eps_0_05: 0.1882 - val_within_eps_0_1: 0.3454\n",
      "Epoch 50/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0014 - loss: 0.0010 - within_eps_0_005: 0.0944 - within_eps_0_01: 0.1904 - within_eps_0_02: 0.3624 - within_eps_0_05: 0.7216 - within_eps_0_1: 0.9404 - val_log_cosh: 0.0521 - val_loss: 0.0099 - val_within_eps_0_005: 0.0237 - val_within_eps_0_01: 0.0475 - val_within_eps_0_02: 0.0916 - val_within_eps_0_05: 0.2280 - val_within_eps_0_1: 0.4053\n",
      "  -> val_log_cosh(min) δ=0.05: 0.044946625829\n",
      "\n",
      "--- Entrenando δ=0.1 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - log_cosh: 0.3059 - loss: 0.0643 - within_eps_0_005: 0.0049 - within_eps_0_01: 0.0098 - within_eps_0_02: 0.0196 - within_eps_0_05: 0.0504 - within_eps_0_1: 0.1011 - val_log_cosh: 0.1447 - val_loss: 0.0392 - val_within_eps_0_005: 0.0055 - val_within_eps_0_01: 0.0120 - val_within_eps_0_02: 0.0224 - val_within_eps_0_05: 0.0605 - val_within_eps_0_1: 0.1548\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.1403 - loss: 0.0401 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0143 - within_eps_0_02: 0.0286 - within_eps_0_05: 0.0713 - within_eps_0_1: 0.1420 - val_log_cosh: 0.1234 - val_loss: 0.0351 - val_within_eps_0_005: 0.0091 - val_within_eps_0_01: 0.0182 - val_within_eps_0_02: 0.0377 - val_within_eps_0_05: 0.0962 - val_within_eps_0_1: 0.1842\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.1064 - loss: 0.0337 - within_eps_0_005: 0.0084 - within_eps_0_01: 0.0171 - within_eps_0_02: 0.0334 - within_eps_0_05: 0.0827 - within_eps_0_1: 0.1671 - val_log_cosh: 0.0988 - val_loss: 0.0293 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0281 - val_within_eps_0_02: 0.0546 - val_within_eps_0_05: 0.1241 - val_within_eps_0_1: 0.2276\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0797 - loss: 0.0282 - within_eps_0_005: 0.0103 - within_eps_0_01: 0.0208 - within_eps_0_02: 0.0410 - within_eps_0_05: 0.0989 - within_eps_0_1: 0.1941 - val_log_cosh: 0.0872 - val_loss: 0.0267 - val_within_eps_0_005: 0.0083 - val_within_eps_0_01: 0.0182 - val_within_eps_0_02: 0.0390 - val_within_eps_0_05: 0.1084 - val_within_eps_0_1: 0.2307\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0581 - loss: 0.0231 - within_eps_0_005: 0.0113 - within_eps_0_01: 0.0237 - within_eps_0_02: 0.0483 - within_eps_0_05: 0.1195 - within_eps_0_1: 0.2357 - val_log_cosh: 0.0831 - val_loss: 0.0257 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0239 - val_within_eps_0_02: 0.0476 - val_within_eps_0_05: 0.1238 - val_within_eps_0_1: 0.2485\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0406 - loss: 0.0184 - within_eps_0_005: 0.0140 - within_eps_0_01: 0.0283 - within_eps_0_02: 0.0553 - within_eps_0_05: 0.1395 - within_eps_0_1: 0.2784 - val_log_cosh: 0.0772 - val_loss: 0.0245 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0565 - val_within_eps_0_05: 0.1317 - val_within_eps_0_1: 0.2561\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0279 - loss: 0.0144 - within_eps_0_005: 0.0180 - within_eps_0_01: 0.0349 - within_eps_0_02: 0.0695 - within_eps_0_05: 0.1727 - within_eps_0_1: 0.3392 - val_log_cosh: 0.0682 - val_loss: 0.0227 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0530 - val_within_eps_0_05: 0.1319 - val_within_eps_0_1: 0.2667\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0186 - loss: 0.0110 - within_eps_0_005: 0.0222 - within_eps_0_01: 0.0435 - within_eps_0_02: 0.0869 - within_eps_0_05: 0.2162 - within_eps_0_1: 0.4140 - val_log_cosh: 0.0660 - val_loss: 0.0220 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1455 - val_within_eps_0_1: 0.2858\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0127 - loss: 0.0083 - within_eps_0_005: 0.0275 - within_eps_0_01: 0.0554 - within_eps_0_02: 0.1081 - within_eps_0_05: 0.2661 - within_eps_0_1: 0.4971 - val_log_cosh: 0.0584 - val_loss: 0.0201 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0330 - val_within_eps_0_02: 0.0641 - val_within_eps_0_05: 0.1653 - val_within_eps_0_1: 0.3033\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0090 - loss: 0.0065 - within_eps_0_005: 0.0335 - within_eps_0_01: 0.0653 - within_eps_0_02: 0.1311 - within_eps_0_05: 0.3166 - within_eps_0_1: 0.5713 - val_log_cosh: 0.0542 - val_loss: 0.0192 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0355 - val_within_eps_0_02: 0.0714 - val_within_eps_0_05: 0.1673 - val_within_eps_0_1: 0.3193\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0069 - loss: 0.0053 - within_eps_0_005: 0.0371 - within_eps_0_01: 0.0735 - within_eps_0_02: 0.1487 - within_eps_0_05: 0.3598 - within_eps_0_1: 0.6386 - val_log_cosh: 0.0580 - val_loss: 0.0202 - val_within_eps_0_005: 0.0176 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0753 - val_within_eps_0_05: 0.1782 - val_within_eps_0_1: 0.3217\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0059 - loss: 0.0046 - within_eps_0_005: 0.0399 - within_eps_0_01: 0.0811 - within_eps_0_02: 0.1616 - within_eps_0_05: 0.3875 - within_eps_0_1: 0.6798 - val_log_cosh: 0.0493 - val_loss: 0.0181 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0653 - val_within_eps_0_05: 0.1706 - val_within_eps_0_1: 0.3337\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - log_cosh: 0.0050 - loss: 0.0041 - within_eps_0_005: 0.0459 - within_eps_0_01: 0.0933 - within_eps_0_02: 0.1824 - within_eps_0_05: 0.4279 - within_eps_0_1: 0.7205 - val_log_cosh: 0.0480 - val_loss: 0.0176 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0625 - val_within_eps_0_05: 0.1633 - val_within_eps_0_1: 0.3427\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0047 - loss: 0.0038 - within_eps_0_005: 0.0484 - within_eps_0_01: 0.0962 - within_eps_0_02: 0.1897 - within_eps_0_05: 0.4457 - within_eps_0_1: 0.7439 - val_log_cosh: 0.0468 - val_loss: 0.0174 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0386 - val_within_eps_0_02: 0.0785 - val_within_eps_0_05: 0.1948 - val_within_eps_0_1: 0.3542\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0044 - loss: 0.0037 - within_eps_0_005: 0.0492 - within_eps_0_01: 0.0961 - within_eps_0_02: 0.1902 - within_eps_0_05: 0.4497 - within_eps_0_1: 0.7477 - val_log_cosh: 0.0439 - val_loss: 0.0166 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0403 - val_within_eps_0_02: 0.0833 - val_within_eps_0_05: 0.2033 - val_within_eps_0_1: 0.3647\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0041 - loss: 0.0034 - within_eps_0_005: 0.0508 - within_eps_0_01: 0.1031 - within_eps_0_02: 0.2037 - within_eps_0_05: 0.4729 - within_eps_0_1: 0.7700 - val_log_cosh: 0.0501 - val_loss: 0.0185 - val_within_eps_0_005: 0.0212 - val_within_eps_0_01: 0.0412 - val_within_eps_0_02: 0.0828 - val_within_eps_0_05: 0.1987 - val_within_eps_0_1: 0.3340\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0039 - loss: 0.0033 - within_eps_0_005: 0.0532 - within_eps_0_01: 0.1056 - within_eps_0_02: 0.2077 - within_eps_0_05: 0.4806 - within_eps_0_1: 0.7792 - val_log_cosh: 0.0380 - val_loss: 0.0149 - val_within_eps_0_005: 0.0228 - val_within_eps_0_01: 0.0449 - val_within_eps_0_02: 0.0935 - val_within_eps_0_05: 0.2170 - val_within_eps_0_1: 0.3997\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0037 - loss: 0.0031 - within_eps_0_005: 0.0537 - within_eps_0_01: 0.1069 - within_eps_0_02: 0.2121 - within_eps_0_05: 0.4916 - within_eps_0_1: 0.7892 - val_log_cosh: 0.0422 - val_loss: 0.0163 - val_within_eps_0_005: 0.0210 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0827 - val_within_eps_0_05: 0.1958 - val_within_eps_0_1: 0.3629\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0034 - loss: 0.0030 - within_eps_0_005: 0.0573 - within_eps_0_01: 0.1127 - within_eps_0_02: 0.2219 - within_eps_0_05: 0.5069 - within_eps_0_1: 0.8023 - val_log_cosh: 0.0383 - val_loss: 0.0150 - val_within_eps_0_005: 0.0227 - val_within_eps_0_01: 0.0464 - val_within_eps_0_02: 0.0891 - val_within_eps_0_05: 0.2105 - val_within_eps_0_1: 0.3933\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0033 - loss: 0.0028 - within_eps_0_005: 0.0570 - within_eps_0_01: 0.1131 - within_eps_0_02: 0.2245 - within_eps_0_05: 0.5151 - within_eps_0_1: 0.8113 - val_log_cosh: 0.0398 - val_loss: 0.0155 - val_within_eps_0_005: 0.0206 - val_within_eps_0_01: 0.0429 - val_within_eps_0_02: 0.0847 - val_within_eps_0_05: 0.2121 - val_within_eps_0_1: 0.3850\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0031 - loss: 0.0027 - within_eps_0_005: 0.0583 - within_eps_0_01: 0.1152 - within_eps_0_02: 0.2295 - within_eps_0_05: 0.5269 - within_eps_0_1: 0.8219 - val_log_cosh: 0.0419 - val_loss: 0.0162 - val_within_eps_0_005: 0.0251 - val_within_eps_0_01: 0.0499 - val_within_eps_0_02: 0.0915 - val_within_eps_0_05: 0.1956 - val_within_eps_0_1: 0.3580\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0029 - loss: 0.0026 - within_eps_0_005: 0.0606 - within_eps_0_01: 0.1207 - within_eps_0_02: 0.2359 - within_eps_0_05: 0.5411 - within_eps_0_1: 0.8305 - val_log_cosh: 0.0364 - val_loss: 0.0143 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0422 - val_within_eps_0_02: 0.0863 - val_within_eps_0_05: 0.2340 - val_within_eps_0_1: 0.4125\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0028 - loss: 0.0025 - within_eps_0_005: 0.0614 - within_eps_0_01: 0.1212 - within_eps_0_02: 0.2412 - within_eps_0_05: 0.5468 - within_eps_0_1: 0.8413 - val_log_cosh: 0.0355 - val_loss: 0.0141 - val_within_eps_0_005: 0.0210 - val_within_eps_0_01: 0.0419 - val_within_eps_0_02: 0.0851 - val_within_eps_0_05: 0.2237 - val_within_eps_0_1: 0.4080\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0027 - loss: 0.0024 - within_eps_0_005: 0.0641 - within_eps_0_01: 0.1275 - within_eps_0_02: 0.2503 - within_eps_0_05: 0.5648 - within_eps_0_1: 0.8464 - val_log_cosh: 0.0408 - val_loss: 0.0158 - val_within_eps_0_005: 0.0234 - val_within_eps_0_01: 0.0477 - val_within_eps_0_02: 0.0915 - val_within_eps_0_05: 0.2045 - val_within_eps_0_1: 0.3764\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0025 - loss: 0.0023 - within_eps_0_005: 0.0662 - within_eps_0_01: 0.1348 - within_eps_0_02: 0.2578 - within_eps_0_05: 0.5685 - within_eps_0_1: 0.8539 - val_log_cosh: 0.0345 - val_loss: 0.0137 - val_within_eps_0_005: 0.0239 - val_within_eps_0_01: 0.0494 - val_within_eps_0_02: 0.1009 - val_within_eps_0_05: 0.2410 - val_within_eps_0_1: 0.4314\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0025 - loss: 0.0023 - within_eps_0_005: 0.0647 - within_eps_0_01: 0.1301 - within_eps_0_02: 0.2567 - within_eps_0_05: 0.5760 - within_eps_0_1: 0.8584 - val_log_cosh: 0.0442 - val_loss: 0.0168 - val_within_eps_0_005: 0.0207 - val_within_eps_0_01: 0.0407 - val_within_eps_0_02: 0.0820 - val_within_eps_0_05: 0.1983 - val_within_eps_0_1: 0.3541\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0024 - loss: 0.0021 - within_eps_0_005: 0.0693 - within_eps_0_01: 0.1361 - within_eps_0_02: 0.2695 - within_eps_0_05: 0.5923 - within_eps_0_1: 0.8700 - val_log_cosh: 0.0362 - val_loss: 0.0142 - val_within_eps_0_005: 0.0242 - val_within_eps_0_01: 0.0487 - val_within_eps_0_02: 0.0967 - val_within_eps_0_05: 0.2380 - val_within_eps_0_1: 0.4188\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0024 - loss: 0.0021 - within_eps_0_005: 0.0685 - within_eps_0_01: 0.1368 - within_eps_0_02: 0.2682 - within_eps_0_05: 0.5939 - within_eps_0_1: 0.8713 - val_log_cosh: 0.0396 - val_loss: 0.0154 - val_within_eps_0_005: 0.0261 - val_within_eps_0_01: 0.0490 - val_within_eps_0_02: 0.0951 - val_within_eps_0_05: 0.2081 - val_within_eps_0_1: 0.3787\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0023 - loss: 0.0021 - within_eps_0_005: 0.0703 - within_eps_0_01: 0.1391 - within_eps_0_02: 0.2685 - within_eps_0_05: 0.5936 - within_eps_0_1: 0.8735 - val_log_cosh: 0.0372 - val_loss: 0.0147 - val_within_eps_0_005: 0.0264 - val_within_eps_0_01: 0.0507 - val_within_eps_0_02: 0.0977 - val_within_eps_0_05: 0.2284 - val_within_eps_0_1: 0.3876\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0023 - loss: 0.0020 - within_eps_0_005: 0.0699 - within_eps_0_01: 0.1392 - within_eps_0_02: 0.2740 - within_eps_0_05: 0.6035 - within_eps_0_1: 0.8771 - val_log_cosh: 0.0406 - val_loss: 0.0156 - val_within_eps_0_005: 0.0253 - val_within_eps_0_01: 0.0501 - val_within_eps_0_02: 0.0958 - val_within_eps_0_05: 0.2111 - val_within_eps_0_1: 0.3840\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0022 - loss: 0.0020 - within_eps_0_005: 0.0717 - within_eps_0_01: 0.1448 - within_eps_0_02: 0.2820 - within_eps_0_05: 0.6141 - within_eps_0_1: 0.8811 - val_log_cosh: 0.0354 - val_loss: 0.0140 - val_within_eps_0_005: 0.0238 - val_within_eps_0_01: 0.0485 - val_within_eps_0_02: 0.0980 - val_within_eps_0_05: 0.2368 - val_within_eps_0_1: 0.4014\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0020 - loss: 0.0019 - within_eps_0_005: 0.0748 - within_eps_0_01: 0.1465 - within_eps_0_02: 0.2908 - within_eps_0_05: 0.6277 - within_eps_0_1: 0.8935 - val_log_cosh: 0.0395 - val_loss: 0.0152 - val_within_eps_0_005: 0.0248 - val_within_eps_0_01: 0.0488 - val_within_eps_0_02: 0.0963 - val_within_eps_0_05: 0.2173 - val_within_eps_0_1: 0.3893\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0021 - loss: 0.0019 - within_eps_0_005: 0.0758 - within_eps_0_01: 0.1472 - within_eps_0_02: 0.2909 - within_eps_0_05: 0.6278 - within_eps_0_1: 0.8910 - val_log_cosh: 0.0389 - val_loss: 0.0148 - val_within_eps_0_005: 0.0239 - val_within_eps_0_01: 0.0479 - val_within_eps_0_02: 0.0940 - val_within_eps_0_05: 0.2329 - val_within_eps_0_1: 0.4072\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0020 - loss: 0.0019 - within_eps_0_005: 0.0744 - within_eps_0_01: 0.1481 - within_eps_0_02: 0.2898 - within_eps_0_05: 0.6266 - within_eps_0_1: 0.8931 - val_log_cosh: 0.0396 - val_loss: 0.0152 - val_within_eps_0_005: 0.0239 - val_within_eps_0_01: 0.0488 - val_within_eps_0_02: 0.0962 - val_within_eps_0_05: 0.2241 - val_within_eps_0_1: 0.4036\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0020 - loss: 0.0018 - within_eps_0_005: 0.0771 - within_eps_0_01: 0.1512 - within_eps_0_02: 0.2929 - within_eps_0_05: 0.6364 - within_eps_0_1: 0.8967 - val_log_cosh: 0.0359 - val_loss: 0.0138 - val_within_eps_0_005: 0.0250 - val_within_eps_0_01: 0.0516 - val_within_eps_0_02: 0.1060 - val_within_eps_0_05: 0.2565 - val_within_eps_0_1: 0.4591\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0814 - within_eps_0_01: 0.1582 - within_eps_0_02: 0.3063 - within_eps_0_05: 0.6510 - within_eps_0_1: 0.9069 - val_log_cosh: 0.0384 - val_loss: 0.0148 - val_within_eps_0_005: 0.0266 - val_within_eps_0_01: 0.0536 - val_within_eps_0_02: 0.1045 - val_within_eps_0_05: 0.2322 - val_within_eps_0_1: 0.4165\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0018 - loss: 0.0016 - within_eps_0_005: 0.0825 - within_eps_0_01: 0.1626 - within_eps_0_02: 0.3116 - within_eps_0_05: 0.6616 - within_eps_0_1: 0.9136 - val_log_cosh: 0.0353 - val_loss: 0.0136 - val_within_eps_0_005: 0.0292 - val_within_eps_0_01: 0.0550 - val_within_eps_0_02: 0.1082 - val_within_eps_0_05: 0.2617 - val_within_eps_0_1: 0.4542\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0788 - within_eps_0_01: 0.1567 - within_eps_0_02: 0.3087 - within_eps_0_05: 0.6539 - within_eps_0_1: 0.9107 - val_log_cosh: 0.0402 - val_loss: 0.0154 - val_within_eps_0_005: 0.0218 - val_within_eps_0_01: 0.0431 - val_within_eps_0_02: 0.0923 - val_within_eps_0_05: 0.2291 - val_within_eps_0_1: 0.4001\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - log_cosh: 0.0018 - loss: 0.0017 - within_eps_0_005: 0.0787 - within_eps_0_01: 0.1569 - within_eps_0_02: 0.3076 - within_eps_0_05: 0.6576 - within_eps_0_1: 0.9091 - val_log_cosh: 0.0349 - val_loss: 0.0136 - val_within_eps_0_005: 0.0298 - val_within_eps_0_01: 0.0598 - val_within_eps_0_02: 0.1159 - val_within_eps_0_05: 0.2580 - val_within_eps_0_1: 0.4291\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0017 - loss: 0.0015 - within_eps_0_005: 0.0847 - within_eps_0_01: 0.1686 - within_eps_0_02: 0.3262 - within_eps_0_05: 0.6764 - within_eps_0_1: 0.9191 - val_log_cosh: 0.0413 - val_loss: 0.0155 - val_within_eps_0_005: 0.0245 - val_within_eps_0_01: 0.0477 - val_within_eps_0_02: 0.0929 - val_within_eps_0_05: 0.2251 - val_within_eps_0_1: 0.4071\n",
      "  -> val_log_cosh(min) δ=0.1: 0.034529011697\n",
      "\n",
      "Tabla val_log_cosh(min) por δ (orden asc):\n",
      "  δ=  0.1: 0.034529011697\n",
      "  δ=0.04116208553314208: 0.037210494280\n",
      "  δ= 0.01: 0.039921592921\n",
      "  δ=0.00853496789932251: 0.043731782585\n",
      "  δ= 0.02: 0.043790385127\n",
      "  δ=0.017357412725687027: 0.044514026493\n",
      "  δ= 0.05: 0.044946625829\n",
      "  δ=0.03049677610397339: 0.045992057770\n",
      "\n",
      ">>> Mejor δ por val_log_cosh: 0.1 (val_log_cosh=0.034529011697)\n",
      "\n",
      "Resultados TEST - Escenario S (GRU)\n",
      "  loss (Huber):              0.159487\n",
      "  log_cosh:                  1.329203\n",
      "  within_eps_0_005          : 0.011641\n",
      "  within_eps_0_01           : 0.020859\n",
      "  within_eps_0_02           : 0.037344\n",
      "  within_eps_0_05           : 0.078720\n",
      "  within_eps_0_1            : 0.138132\n",
      "  AUTC[0.005–0.100]:         nan\n",
      "\n",
      "Grid δ (calibrado con cuantiles |e| en VAL): [0.01, 0.014598846435546875, 0.02, 0.02976226806640625, 0.05, 0.051824706792831444, 0.07143068313598633, 0.1]\n",
      "\n",
      "=== Barrido Huber delta _M (GRU) ===\n",
      "\n",
      "--- Entrenando δ=0.01 ---\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 07:42:56.034386: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - log_cosh: 0.3148 - loss: 0.0070 - within_eps_0_005: 0.0047 - within_eps_0_01: 0.0095 - within_eps_0_02: 0.0195 - within_eps_0_05: 0.0485 - within_eps_0_1: 0.0967 - val_log_cosh: 0.1318 - val_loss: 0.0041 - val_within_eps_0_005: 0.0080 - val_within_eps_0_01: 0.0161 - val_within_eps_0_02: 0.0319 - val_within_eps_0_05: 0.0773 - val_within_eps_0_1: 0.1506\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.1345 - loss: 0.0043 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0146 - within_eps_0_02: 0.0292 - within_eps_0_05: 0.0729 - within_eps_0_1: 0.1461 - val_log_cosh: 0.1029 - val_loss: 0.0034 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0242 - val_within_eps_0_02: 0.0464 - val_within_eps_0_05: 0.1161 - val_within_eps_0_1: 0.2238\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0982 - loss: 0.0036 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0174 - within_eps_0_02: 0.0341 - within_eps_0_05: 0.0863 - within_eps_0_1: 0.1703 - val_log_cosh: 0.0945 - val_loss: 0.0033 - val_within_eps_0_005: 0.0107 - val_within_eps_0_01: 0.0211 - val_within_eps_0_02: 0.0428 - val_within_eps_0_05: 0.1097 - val_within_eps_0_1: 0.2271\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0705 - loss: 0.0030 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0210 - within_eps_0_02: 0.0417 - within_eps_0_05: 0.1035 - within_eps_0_1: 0.2056 - val_log_cosh: 0.0905 - val_loss: 0.0032 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0581 - val_within_eps_0_05: 0.1388 - val_within_eps_0_1: 0.2582\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0468 - loss: 0.0024 - within_eps_0_005: 0.0129 - within_eps_0_01: 0.0255 - within_eps_0_02: 0.0515 - within_eps_0_05: 0.1294 - within_eps_0_1: 0.2557 - val_log_cosh: 0.0835 - val_loss: 0.0031 - val_within_eps_0_005: 0.0159 - val_within_eps_0_01: 0.0313 - val_within_eps_0_02: 0.0603 - val_within_eps_0_05: 0.1389 - val_within_eps_0_1: 0.2472\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0303 - loss: 0.0019 - within_eps_0_005: 0.0164 - within_eps_0_01: 0.0332 - within_eps_0_02: 0.0659 - within_eps_0_05: 0.1637 - within_eps_0_1: 0.3204 - val_log_cosh: 0.0746 - val_loss: 0.0028 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0329 - val_within_eps_0_02: 0.0650 - val_within_eps_0_05: 0.1560 - val_within_eps_0_1: 0.2719\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0184 - loss: 0.0015 - within_eps_0_005: 0.0217 - within_eps_0_01: 0.0435 - within_eps_0_02: 0.0862 - within_eps_0_05: 0.2123 - within_eps_0_1: 0.4097 - val_log_cosh: 0.0668 - val_loss: 0.0026 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0364 - val_within_eps_0_02: 0.0730 - val_within_eps_0_05: 0.1762 - val_within_eps_0_1: 0.3125\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0111 - loss: 0.0011 - within_eps_0_005: 0.0285 - within_eps_0_01: 0.0569 - within_eps_0_02: 0.1142 - within_eps_0_05: 0.2786 - within_eps_0_1: 0.5206 - val_log_cosh: 0.0664 - val_loss: 0.0026 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0384 - val_within_eps_0_02: 0.0765 - val_within_eps_0_05: 0.1865 - val_within_eps_0_1: 0.3323\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0074 - loss: 8.9628e-04 - within_eps_0_005: 0.0356 - within_eps_0_01: 0.0714 - within_eps_0_02: 0.1423 - within_eps_0_05: 0.3447 - within_eps_0_1: 0.6209 - val_log_cosh: 0.0661 - val_loss: 0.0026 - val_within_eps_0_005: 0.0195 - val_within_eps_0_01: 0.0384 - val_within_eps_0_02: 0.0764 - val_within_eps_0_05: 0.1888 - val_within_eps_0_1: 0.3394\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0056 - loss: 7.6157e-04 - within_eps_0_005: 0.0431 - within_eps_0_01: 0.0859 - within_eps_0_02: 0.1705 - within_eps_0_05: 0.4053 - within_eps_0_1: 0.6949 - val_log_cosh: 0.0590 - val_loss: 0.0024 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0388 - val_within_eps_0_02: 0.0782 - val_within_eps_0_05: 0.1931 - val_within_eps_0_1: 0.3472\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0048 - loss: 6.9448e-04 - within_eps_0_005: 0.0479 - within_eps_0_01: 0.0953 - within_eps_0_02: 0.1885 - within_eps_0_05: 0.4402 - within_eps_0_1: 0.7344 - val_log_cosh: 0.0656 - val_loss: 0.0026 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0367 - val_within_eps_0_02: 0.0721 - val_within_eps_0_05: 0.1724 - val_within_eps_0_1: 0.3303\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0041 - loss: 6.3823e-04 - within_eps_0_005: 0.0515 - within_eps_0_01: 0.1027 - within_eps_0_02: 0.2041 - within_eps_0_05: 0.4747 - within_eps_0_1: 0.7684 - val_log_cosh: 0.0562 - val_loss: 0.0023 - val_within_eps_0_005: 0.0216 - val_within_eps_0_01: 0.0417 - val_within_eps_0_02: 0.0818 - val_within_eps_0_05: 0.1955 - val_within_eps_0_1: 0.3607\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0038 - loss: 6.0915e-04 - within_eps_0_005: 0.0538 - within_eps_0_01: 0.1082 - within_eps_0_02: 0.2140 - within_eps_0_05: 0.4924 - within_eps_0_1: 0.7854 - val_log_cosh: 0.0616 - val_loss: 0.0025 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0330 - val_within_eps_0_02: 0.0667 - val_within_eps_0_05: 0.1695 - val_within_eps_0_1: 0.3235\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0035 - loss: 5.7890e-04 - within_eps_0_005: 0.0577 - within_eps_0_01: 0.1149 - within_eps_0_02: 0.2268 - within_eps_0_05: 0.5152 - within_eps_0_1: 0.8032 - val_log_cosh: 0.0542 - val_loss: 0.0023 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0800 - val_within_eps_0_05: 0.1914 - val_within_eps_0_1: 0.3491\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0033 - loss: 5.5530e-04 - within_eps_0_005: 0.0603 - within_eps_0_01: 0.1205 - within_eps_0_02: 0.2373 - within_eps_0_05: 0.5336 - within_eps_0_1: 0.8164 - val_log_cosh: 0.0584 - val_loss: 0.0024 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0360 - val_within_eps_0_02: 0.0719 - val_within_eps_0_05: 0.1754 - val_within_eps_0_1: 0.3314\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0031 - loss: 5.3844e-04 - within_eps_0_005: 0.0626 - within_eps_0_01: 0.1249 - within_eps_0_02: 0.2456 - within_eps_0_05: 0.5474 - within_eps_0_1: 0.8262 - val_log_cosh: 0.0599 - val_loss: 0.0025 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0351 - val_within_eps_0_02: 0.0693 - val_within_eps_0_05: 0.1705 - val_within_eps_0_1: 0.3285\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0029 - loss: 5.2084e-04 - within_eps_0_005: 0.0646 - within_eps_0_01: 0.1295 - within_eps_0_02: 0.2537 - within_eps_0_05: 0.5604 - within_eps_0_1: 0.8380 - val_log_cosh: 0.0596 - val_loss: 0.0024 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0685 - val_within_eps_0_05: 0.1732 - val_within_eps_0_1: 0.3279\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0028 - loss: 5.0798e-04 - within_eps_0_005: 0.0668 - within_eps_0_01: 0.1316 - within_eps_0_02: 0.2595 - within_eps_0_05: 0.5702 - within_eps_0_1: 0.8446 - val_log_cosh: 0.0574 - val_loss: 0.0024 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0365 - val_within_eps_0_02: 0.0722 - val_within_eps_0_05: 0.1789 - val_within_eps_0_1: 0.3318\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0027 - loss: 5.0025e-04 - within_eps_0_005: 0.0688 - within_eps_0_01: 0.1369 - within_eps_0_02: 0.2666 - within_eps_0_05: 0.5783 - within_eps_0_1: 0.8485 - val_log_cosh: 0.0529 - val_loss: 0.0022 - val_within_eps_0_005: 0.0216 - val_within_eps_0_01: 0.0419 - val_within_eps_0_02: 0.0827 - val_within_eps_0_05: 0.1902 - val_within_eps_0_1: 0.3583\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0026 - loss: 4.8781e-04 - within_eps_0_005: 0.0695 - within_eps_0_01: 0.1393 - within_eps_0_02: 0.2714 - within_eps_0_05: 0.5879 - within_eps_0_1: 0.8551 - val_log_cosh: 0.0563 - val_loss: 0.0023 - val_within_eps_0_005: 0.0200 - val_within_eps_0_01: 0.0401 - val_within_eps_0_02: 0.0795 - val_within_eps_0_05: 0.1878 - val_within_eps_0_1: 0.3469\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0025 - loss: 4.7046e-04 - within_eps_0_005: 0.0732 - within_eps_0_01: 0.1447 - within_eps_0_02: 0.2828 - within_eps_0_05: 0.6043 - within_eps_0_1: 0.8652 - val_log_cosh: 0.0611 - val_loss: 0.0025 - val_within_eps_0_005: 0.0182 - val_within_eps_0_01: 0.0361 - val_within_eps_0_02: 0.0704 - val_within_eps_0_05: 0.1724 - val_within_eps_0_1: 0.3279\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - log_cosh: 0.0024 - loss: 4.5967e-04 - within_eps_0_005: 0.0737 - within_eps_0_01: 0.1474 - within_eps_0_02: 0.2857 - within_eps_0_05: 0.6110 - within_eps_0_1: 0.8729 - val_log_cosh: 0.0552 - val_loss: 0.0023 - val_within_eps_0_005: 0.0188 - val_within_eps_0_01: 0.0375 - val_within_eps_0_02: 0.0750 - val_within_eps_0_05: 0.1853 - val_within_eps_0_1: 0.3480\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - log_cosh: 0.0023 - loss: 4.4878e-04 - within_eps_0_005: 0.0762 - within_eps_0_01: 0.1514 - within_eps_0_02: 0.2935 - within_eps_0_05: 0.6197 - within_eps_0_1: 0.8771 - val_log_cosh: 0.0590 - val_loss: 0.0024 - val_within_eps_0_005: 0.0182 - val_within_eps_0_01: 0.0369 - val_within_eps_0_02: 0.0732 - val_within_eps_0_05: 0.1745 - val_within_eps_0_1: 0.3316\n",
      "Epoch 24/160\n",
      "\u001b[1m107/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - log_cosh: 0.0022 - loss: 4.4101e-04 - within_eps_0_005: 0.0772 - within_eps_0_01: 0.1548 - within_eps_0_02: 0.2993 - within_eps_0_05: 0.6289 - within_eps_0_1: 0.8817"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 224\u001b[0m\n\u001b[1;32m    221\u001b[0m evaluate_on_test(model_s, test_dss, best_delta\u001b[38;5;241m=\u001b[39mdelta_s, scaler\u001b[38;5;241m=\u001b[39mscaler)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# Escenario M (60→5)\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m model_m, delta_m, path_m \u001b[38;5;241m=\u001b[39m \u001b[43msweep_deltas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResultados TEST - Escenario M (GRU)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    226\u001b[0m evaluate_on_test(model_m, test_dsm, best_delta\u001b[38;5;241m=\u001b[39mdelta_m, scaler\u001b[38;5;241m=\u001b[39mscaler)\n",
      "Cell \u001b[0;32mIn[3], line 177\u001b[0m, in \u001b[0;36msweep_deltas\u001b[0;34m(train_ds, val_ds, scenario_tag, scaler)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m deltas:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Entrenando δ=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m     model, val_logcosh, ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_for_delta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario_tag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  -> val_log_cosh(min) δ=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_logcosh\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.12f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend((d, val_logcosh, ckpt_path))\n",
      "Cell \u001b[0;32mIn[3], line 162\u001b[0m, in \u001b[0;36mtrain_for_delta\u001b[0;34m(train_ds, val_ds, delta, scenario_tag, scaler)\u001b[0m\n\u001b[1;32m    151\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    152\u001b[0m     MODEL_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgru_huber_w\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_h\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_delta\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_eps_tag(delta)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mscenario_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    155\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    156\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTerminateOnNaN(),\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# >>> monitor común e independiente de δ <<<\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_log_cosh\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    159\u001b[0m     ModelCheckpoint(ckpt_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_log_cosh\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m ]\n\u001b[0;32m--> 162\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m vlc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(hist\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_log_cosh\u001b[39m\u001b[38;5;124m\"\u001b[39m, []), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    164\u001b[0m vlc \u001b[38;5;241m=\u001b[39m vlc[np\u001b[38;5;241m.\u001b[39misfinite(vlc)]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/tf-m2/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# GRU + Huber (sweep delta)\n",
    "# Selección de δ basada en métrica común: val_log_cosh\n",
    "# Grid de δ calibrado con cuantiles de |e| (baseline persistencia) en VAL\n",
    "# =========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import List, Tuple\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Dropout, RepeatVector, TimeDistributed, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ---------- Scaler único (MinMax) ----------\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    from joblib import load\n",
    "    scaler = load(\"scaler_modelos.joblib\")\n",
    "\n",
    "# ---------- Config ----------\n",
    "MODEL_DIR = \"./models_gru_huber_sweep\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# EPS para métricas within (escala normalizada [0,1])\n",
    "EPS_LIST = [0.005, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def infer_shapes_from_dataset(ds: tf.data.Dataset) -> Tuple[int, int, int]:\n",
    "    for xb, yb in ds.take(1):\n",
    "        w = int(xb.shape[1])\n",
    "        f = int(xb.shape[2])\n",
    "        h = int(yb.shape[1])\n",
    "        return w, f, h\n",
    "    raise ValueError(\"Dataset vacío\")\n",
    "\n",
    "def _eps_tag(x: float) -> str:\n",
    "    s = f\"{x:.10g}\"\n",
    "    s = s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "    return s.replace('.', '_')\n",
    "\n",
    "# ---------- Métricas ----------\n",
    "def log_cosh_metric(y_true, y_pred):\n",
    "    e = tf.cast(y_pred, tf.float32) - tf.cast(y_true, tf.float32)\n",
    "    ae = tf.abs(e)\n",
    "    return tf.reduce_mean(ae + tf.nn.softplus(-2.0 * ae) - tf.math.log(2.0))\n",
    "log_cosh_metric.__name__ = \"log_cosh\"\n",
    "\n",
    "def make_within_eps_vector_metric(eps_vec: np.ndarray, tag: str):\n",
    "    eps_tf = tf.constant(eps_vec.astype(np.float32), dtype=tf.float32)  # (F,)\n",
    "    def within_eps(y_true, y_pred):\n",
    "        diff = tf.abs(tf.cast(y_pred, tf.float32) - tf.cast(y_true, tf.float32))  # (B,H,F)\n",
    "        thr  = eps_tf[tf.newaxis, tf.newaxis, :]\n",
    "        hit  = tf.cast(diff <= thr, tf.float32)\n",
    "        return tf.reduce_mean(hit)\n",
    "    within_eps.__name__ = tag\n",
    "    return within_eps\n",
    "\n",
    "def build_within_metrics_minmax(scaler, eps_list: List[float], n_features: int):\n",
    "    if not hasattr(scaler, \"data_range_\"):\n",
    "        raise ValueError(\"Se esperaba MinMaxScaler con data_range_.\")\n",
    "    if len(scaler.data_range_) != n_features:\n",
    "        raise ValueError(\"scaler.data_range_ no coincide con n_features.\")\n",
    "    metrics = [log_cosh_metric]\n",
    "    for e in eps_list:\n",
    "        eps_vec = np.full((n_features,), float(e), dtype=np.float32)\n",
    "        tag = f\"within_eps_{_eps_tag(e)}\"\n",
    "        metrics.append(make_within_eps_vector_metric(eps_vec, tag))\n",
    "    return metrics\n",
    "\n",
    "def compute_autc_from_results(res: dict, eps_list: List[float]) -> float:\n",
    "    eps = np.array(sorted(eps_list), dtype=np.float32)\n",
    "    acc = np.array([res.get(f\"within_eps_{_eps_tag(e)}\", np.nan) for e in eps], dtype=np.float32)\n",
    "    mask = np.isfinite(acc)\n",
    "    if mask.sum() < 2:\n",
    "        return float(\"nan\")\n",
    "    return float(np.trapz(acc[mask], eps[mask]) / (eps[mask][-1] - eps[mask][0]))\n",
    "\n",
    "# ---------- Modelo GRU ----------\n",
    "def build_gru_point_model(window: int, n_features: int, horizon: int,\n",
    "                          units_enc: int = 128, units_dec: int = 64,\n",
    "                          p_drop_enc: float = 0.2, p_drop_dec: float = 0.2) -> Model:\n",
    "    inp = Input(shape=(window, n_features))\n",
    "    x = GRU(units_enc, return_sequences=False)(inp)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(p_drop_enc)(x)\n",
    "\n",
    "    x = RepeatVector(horizon)(x)\n",
    "    x = GRU(units_dec, return_sequences=True)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(p_drop_dec)(x)\n",
    "\n",
    "    out_lin = TimeDistributed(Dense(n_features))(x)  # (B,H,F)\n",
    "    return Model(inp, out_lin, name=f\"GRU_POINT_H{horizon}_F{n_features}\")\n",
    "\n",
    "# ---------- Pérdida Huber ----------\n",
    "def make_huber_loss(delta: float):\n",
    "    base = tf.keras.losses.Huber(delta=float(delta))\n",
    "    def huber_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32); y_pred = tf.cast(y_pred, tf.float32)\n",
    "        return base(y_true, y_pred)\n",
    "    huber_loss.__name__ = f\"huber_delta_{_eps_tag(delta)}\"\n",
    "    return huber_loss\n",
    "\n",
    "# ---------- Calibración del grid de δ (Sugerencia 3) ----------\n",
    "def estimate_error_quantiles_persistence(val_ds: tf.data.Dataset, max_batches: int = 256):\n",
    "    \"\"\"Cuantiles de |e| en VAL usando baseline de persistencia (y_hat = último paso repetido).\"\"\"\n",
    "    errs = []\n",
    "    taken = 0\n",
    "    for xb, yb in val_ds:\n",
    "        # xb: (B, W, F), yb: (B, H, F)\n",
    "        yhat = tf.repeat(xb[:, -1:, :], repeats=tf.shape(yb)[1], axis=1)  # (B,H,F)\n",
    "        e = tf.abs(tf.cast(yb, tf.float32) - tf.cast(yhat, tf.float32)).numpy().ravel()\n",
    "        errs.append(e)\n",
    "        taken += 1\n",
    "        if taken >= max_batches:\n",
    "            break\n",
    "    if not errs:\n",
    "        return [0.01, 0.02, 0.05, 0.1]  # fallback\n",
    "    e = np.concatenate(errs)\n",
    "    qs = np.quantile(e, [0.5, 0.75, 0.9, 0.95])\n",
    "    return list(qs)\n",
    "\n",
    "def build_delta_grid(val_ds: tf.data.Dataset):\n",
    "    base = [0.01, 0.02, 0.05, 0.1]                # base pequeña estable\n",
    "    qs = estimate_error_quantiles_persistence(val_ds, max_batches=256)  # p50, p75, p90, p95\n",
    "    cand = sorted(set(base + qs))\n",
    "    # recorte por seguridad al rango normalizado\n",
    "    cand = [float(np.clip(c, 1e-4, 0.5)) for c in cand]\n",
    "    cand = sorted(set(cand))\n",
    "    print(\"\\nGrid δ (calibrado con cuantiles |e| en VAL):\", cand)\n",
    "    return cand\n",
    "\n",
    "# ---------- Entrenamiento para un δ (callbacks en val_log_cosh; Sugerencia 2) ----------\n",
    "def train_for_delta(train_ds: tf.data.Dataset,\n",
    "                    val_ds: tf.data.Dataset,\n",
    "                    delta: float,\n",
    "                    scenario_tag: str,\n",
    "                    scaler) -> tuple[Model, float, str]:\n",
    "    w, f, h = infer_shapes_from_dataset(train_ds)\n",
    "    model = build_gru_point_model(w, f, h)\n",
    "\n",
    "    metrics = build_within_metrics_minmax(scaler, EPS_LIST, n_features=f)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
    "        loss=make_huber_loss(delta),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    ckpt_path = os.path.join(\n",
    "        MODEL_DIR, f\"gru_huber_w{w}_h{h}_delta{_eps_tag(delta)}{scenario_tag}.keras\"\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        # >>> monitor común e independiente de δ <<<\n",
    "        EarlyStopping(monitor=\"val_log_cosh\", mode=\"min\", patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(ckpt_path, monitor=\"val_log_cosh\", mode=\"min\", save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=160, callbacks=callbacks, verbose=1)\n",
    "    vlc = np.array(hist.history.get(\"val_log_cosh\", []), dtype=np.float32)\n",
    "    vlc = vlc[np.isfinite(vlc)]\n",
    "    best_val_logcosh = float(np.min(vlc)) if vlc.size > 0 else np.inf\n",
    "    return model, best_val_logcosh, ckpt_path\n",
    "\n",
    "# ---------- Barrido de deltas (selección por val_log_cosh) ----------\n",
    "def sweep_deltas(train_ds, val_ds, scenario_tag: str, scaler) -> tuple[Model, float, str]:\n",
    "    deltas = build_delta_grid(val_ds)  # Sugerencia 3\n",
    "    print(f\"\\n=== Barrido Huber delta {scenario_tag} (GRU) ===\")\n",
    "    results = []  # (delta, best_val_logcosh, ckpt_path)\n",
    "\n",
    "    best_score = np.inf; best_ckpt=None; best_delta=None; best_model=None\n",
    "    for d in deltas:\n",
    "        print(f\"\\n--- Entrenando δ={d} ---\")\n",
    "        model, val_logcosh, ckpt_path = train_for_delta(train_ds, val_ds, d, scenario_tag, scaler)\n",
    "        print(f\"  -> val_log_cosh(min) δ={d}: {val_logcosh:.12f}\")\n",
    "        results.append((d, val_logcosh, ckpt_path))\n",
    "        if val_logcosh < best_score:\n",
    "            best_score, best_ckpt, best_delta, best_model = val_logcosh, ckpt_path, d, model\n",
    "\n",
    "    # Carga el mejor checkpoint (Flask-ready)\n",
    "    if best_ckpt:\n",
    "        best_model = tf.keras.models.load_model(best_ckpt, compile=False)\n",
    "\n",
    "    # Tabla ordenada para inspección\n",
    "    results_sorted = sorted(results, key=lambda x: x[1])\n",
    "    print(\"\\nTabla val_log_cosh(min) por δ (orden asc):\")\n",
    "    for d, v, _ in results_sorted:\n",
    "        print(f\"  δ={d:>5}: {v:.12f}\")\n",
    "    print(f\"\\n>>> Mejor δ por val_log_cosh: {best_delta} (val_log_cosh={best_score:.12f})\")\n",
    "    return best_model, best_delta, best_ckpt\n",
    "\n",
    "# ---------- Evaluación en TEST ----------\n",
    "def evaluate_on_test(model: tf.keras.Model, ds: tf.data.Dataset, best_delta: float, scaler):\n",
    "    if (model is None) or (best_delta is None) or (not np.isfinite(best_delta)):\n",
    "        print(\"  [AVISO] No se pudo entrenar un modelo válido.\")\n",
    "        return\n",
    "    _, f, _ = infer_shapes_from_dataset(ds)\n",
    "    metrics = build_within_metrics_minmax(scaler, EPS_LIST, n_features=f)\n",
    "    model.compile(optimizer=\"adam\", loss=make_huber_loss(best_delta), metrics=metrics)\n",
    "\n",
    "    res = model.evaluate(ds, return_dict=True, verbose=0)\n",
    "    print(\"  loss (Huber):              {:.6f}\".format(res.get(\"loss\", float(\"nan\"))))\n",
    "    print(\"  log_cosh:                  {:.6f}\".format(res.get(\"log_cosh\", float(\"nan\"))))\n",
    "    for e in EPS_LIST:\n",
    "        key = f\"within_eps_{_eps_tag(e)}\"\n",
    "        print(f\"  {key:26s}: {res.get(key, float('nan')):.6f}\")\n",
    "    autc = compute_autc_from_results(res, EPS_LIST)\n",
    "    eps_min, eps_max = float(min(EPS_LIST)), float(max(EPS_LIST))\n",
    "    print(f\"  AUTC[{eps_min:.3f}–{eps_max:.3f}]:         {autc:.6f}\")\n",
    "\n",
    "# ================== EJECUCIÓN: TRES ESCENARIOS ==================\n",
    "# Usa tus datasets ya creados sin shuffle en val/test:\n",
    "#   train_dss/val_dss/test_dss, train_dsm/val_dsm/test_dsm, train_dsl/val_dsl/test_dsl\n",
    "\n",
    "# Escenario S (20→1)\n",
    "model_s, delta_s, path_s = sweep_deltas(train_dss, val_dss, scenario_tag=\"_S\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario S (GRU)\")\n",
    "evaluate_on_test(model_s, test_dss, best_delta=delta_s, scaler=scaler)\n",
    "\n",
    "# Escenario M (60→5)\n",
    "model_m, delta_m, path_m = sweep_deltas(train_dsm, val_dsm, scenario_tag=\"_M\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario M (GRU)\")\n",
    "evaluate_on_test(model_m, test_dsm, best_delta=delta_m, scaler=scaler)\n",
    "\n",
    "# Escenario L (120→20)\n",
    "model_l, delta_l, path_l = sweep_deltas(train_dsl, val_dsl, scenario_tag=\"_L\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario L (GRU)\")\n",
    "evaluate_on_test(model_l, test_dsl, best_delta=delta_l, scaler=scaler)\n",
    "\n",
    "print(\"\\n=== Mejor δ por escenario (GRU, métrica común: val_log_cosh) ===\")\n",
    "print(f\"  S: {delta_s}  -> {path_s}\")\n",
    "print(f\"  M: {delta_m}  -> {path_m}\")\n",
    "print(f\"  L: {delta_l}  -> {path_l}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db361b0-1c84-499a-8a58-7fad1d097e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
