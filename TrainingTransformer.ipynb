{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784a0ed-ac04-4d3a-af53-04c0fde70b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descarga de índices bursátiles desde Yahoo Finances.\n",
    "# -- Sólo descomentar una vez, el resto de usos se pueden hacer desde el fichero descargado\n",
    "\"\"\"\n",
    "import yfinance as yf\n",
    "\n",
    "tickers = [\n",
    "    \"^GSPC\",\"^IXIC\",\"^DJI\",\"^RUT\",\n",
    "    \"^FTSE\",\"^GDAXI\",\"^FCHI\",\"^125904-USD-STRD\",\"^IBEX\",\n",
    "    \"^N225\",\"^HSI\",\"000001.SS\",\"^KS11\",\"^BSESN\",\n",
    "    \"^GSPTSE\",\"^BVSP\",\"^MXX\",\"^MERV\",\n",
    "    \"^AXJO\",\"^NZ50\",\n",
    "    \"ES=F\",\"NQ=F\",\"YM=F\",\"ZT=F\",\"^VIX\"\n",
    "]\n",
    "\n",
    "# Descarga de cierres diarios sin agrupar por ticker\n",
    "data = yf.download(\n",
    "    tickers,\n",
    "    start=\"2005-01-01\",\n",
    "    end=\"2025-01-02\"\n",
    ")\n",
    "\n",
    "cierres = data[\"Close\"]  # DataFrame con cada ticker como columna\n",
    "cierres.to_csv(\"./data/cierres_diarios_2005_2025.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc34691-25a0-4a1f-9086-93ddab4ccdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso de los datos descargados para entrenamiento\n",
    "# -- Asegurarse de enrutamiento y nombre de fichero correctos\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/cierres_diarios_2005_2025n.csv', parse_dates=['Date'], index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd66cde-2833-4633-8201-741fd914285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 08:49:21.392940: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-09-19 08:49:21.392967: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-09-19 08:49:21.392973: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-09-19 08:49:21.392988: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-19 08:49:21.392999: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Preparación de los datos\n",
    "\n",
    "# Eliminación de nulos\n",
    "df.ffill(inplace=True)\n",
    "df.bfill(inplace=True)\n",
    "\n",
    "# Split en crudo (¡antes de escalar!)\n",
    "n = len(df)\n",
    "train_raw = df.iloc[:int(n*0.7)]\n",
    "val_raw   = df.iloc[int(n*0.7):int(n*0.9)]\n",
    "test_raw  = df.iloc[int(n*0.9):]\n",
    "\n",
    "# Ajustar scaler SOLO con TRAIN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_raw)  # <- fit solo con train\n",
    "\n",
    "# Transformar cada split con ese scaler\n",
    "import pandas as pd\n",
    "train_df = pd.DataFrame(scaler.transform(train_raw), index=train_raw.index, columns=train_raw.columns).astype(\"float32\")\n",
    "val_df   = pd.DataFrame(scaler.transform(val_raw),   index=val_raw.index,   columns=val_raw.columns).astype(\"float32\")\n",
    "test_df  = pd.DataFrame(scaler.transform(test_raw),  index=test_raw.index,  columns=test_raw.columns).astype(\"float32\")\n",
    "\n",
    "# Guardar scaler para escenarios S/M/L\n",
    "dump(scaler, \"scaler_modelos.joblib\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_dataset(data, window_size, horizon, batch_size=32, shuffle=True):\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "        data=data.values,\n",
    "        targets=None,\n",
    "        sequence_length=window_size + horizon,\n",
    "        sequence_stride=1,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return ds.map(\n",
    "        lambda seq: (\n",
    "            tf.cast(seq[:, :window_size, :], tf.float32),\n",
    "            tf.cast(seq[:, window_size:, :], tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Recreamos datasets con shuffle=False para val/test:\n",
    "train_dss = make_dataset(train_df, window_size=20,  horizon=1,  batch_size=32, shuffle=True)\n",
    "val_dss   = make_dataset(val_df,   window_size=20,  horizon=1,  batch_size=32, shuffle=False)\n",
    "test_dss  = make_dataset(test_df,  window_size=20,  horizon=1,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_dsm = make_dataset(train_df, window_size=60,  horizon=5,  batch_size=32, shuffle=True)\n",
    "val_dsm   = make_dataset(val_df,   window_size=60,  horizon=5,  batch_size=32, shuffle=False)\n",
    "test_dsm  = make_dataset(test_df,  window_size=60,  horizon=5,  batch_size=32, shuffle=False)\n",
    "\n",
    "train_dsl = make_dataset(train_df, window_size=120, horizon=20, batch_size=32, shuffle=True)\n",
    "val_dsl   = make_dataset(val_df,   window_size=120, horizon=20, batch_size=32, shuffle=False)\n",
    "test_dsl  = make_dataset(test_df,  window_size=120, horizon=20, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087752d9-adb2-4895-8c39-acce55ec35e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 08:49:23.148063: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid δ (calibrado con cuantiles |e| en VAL): [0.00853496789932251, 0.01, 0.017357412725687027, 0.02, 0.03049677610397339, 0.04116208553314208, 0.05, 0.1]\n",
      "\n",
      "=== Barrido Huber delta _S (Transformer) ===\n",
      "\n",
      "--- Entrenando δ=0.00853496789932251 ---\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 08:49:24.924887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - log_cosh: 0.2003 - loss: 0.0045 - within_eps_0_005: 0.0066 - within_eps_0_01: 0.0131 - within_eps_0_02: 0.0249 - within_eps_0_05: 0.0620 - within_eps_0_1: 0.1275 - val_log_cosh: 0.0939 - val_loss: 0.0029 - val_within_eps_0_005: 0.0101 - val_within_eps_0_01: 0.0213 - val_within_eps_0_02: 0.0436 - val_within_eps_0_05: 0.1102 - val_within_eps_0_1: 0.2213\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.1042 - loss: 0.0032 - within_eps_0_005: 0.0083 - within_eps_0_01: 0.0171 - within_eps_0_02: 0.0339 - within_eps_0_05: 0.0825 - within_eps_0_1: 0.1650 - val_log_cosh: 0.0778 - val_loss: 0.0025 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0498 - val_within_eps_0_05: 0.1196 - val_within_eps_0_1: 0.2187\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0978 - loss: 0.0031 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0175 - within_eps_0_02: 0.0339 - within_eps_0_05: 0.0856 - within_eps_0_1: 0.1708 - val_log_cosh: 0.0733 - val_loss: 0.0023 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1471 - val_within_eps_0_1: 0.2849\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0939 - loss: 0.0030 - within_eps_0_005: 0.0087 - within_eps_0_01: 0.0174 - within_eps_0_02: 0.0349 - within_eps_0_05: 0.0889 - within_eps_0_1: 0.1762 - val_log_cosh: 0.0705 - val_loss: 0.0023 - val_within_eps_0_005: 0.0159 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0561 - val_within_eps_0_05: 0.1421 - val_within_eps_0_1: 0.2767\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0880 - loss: 0.0029 - within_eps_0_005: 0.0094 - within_eps_0_01: 0.0188 - within_eps_0_02: 0.0365 - within_eps_0_05: 0.0927 - within_eps_0_1: 0.1834 - val_log_cosh: 0.0678 - val_loss: 0.0023 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0255 - val_within_eps_0_02: 0.0492 - val_within_eps_0_05: 0.1194 - val_within_eps_0_1: 0.2506\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0837 - loss: 0.0029 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0183 - within_eps_0_02: 0.0378 - within_eps_0_05: 0.0953 - within_eps_0_1: 0.1872 - val_log_cosh: 0.0647 - val_loss: 0.0022 - val_within_eps_0_005: 0.0197 - val_within_eps_0_01: 0.0370 - val_within_eps_0_02: 0.0715 - val_within_eps_0_05: 0.1611 - val_within_eps_0_1: 0.3121\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - log_cosh: 0.0778 - loss: 0.0027 - within_eps_0_005: 0.0093 - within_eps_0_01: 0.0192 - within_eps_0_02: 0.0394 - within_eps_0_05: 0.0987 - within_eps_0_1: 0.1961 - val_log_cosh: 0.0597 - val_loss: 0.0021 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0309 - val_within_eps_0_02: 0.0670 - val_within_eps_0_05: 0.1646 - val_within_eps_0_1: 0.3065\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0762 - loss: 0.0027 - within_eps_0_005: 0.0099 - within_eps_0_01: 0.0193 - within_eps_0_02: 0.0378 - within_eps_0_05: 0.0958 - within_eps_0_1: 0.1930 - val_log_cosh: 0.0558 - val_loss: 0.0021 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1405 - val_within_eps_0_1: 0.2556\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0699 - loss: 0.0026 - within_eps_0_005: 0.0100 - within_eps_0_01: 0.0212 - within_eps_0_02: 0.0424 - within_eps_0_05: 0.1033 - within_eps_0_1: 0.2044 - val_log_cosh: 0.0634 - val_loss: 0.0022 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0657 - val_within_eps_0_05: 0.1761 - val_within_eps_0_1: 0.3282\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0654 - loss: 0.0025 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0218 - within_eps_0_02: 0.0443 - within_eps_0_05: 0.1083 - within_eps_0_1: 0.2126 - val_log_cosh: 0.0734 - val_loss: 0.0023 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0344 - val_within_eps_0_02: 0.0706 - val_within_eps_0_05: 0.1738 - val_within_eps_0_1: 0.3282\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0608 - loss: 0.0024 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0231 - within_eps_0_02: 0.0468 - within_eps_0_05: 0.1130 - within_eps_0_1: 0.2195 - val_log_cosh: 0.0756 - val_loss: 0.0024 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1429 - val_within_eps_0_1: 0.2877\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0563 - loss: 0.0023 - within_eps_0_005: 0.0118 - within_eps_0_01: 0.0234 - within_eps_0_02: 0.0483 - within_eps_0_05: 0.1180 - within_eps_0_1: 0.2286 - val_log_cosh: 0.0954 - val_loss: 0.0028 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0563 - val_within_eps_0_05: 0.1468 - val_within_eps_0_1: 0.2873\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0507 - loss: 0.0022 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0244 - within_eps_0_02: 0.0494 - within_eps_0_05: 0.1219 - within_eps_0_1: 0.2432 - val_log_cosh: 0.0854 - val_loss: 0.0026 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1410 - val_within_eps_0_1: 0.2681\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0468 - loss: 0.0021 - within_eps_0_005: 0.0127 - within_eps_0_01: 0.0260 - within_eps_0_02: 0.0506 - within_eps_0_05: 0.1258 - within_eps_0_1: 0.2506 - val_log_cosh: 0.0943 - val_loss: 0.0028 - val_within_eps_0_005: 0.0119 - val_within_eps_0_01: 0.0252 - val_within_eps_0_02: 0.0524 - val_within_eps_0_05: 0.1228 - val_within_eps_0_1: 0.2427\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0437 - loss: 0.0020 - within_eps_0_005: 0.0137 - within_eps_0_01: 0.0265 - within_eps_0_02: 0.0533 - within_eps_0_05: 0.1325 - within_eps_0_1: 0.2631 - val_log_cosh: 0.1214 - val_loss: 0.0033 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0234 - val_within_eps_0_02: 0.0496 - val_within_eps_0_05: 0.1229 - val_within_eps_0_1: 0.2417\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0383 - loss: 0.0019 - within_eps_0_005: 0.0143 - within_eps_0_01: 0.0283 - within_eps_0_02: 0.0569 - within_eps_0_05: 0.1424 - within_eps_0_1: 0.2808 - val_log_cosh: 0.1217 - val_loss: 0.0033 - val_within_eps_0_005: 0.0074 - val_within_eps_0_01: 0.0162 - val_within_eps_0_02: 0.0339 - val_within_eps_0_05: 0.0928 - val_within_eps_0_1: 0.2015\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0356 - loss: 0.0018 - within_eps_0_005: 0.0150 - within_eps_0_01: 0.0307 - within_eps_0_02: 0.0600 - within_eps_0_05: 0.1484 - within_eps_0_1: 0.2944 - val_log_cosh: 0.0720 - val_loss: 0.0024 - val_within_eps_0_005: 0.0167 - val_within_eps_0_01: 0.0331 - val_within_eps_0_02: 0.0656 - val_within_eps_0_05: 0.1591 - val_within_eps_0_1: 0.2913\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0315 - loss: 0.0017 - within_eps_0_005: 0.0162 - within_eps_0_01: 0.0320 - within_eps_0_02: 0.0636 - within_eps_0_05: 0.1581 - within_eps_0_1: 0.3103 - val_log_cosh: 0.0540 - val_loss: 0.0020 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0597 - val_within_eps_0_05: 0.1464 - val_within_eps_0_1: 0.2867\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0286 - loss: 0.0016 - within_eps_0_005: 0.0170 - within_eps_0_01: 0.0343 - within_eps_0_02: 0.0688 - within_eps_0_05: 0.1693 - within_eps_0_1: 0.3268 - val_log_cosh: 0.0771 - val_loss: 0.0024 - val_within_eps_0_005: 0.0200 - val_within_eps_0_01: 0.0388 - val_within_eps_0_02: 0.0723 - val_within_eps_0_05: 0.1724 - val_within_eps_0_1: 0.3098\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0250 - loss: 0.0015 - within_eps_0_005: 0.0179 - within_eps_0_01: 0.0367 - within_eps_0_02: 0.0728 - within_eps_0_05: 0.1767 - within_eps_0_1: 0.3440 - val_log_cosh: 0.0506 - val_loss: 0.0019 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0625 - val_within_eps_0_05: 0.1592 - val_within_eps_0_1: 0.3029\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0222 - loss: 0.0014 - within_eps_0_005: 0.0197 - within_eps_0_01: 0.0369 - within_eps_0_02: 0.0734 - within_eps_0_05: 0.1858 - within_eps_0_1: 0.3662 - val_log_cosh: 0.0839 - val_loss: 0.0026 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0341 - val_within_eps_0_02: 0.0670 - val_within_eps_0_05: 0.1482 - val_within_eps_0_1: 0.2820\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - log_cosh: 0.0189 - loss: 0.0013 - within_eps_0_005: 0.0207 - within_eps_0_01: 0.0401 - within_eps_0_02: 0.0823 - within_eps_0_05: 0.2041 - within_eps_0_1: 0.3952 - val_log_cosh: 0.2153 - val_loss: 0.0050 - val_within_eps_0_005: 0.0011 - val_within_eps_0_01: 0.0025 - val_within_eps_0_02: 0.0048 - val_within_eps_0_05: 0.0137 - val_within_eps_0_1: 0.0437\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0174 - loss: 0.0012 - within_eps_0_005: 0.0216 - within_eps_0_01: 0.0440 - within_eps_0_02: 0.0884 - within_eps_0_05: 0.2159 - within_eps_0_1: 0.4127 - val_log_cosh: 0.1159 - val_loss: 0.0031 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0332 - val_within_eps_0_02: 0.0696 - val_within_eps_0_05: 0.1553 - val_within_eps_0_1: 0.2689\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0151 - loss: 0.0011 - within_eps_0_005: 0.0232 - within_eps_0_01: 0.0466 - within_eps_0_02: 0.0942 - within_eps_0_05: 0.2298 - within_eps_0_1: 0.4443 - val_log_cosh: 0.0571 - val_loss: 0.0021 - val_within_eps_0_005: 0.0232 - val_within_eps_0_01: 0.0464 - val_within_eps_0_02: 0.0857 - val_within_eps_0_05: 0.1793 - val_within_eps_0_1: 0.3156\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0122 - loss: 0.0010 - within_eps_0_005: 0.0259 - within_eps_0_01: 0.0513 - within_eps_0_02: 0.1026 - within_eps_0_05: 0.2536 - within_eps_0_1: 0.4853 - val_log_cosh: 0.1243 - val_loss: 0.0033 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0335 - val_within_eps_0_02: 0.0688 - val_within_eps_0_05: 0.1554 - val_within_eps_0_1: 0.2653\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - log_cosh: 0.0122 - loss: 0.0010 - within_eps_0_005: 0.0273 - within_eps_0_01: 0.0554 - within_eps_0_02: 0.1065 - within_eps_0_05: 0.2635 - within_eps_0_1: 0.4966 - val_log_cosh: 0.0590 - val_loss: 0.0021 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0340 - val_within_eps_0_02: 0.0692 - val_within_eps_0_05: 0.1780 - val_within_eps_0_1: 0.3449\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0095 - loss: 8.9560e-04 - within_eps_0_005: 0.0302 - within_eps_0_01: 0.0604 - within_eps_0_02: 0.1202 - within_eps_0_05: 0.2925 - within_eps_0_1: 0.5423 - val_log_cosh: 0.0794 - val_loss: 0.0025 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0313 - val_within_eps_0_02: 0.0621 - val_within_eps_0_05: 0.1534 - val_within_eps_0_1: 0.3068\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0077 - loss: 7.9886e-04 - within_eps_0_005: 0.0321 - within_eps_0_01: 0.0668 - within_eps_0_02: 0.1329 - within_eps_0_05: 0.3251 - within_eps_0_1: 0.5932 - val_log_cosh: 0.1762 - val_loss: 0.0043 - val_within_eps_0_005: 0.0055 - val_within_eps_0_01: 0.0120 - val_within_eps_0_02: 0.0239 - val_within_eps_0_05: 0.0600 - val_within_eps_0_1: 0.1103\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - log_cosh: 0.0092 - loss: 8.7209e-04 - within_eps_0_005: 0.0306 - within_eps_0_01: 0.0626 - within_eps_0_02: 0.1241 - within_eps_0_05: 0.3040 - within_eps_0_1: 0.5608 - val_log_cosh: 0.1392 - val_loss: 0.0037 - val_within_eps_0_005: 0.0097 - val_within_eps_0_01: 0.0195 - val_within_eps_0_02: 0.0380 - val_within_eps_0_05: 0.0868 - val_within_eps_0_1: 0.1515\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0076 - loss: 7.8343e-04 - within_eps_0_005: 0.0353 - within_eps_0_01: 0.0710 - within_eps_0_02: 0.1410 - within_eps_0_05: 0.3388 - within_eps_0_1: 0.6103 - val_log_cosh: 0.1104 - val_loss: 0.0030 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0292 - val_within_eps_0_02: 0.0562 - val_within_eps_0_05: 0.1373 - val_within_eps_0_1: 0.2645\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - log_cosh: 0.0054 - loss: 6.5350e-04 - within_eps_0_005: 0.0429 - within_eps_0_01: 0.0853 - within_eps_0_02: 0.1669 - within_eps_0_05: 0.3947 - within_eps_0_1: 0.6866 - val_log_cosh: 0.1158 - val_loss: 0.0032 - val_within_eps_0_005: 0.0105 - val_within_eps_0_01: 0.0222 - val_within_eps_0_02: 0.0468 - val_within_eps_0_05: 0.1263 - val_within_eps_0_1: 0.2318\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0063 - loss: 6.9949e-04 - within_eps_0_005: 0.0389 - within_eps_0_01: 0.0781 - within_eps_0_02: 0.1591 - within_eps_0_05: 0.3802 - within_eps_0_1: 0.6658 - val_log_cosh: 0.1798 - val_loss: 0.0044 - val_within_eps_0_005: 0.0048 - val_within_eps_0_01: 0.0098 - val_within_eps_0_02: 0.0191 - val_within_eps_0_05: 0.0427 - val_within_eps_0_1: 0.0913\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0102 - loss: 9.0518e-04 - within_eps_0_005: 0.0315 - within_eps_0_01: 0.0613 - within_eps_0_02: 0.1227 - within_eps_0_05: 0.3005 - within_eps_0_1: 0.5542 - val_log_cosh: 0.0536 - val_loss: 0.0020 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0328 - val_within_eps_0_02: 0.0646 - val_within_eps_0_05: 0.1592 - val_within_eps_0_1: 0.3318\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0066 - loss: 7.2979e-04 - within_eps_0_005: 0.0378 - within_eps_0_01: 0.0732 - within_eps_0_02: 0.1460 - within_eps_0_05: 0.3575 - within_eps_0_1: 0.6412 - val_log_cosh: 0.0554 - val_loss: 0.0020 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0631 - val_within_eps_0_05: 0.1619 - val_within_eps_0_1: 0.3206\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0044 - loss: 5.9011e-04 - within_eps_0_005: 0.0441 - within_eps_0_01: 0.0899 - within_eps_0_02: 0.1808 - within_eps_0_05: 0.4270 - within_eps_0_1: 0.7335 - val_log_cosh: 0.1468 - val_loss: 0.0038 - val_within_eps_0_005: 0.0083 - val_within_eps_0_01: 0.0183 - val_within_eps_0_02: 0.0382 - val_within_eps_0_05: 0.0876 - val_within_eps_0_1: 0.1589\n",
      "  -> min val_log_cosh=0.050636094064 | min val_huber=0.001937584835\n",
      "\n",
      "--- Entrenando δ=0.01 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 109ms/step - log_cosh: 0.1913 - loss: 0.0052 - within_eps_0_005: 0.0069 - within_eps_0_01: 0.0137 - within_eps_0_02: 0.0269 - within_eps_0_05: 0.0649 - within_eps_0_1: 0.1282 - val_log_cosh: 0.0864 - val_loss: 0.0031 - val_within_eps_0_005: 0.0103 - val_within_eps_0_01: 0.0202 - val_within_eps_0_02: 0.0405 - val_within_eps_0_05: 0.1071 - val_within_eps_0_1: 0.2208\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.1049 - loss: 0.0038 - within_eps_0_005: 0.0087 - within_eps_0_01: 0.0168 - within_eps_0_02: 0.0332 - within_eps_0_05: 0.0836 - within_eps_0_1: 0.1674 - val_log_cosh: 0.0734 - val_loss: 0.0028 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0574 - val_within_eps_0_05: 0.1454 - val_within_eps_0_1: 0.2634\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0992 - loss: 0.0037 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0175 - within_eps_0_02: 0.0355 - within_eps_0_05: 0.0876 - within_eps_0_1: 0.1753 - val_log_cosh: 0.0788 - val_loss: 0.0028 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0557 - val_within_eps_0_05: 0.1367 - val_within_eps_0_1: 0.2833\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0970 - loss: 0.0036 - within_eps_0_005: 0.0093 - within_eps_0_01: 0.0172 - within_eps_0_02: 0.0342 - within_eps_0_05: 0.0853 - within_eps_0_1: 0.1700 - val_log_cosh: 0.0707 - val_loss: 0.0027 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0526 - val_within_eps_0_05: 0.1366 - val_within_eps_0_1: 0.2787\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0895 - loss: 0.0035 - within_eps_0_005: 0.0087 - within_eps_0_01: 0.0175 - within_eps_0_02: 0.0359 - within_eps_0_05: 0.0900 - within_eps_0_1: 0.1825 - val_log_cosh: 0.0720 - val_loss: 0.0026 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0327 - val_within_eps_0_02: 0.0628 - val_within_eps_0_05: 0.1533 - val_within_eps_0_1: 0.3135\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0847 - loss: 0.0034 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0181 - within_eps_0_02: 0.0378 - within_eps_0_05: 0.0941 - within_eps_0_1: 0.1886 - val_log_cosh: 0.0727 - val_loss: 0.0027 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0311 - val_within_eps_0_02: 0.0625 - val_within_eps_0_05: 0.1624 - val_within_eps_0_1: 0.3214\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0799 - loss: 0.0033 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0197 - within_eps_0_02: 0.0388 - within_eps_0_05: 0.0980 - within_eps_0_1: 0.1915 - val_log_cosh: 0.0684 - val_loss: 0.0026 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0628 - val_within_eps_0_05: 0.1604 - val_within_eps_0_1: 0.3030\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0760 - loss: 0.0032 - within_eps_0_005: 0.0093 - within_eps_0_01: 0.0191 - within_eps_0_02: 0.0392 - within_eps_0_05: 0.0966 - within_eps_0_1: 0.1931 - val_log_cosh: 0.0673 - val_loss: 0.0026 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0405 - val_within_eps_0_02: 0.0783 - val_within_eps_0_05: 0.1885 - val_within_eps_0_1: 0.3426\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - log_cosh: 0.0717 - loss: 0.0031 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0207 - within_eps_0_02: 0.0422 - within_eps_0_05: 0.1024 - within_eps_0_1: 0.2027 - val_log_cosh: 0.0665 - val_loss: 0.0026 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0607 - val_within_eps_0_05: 0.1554 - val_within_eps_0_1: 0.3178\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0667 - loss: 0.0029 - within_eps_0_005: 0.0109 - within_eps_0_01: 0.0217 - within_eps_0_02: 0.0441 - within_eps_0_05: 0.1076 - within_eps_0_1: 0.2130 - val_log_cosh: 0.0730 - val_loss: 0.0027 - val_within_eps_0_005: 0.0194 - val_within_eps_0_01: 0.0369 - val_within_eps_0_02: 0.0713 - val_within_eps_0_05: 0.1640 - val_within_eps_0_1: 0.2961\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0622 - loss: 0.0028 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0219 - within_eps_0_02: 0.0442 - within_eps_0_05: 0.1081 - within_eps_0_1: 0.2178 - val_log_cosh: 0.0646 - val_loss: 0.0025 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0336 - val_within_eps_0_02: 0.0698 - val_within_eps_0_05: 0.1709 - val_within_eps_0_1: 0.3261\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0564 - loss: 0.0027 - within_eps_0_005: 0.0114 - within_eps_0_01: 0.0232 - within_eps_0_02: 0.0471 - within_eps_0_05: 0.1161 - within_eps_0_1: 0.2306 - val_log_cosh: 0.0710 - val_loss: 0.0028 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0525 - val_within_eps_0_05: 0.1372 - val_within_eps_0_1: 0.2800\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0538 - loss: 0.0026 - within_eps_0_005: 0.0118 - within_eps_0_01: 0.0239 - within_eps_0_02: 0.0491 - within_eps_0_05: 0.1205 - within_eps_0_1: 0.2391 - val_log_cosh: 0.0756 - val_loss: 0.0028 - val_within_eps_0_005: 0.0183 - val_within_eps_0_01: 0.0360 - val_within_eps_0_02: 0.0697 - val_within_eps_0_05: 0.1585 - val_within_eps_0_1: 0.2944\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0486 - loss: 0.0025 - within_eps_0_005: 0.0127 - within_eps_0_01: 0.0241 - within_eps_0_02: 0.0495 - within_eps_0_05: 0.1237 - within_eps_0_1: 0.2457 - val_log_cosh: 0.0816 - val_loss: 0.0029 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0520 - val_within_eps_0_05: 0.1400 - val_within_eps_0_1: 0.2807\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - log_cosh: 0.0452 - loss: 0.0024 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0511 - within_eps_0_05: 0.1293 - within_eps_0_1: 0.2539 - val_log_cosh: 0.0769 - val_loss: 0.0028 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0628 - val_within_eps_0_05: 0.1640 - val_within_eps_0_1: 0.3018\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0444 - loss: 0.0024 - within_eps_0_005: 0.0134 - within_eps_0_01: 0.0271 - within_eps_0_02: 0.0538 - within_eps_0_05: 0.1307 - within_eps_0_1: 0.2612 - val_log_cosh: 0.0526 - val_loss: 0.0022 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0328 - val_within_eps_0_02: 0.0679 - val_within_eps_0_05: 0.1721 - val_within_eps_0_1: 0.3516\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0385 - loss: 0.0022 - within_eps_0_005: 0.0127 - within_eps_0_01: 0.0276 - within_eps_0_02: 0.0562 - within_eps_0_05: 0.1398 - within_eps_0_1: 0.2765 - val_log_cosh: 0.0723 - val_loss: 0.0028 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0675 - val_within_eps_0_05: 0.1670 - val_within_eps_0_1: 0.2977\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0320 - loss: 0.0020 - within_eps_0_005: 0.0165 - within_eps_0_01: 0.0326 - within_eps_0_02: 0.0627 - within_eps_0_05: 0.1576 - within_eps_0_1: 0.3083 - val_log_cosh: 0.0818 - val_loss: 0.0029 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0362 - val_within_eps_0_02: 0.0709 - val_within_eps_0_05: 0.1784 - val_within_eps_0_1: 0.3042\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0282 - loss: 0.0019 - within_eps_0_005: 0.0174 - within_eps_0_01: 0.0332 - within_eps_0_02: 0.0660 - within_eps_0_05: 0.1668 - within_eps_0_1: 0.3245 - val_log_cosh: 0.0605 - val_loss: 0.0024 - val_within_eps_0_005: 0.0223 - val_within_eps_0_01: 0.0423 - val_within_eps_0_02: 0.0797 - val_within_eps_0_05: 0.1866 - val_within_eps_0_1: 0.3519\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0253 - loss: 0.0018 - within_eps_0_005: 0.0178 - within_eps_0_01: 0.0361 - within_eps_0_02: 0.0719 - within_eps_0_05: 0.1767 - within_eps_0_1: 0.3437 - val_log_cosh: 0.1303 - val_loss: 0.0041 - val_within_eps_0_005: 0.0075 - val_within_eps_0_01: 0.0161 - val_within_eps_0_02: 0.0327 - val_within_eps_0_05: 0.0913 - val_within_eps_0_1: 0.1889\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0264 - loss: 0.0018 - within_eps_0_005: 0.0170 - within_eps_0_01: 0.0340 - within_eps_0_02: 0.0694 - within_eps_0_05: 0.1730 - within_eps_0_1: 0.3392 - val_log_cosh: 0.0910 - val_loss: 0.0032 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1433 - val_within_eps_0_1: 0.2458\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0220 - loss: 0.0016 - within_eps_0_005: 0.0192 - within_eps_0_01: 0.0389 - within_eps_0_02: 0.0758 - within_eps_0_05: 0.1930 - within_eps_0_1: 0.3720 - val_log_cosh: 0.0715 - val_loss: 0.0028 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1431 - val_within_eps_0_1: 0.2746\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0182 - loss: 0.0015 - within_eps_0_005: 0.0212 - within_eps_0_01: 0.0410 - within_eps_0_02: 0.0819 - within_eps_0_05: 0.2038 - within_eps_0_1: 0.4004 - val_log_cosh: 0.0943 - val_loss: 0.0033 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0277 - val_within_eps_0_02: 0.0554 - val_within_eps_0_05: 0.1470 - val_within_eps_0_1: 0.2747\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - log_cosh: 0.0154 - loss: 0.0013 - within_eps_0_005: 0.0233 - within_eps_0_01: 0.0458 - within_eps_0_02: 0.0921 - within_eps_0_05: 0.2287 - within_eps_0_1: 0.4377 - val_log_cosh: 0.0566 - val_loss: 0.0023 - val_within_eps_0_005: 0.0228 - val_within_eps_0_01: 0.0454 - val_within_eps_0_02: 0.0886 - val_within_eps_0_05: 0.2116 - val_within_eps_0_1: 0.3691\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0133 - loss: 0.0012 - within_eps_0_005: 0.0259 - within_eps_0_01: 0.0515 - within_eps_0_02: 0.1014 - within_eps_0_05: 0.2474 - within_eps_0_1: 0.4693 - val_log_cosh: 0.0959 - val_loss: 0.0034 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0549 - val_within_eps_0_05: 0.1311 - val_within_eps_0_1: 0.2393\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0125 - loss: 0.0012 - within_eps_0_005: 0.0266 - within_eps_0_01: 0.0527 - within_eps_0_02: 0.1044 - within_eps_0_05: 0.2565 - within_eps_0_1: 0.4862 - val_log_cosh: 0.0486 - val_loss: 0.0022 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0546 - val_within_eps_0_05: 0.1587 - val_within_eps_0_1: 0.3192\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0096 - loss: 0.0010 - within_eps_0_005: 0.0302 - within_eps_0_01: 0.0584 - within_eps_0_02: 0.1188 - within_eps_0_05: 0.2896 - within_eps_0_1: 0.5418 - val_log_cosh: 0.0639 - val_loss: 0.0026 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0686 - val_within_eps_0_05: 0.1664 - val_within_eps_0_1: 0.3140\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0096 - loss: 0.0010 - within_eps_0_005: 0.0302 - within_eps_0_01: 0.0610 - within_eps_0_02: 0.1205 - within_eps_0_05: 0.2948 - within_eps_0_1: 0.5500 - val_log_cosh: 0.0469 - val_loss: 0.0021 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1520 - val_within_eps_0_1: 0.3158\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0071 - loss: 8.9059e-04 - within_eps_0_005: 0.0346 - within_eps_0_01: 0.0695 - within_eps_0_02: 0.1390 - within_eps_0_05: 0.3375 - within_eps_0_1: 0.6127 - val_log_cosh: 0.0813 - val_loss: 0.0030 - val_within_eps_0_005: 0.0214 - val_within_eps_0_01: 0.0394 - val_within_eps_0_02: 0.0805 - val_within_eps_0_05: 0.1822 - val_within_eps_0_1: 0.3060\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0067 - loss: 8.4186e-04 - within_eps_0_005: 0.0369 - within_eps_0_01: 0.0744 - within_eps_0_02: 0.1485 - within_eps_0_05: 0.3632 - within_eps_0_1: 0.6486 - val_log_cosh: 0.0479 - val_loss: 0.0022 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0584 - val_within_eps_0_05: 0.1542 - val_within_eps_0_1: 0.3415\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0049 - loss: 7.2746e-04 - within_eps_0_005: 0.0417 - within_eps_0_01: 0.0849 - within_eps_0_02: 0.1691 - within_eps_0_05: 0.4027 - within_eps_0_1: 0.7032 - val_log_cosh: 0.1494 - val_loss: 0.0046 - val_within_eps_0_005: 0.0074 - val_within_eps_0_01: 0.0143 - val_within_eps_0_02: 0.0291 - val_within_eps_0_05: 0.0674 - val_within_eps_0_1: 0.1126\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0072 - loss: 8.4511e-04 - within_eps_0_005: 0.0412 - within_eps_0_01: 0.0807 - within_eps_0_02: 0.1583 - within_eps_0_05: 0.3791 - within_eps_0_1: 0.6655 - val_log_cosh: 0.0653 - val_loss: 0.0025 - val_within_eps_0_005: 0.0187 - val_within_eps_0_01: 0.0394 - val_within_eps_0_02: 0.0796 - val_within_eps_0_05: 0.1927 - val_within_eps_0_1: 0.3324\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0037 - loss: 6.2687e-04 - within_eps_0_005: 0.0495 - within_eps_0_01: 0.0983 - within_eps_0_02: 0.1915 - within_eps_0_05: 0.4586 - within_eps_0_1: 0.7705 - val_log_cosh: 0.1022 - val_loss: 0.0034 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0311 - val_within_eps_0_02: 0.0619 - val_within_eps_0_05: 0.1483 - val_within_eps_0_1: 0.2690\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0048 - loss: 6.9155e-04 - within_eps_0_005: 0.0479 - within_eps_0_01: 0.0954 - within_eps_0_02: 0.1887 - within_eps_0_05: 0.4480 - within_eps_0_1: 0.7412 - val_log_cosh: 0.0904 - val_loss: 0.0031 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0357 - val_within_eps_0_02: 0.0707 - val_within_eps_0_05: 0.1731 - val_within_eps_0_1: 0.3064\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0043 - loss: 6.6650e-04 - within_eps_0_005: 0.0494 - within_eps_0_01: 0.0978 - within_eps_0_02: 0.1888 - within_eps_0_05: 0.4481 - within_eps_0_1: 0.7479 - val_log_cosh: 0.0876 - val_loss: 0.0031 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0349 - val_within_eps_0_02: 0.0698 - val_within_eps_0_05: 0.1563 - val_within_eps_0_1: 0.3030\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0037 - loss: 6.0437e-04 - within_eps_0_005: 0.0539 - within_eps_0_01: 0.1077 - within_eps_0_02: 0.2103 - within_eps_0_05: 0.4859 - within_eps_0_1: 0.7905 - val_log_cosh: 0.0850 - val_loss: 0.0031 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0247 - val_within_eps_0_02: 0.0502 - val_within_eps_0_05: 0.1295 - val_within_eps_0_1: 0.2634\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0029 - loss: 5.3560e-04 - within_eps_0_005: 0.0577 - within_eps_0_01: 0.1143 - within_eps_0_02: 0.2273 - within_eps_0_05: 0.5256 - within_eps_0_1: 0.8321 - val_log_cosh: 0.1042 - val_loss: 0.0036 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0221 - val_within_eps_0_02: 0.0443 - val_within_eps_0_05: 0.1169 - val_within_eps_0_1: 0.2203\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0022 - loss: 4.5615e-04 - within_eps_0_005: 0.0682 - within_eps_0_01: 0.1350 - within_eps_0_02: 0.2639 - within_eps_0_05: 0.5913 - within_eps_0_1: 0.8843 - val_log_cosh: 0.1110 - val_loss: 0.0038 - val_within_eps_0_005: 0.0076 - val_within_eps_0_01: 0.0161 - val_within_eps_0_02: 0.0339 - val_within_eps_0_05: 0.0938 - val_within_eps_0_1: 0.1952\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0051 - loss: 6.7815e-04 - within_eps_0_005: 0.0549 - within_eps_0_01: 0.1093 - within_eps_0_02: 0.2157 - within_eps_0_05: 0.4848 - within_eps_0_1: 0.7588 - val_log_cosh: 0.1249 - val_loss: 0.0040 - val_within_eps_0_005: 0.0107 - val_within_eps_0_01: 0.0202 - val_within_eps_0_02: 0.0395 - val_within_eps_0_05: 0.0941 - val_within_eps_0_1: 0.1921\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0036 - loss: 5.9275e-04 - within_eps_0_005: 0.0528 - within_eps_0_01: 0.1064 - within_eps_0_02: 0.2113 - within_eps_0_05: 0.4945 - within_eps_0_1: 0.7955 - val_log_cosh: 0.1026 - val_loss: 0.0035 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0243 - val_within_eps_0_02: 0.0463 - val_within_eps_0_05: 0.1125 - val_within_eps_0_1: 0.2106\n",
      "Epoch 41/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0031 - loss: 5.5427e-04 - within_eps_0_005: 0.0568 - within_eps_0_01: 0.1132 - within_eps_0_02: 0.2234 - within_eps_0_05: 0.5146 - within_eps_0_1: 0.8176 - val_log_cosh: 0.1580 - val_loss: 0.0047 - val_within_eps_0_005: 0.0039 - val_within_eps_0_01: 0.0083 - val_within_eps_0_02: 0.0172 - val_within_eps_0_05: 0.0533 - val_within_eps_0_1: 0.1196\n",
      "Epoch 42/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0054 - loss: 7.1992e-04 - within_eps_0_005: 0.0471 - within_eps_0_01: 0.0953 - within_eps_0_02: 0.1899 - within_eps_0_05: 0.4399 - within_eps_0_1: 0.7303 - val_log_cosh: 0.0759 - val_loss: 0.0028 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0418 - val_within_eps_0_02: 0.0837 - val_within_eps_0_05: 0.1974 - val_within_eps_0_1: 0.3242\n",
      "Epoch 43/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0033 - loss: 5.6983e-04 - within_eps_0_005: 0.0535 - within_eps_0_01: 0.1090 - within_eps_0_02: 0.2172 - within_eps_0_05: 0.5059 - within_eps_0_1: 0.8085 - val_log_cosh: 0.1271 - val_loss: 0.0041 - val_within_eps_0_005: 0.0073 - val_within_eps_0_01: 0.0148 - val_within_eps_0_02: 0.0313 - val_within_eps_0_05: 0.0834 - val_within_eps_0_1: 0.1791\n",
      "  -> min val_log_cosh=0.046861279756 | min val_huber=0.002146322280\n",
      "\n",
      "--- Entrenando δ=0.017357412725687027 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 106ms/step - log_cosh: 0.1946 - loss: 0.0090 - within_eps_0_005: 0.0067 - within_eps_0_01: 0.0134 - within_eps_0_02: 0.0263 - within_eps_0_05: 0.0643 - within_eps_0_1: 0.1296 - val_log_cosh: 0.1147 - val_loss: 0.0061 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0221 - val_within_eps_0_02: 0.0449 - val_within_eps_0_05: 0.1122 - val_within_eps_0_1: 0.2334\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.1112 - loss: 0.0067 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0166 - within_eps_0_02: 0.0328 - within_eps_0_05: 0.0808 - within_eps_0_1: 0.1599 - val_log_cosh: 0.0783 - val_loss: 0.0048 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0278 - val_within_eps_0_02: 0.0555 - val_within_eps_0_05: 0.1431 - val_within_eps_0_1: 0.2842\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - log_cosh: 0.1058 - loss: 0.0065 - within_eps_0_005: 0.0085 - within_eps_0_01: 0.0171 - within_eps_0_02: 0.0351 - within_eps_0_05: 0.0839 - within_eps_0_1: 0.1668 - val_log_cosh: 0.0644 - val_loss: 0.0042 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0315 - val_within_eps_0_02: 0.0668 - val_within_eps_0_05: 0.1776 - val_within_eps_0_1: 0.3345\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.1007 - loss: 0.0063 - within_eps_0_005: 0.0078 - within_eps_0_01: 0.0164 - within_eps_0_02: 0.0348 - within_eps_0_05: 0.0857 - within_eps_0_1: 0.1688 - val_log_cosh: 0.0648 - val_loss: 0.0043 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0651 - val_within_eps_0_05: 0.1723 - val_within_eps_0_1: 0.3175\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - log_cosh: 0.0943 - loss: 0.0061 - within_eps_0_005: 0.0082 - within_eps_0_01: 0.0176 - within_eps_0_02: 0.0345 - within_eps_0_05: 0.0881 - within_eps_0_1: 0.1760 - val_log_cosh: 0.0624 - val_loss: 0.0043 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1416 - val_within_eps_0_1: 0.2993\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0875 - loss: 0.0059 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0180 - within_eps_0_02: 0.0372 - within_eps_0_05: 0.0932 - within_eps_0_1: 0.1844 - val_log_cosh: 0.0638 - val_loss: 0.0042 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0637 - val_within_eps_0_05: 0.1657 - val_within_eps_0_1: 0.3134\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0835 - loss: 0.0057 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0188 - within_eps_0_02: 0.0378 - within_eps_0_05: 0.0947 - within_eps_0_1: 0.1880 - val_log_cosh: 0.0621 - val_loss: 0.0042 - val_within_eps_0_005: 0.0204 - val_within_eps_0_01: 0.0386 - val_within_eps_0_02: 0.0744 - val_within_eps_0_05: 0.1802 - val_within_eps_0_1: 0.3275\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - log_cosh: 0.0781 - loss: 0.0055 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0198 - within_eps_0_02: 0.0393 - within_eps_0_05: 0.0973 - within_eps_0_1: 0.1935 - val_log_cosh: 0.0578 - val_loss: 0.0039 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0408 - val_within_eps_0_02: 0.0831 - val_within_eps_0_05: 0.2060 - val_within_eps_0_1: 0.3614\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0744 - loss: 0.0054 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0212 - within_eps_0_02: 0.0405 - within_eps_0_05: 0.1002 - within_eps_0_1: 0.1995 - val_log_cosh: 0.0597 - val_loss: 0.0041 - val_within_eps_0_005: 0.0200 - val_within_eps_0_01: 0.0391 - val_within_eps_0_02: 0.0777 - val_within_eps_0_05: 0.1815 - val_within_eps_0_1: 0.3454\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - log_cosh: 0.0678 - loss: 0.0051 - within_eps_0_005: 0.0112 - within_eps_0_01: 0.0222 - within_eps_0_02: 0.0432 - within_eps_0_05: 0.1069 - within_eps_0_1: 0.2090 - val_log_cosh: 0.0715 - val_loss: 0.0046 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0404 - val_within_eps_0_02: 0.0748 - val_within_eps_0_05: 0.1742 - val_within_eps_0_1: 0.3187\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - log_cosh: 0.0629 - loss: 0.0049 - within_eps_0_005: 0.0105 - within_eps_0_01: 0.0210 - within_eps_0_02: 0.0429 - within_eps_0_05: 0.1100 - within_eps_0_1: 0.2173 - val_log_cosh: 0.0653 - val_loss: 0.0043 - val_within_eps_0_005: 0.0189 - val_within_eps_0_01: 0.0372 - val_within_eps_0_02: 0.0724 - val_within_eps_0_05: 0.1899 - val_within_eps_0_1: 0.3445\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0572 - loss: 0.0047 - within_eps_0_005: 0.0110 - within_eps_0_01: 0.0232 - within_eps_0_02: 0.0473 - within_eps_0_05: 0.1161 - within_eps_0_1: 0.2279 - val_log_cosh: 0.0648 - val_loss: 0.0042 - val_within_eps_0_005: 0.0223 - val_within_eps_0_01: 0.0417 - val_within_eps_0_02: 0.0814 - val_within_eps_0_05: 0.1979 - val_within_eps_0_1: 0.3440\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0529 - loss: 0.0045 - within_eps_0_005: 0.0121 - within_eps_0_01: 0.0244 - within_eps_0_02: 0.0494 - within_eps_0_05: 0.1215 - within_eps_0_1: 0.2381 - val_log_cosh: 0.0700 - val_loss: 0.0046 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1381 - val_within_eps_0_1: 0.2691\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - log_cosh: 0.0474 - loss: 0.0042 - within_eps_0_005: 0.0125 - within_eps_0_01: 0.0256 - within_eps_0_02: 0.0516 - within_eps_0_05: 0.1296 - within_eps_0_1: 0.2522 - val_log_cosh: 0.0757 - val_loss: 0.0047 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0359 - val_within_eps_0_02: 0.0695 - val_within_eps_0_05: 0.1646 - val_within_eps_0_1: 0.3067\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - log_cosh: 0.0427 - loss: 0.0040 - within_eps_0_005: 0.0138 - within_eps_0_01: 0.0274 - within_eps_0_02: 0.0557 - within_eps_0_05: 0.1364 - within_eps_0_1: 0.2691 - val_log_cosh: 0.0916 - val_loss: 0.0055 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0662 - val_within_eps_0_05: 0.1541 - val_within_eps_0_1: 0.2855\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - log_cosh: 0.0400 - loss: 0.0038 - within_eps_0_005: 0.0140 - within_eps_0_01: 0.0279 - within_eps_0_02: 0.0566 - within_eps_0_05: 0.1374 - within_eps_0_1: 0.2732 - val_log_cosh: 0.0864 - val_loss: 0.0052 - val_within_eps_0_005: 0.0213 - val_within_eps_0_01: 0.0420 - val_within_eps_0_02: 0.0829 - val_within_eps_0_05: 0.1861 - val_within_eps_0_1: 0.3201\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - log_cosh: 0.0357 - loss: 0.0036 - within_eps_0_005: 0.0148 - within_eps_0_01: 0.0299 - within_eps_0_02: 0.0595 - within_eps_0_05: 0.1482 - within_eps_0_1: 0.2943 - val_log_cosh: 0.0819 - val_loss: 0.0051 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0380 - val_within_eps_0_02: 0.0734 - val_within_eps_0_05: 0.1764 - val_within_eps_0_1: 0.3246\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - log_cosh: 0.0326 - loss: 0.0034 - within_eps_0_005: 0.0157 - within_eps_0_01: 0.0310 - within_eps_0_02: 0.0622 - within_eps_0_05: 0.1536 - within_eps_0_1: 0.3028 - val_log_cosh: 0.0921 - val_loss: 0.0054 - val_within_eps_0_005: 0.0187 - val_within_eps_0_01: 0.0358 - val_within_eps_0_02: 0.0753 - val_within_eps_0_05: 0.1868 - val_within_eps_0_1: 0.3245\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - log_cosh: 0.0293 - loss: 0.0032 - within_eps_0_005: 0.0163 - within_eps_0_01: 0.0328 - within_eps_0_02: 0.0659 - within_eps_0_05: 0.1641 - within_eps_0_1: 0.3216 - val_log_cosh: 0.0802 - val_loss: 0.0050 - val_within_eps_0_005: 0.0244 - val_within_eps_0_01: 0.0465 - val_within_eps_0_02: 0.0863 - val_within_eps_0_05: 0.1911 - val_within_eps_0_1: 0.3427\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - log_cosh: 0.0253 - loss: 0.0030 - within_eps_0_005: 0.0172 - within_eps_0_01: 0.0341 - within_eps_0_02: 0.0697 - within_eps_0_05: 0.1756 - within_eps_0_1: 0.3433 - val_log_cosh: 0.1055 - val_loss: 0.0059 - val_within_eps_0_005: 0.0191 - val_within_eps_0_01: 0.0360 - val_within_eps_0_02: 0.0702 - val_within_eps_0_05: 0.1612 - val_within_eps_0_1: 0.2863\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - log_cosh: 0.0232 - loss: 0.0028 - within_eps_0_005: 0.0191 - within_eps_0_01: 0.0376 - within_eps_0_02: 0.0745 - within_eps_0_05: 0.1854 - within_eps_0_1: 0.3603 - val_log_cosh: 0.0884 - val_loss: 0.0053 - val_within_eps_0_005: 0.0199 - val_within_eps_0_01: 0.0393 - val_within_eps_0_02: 0.0776 - val_within_eps_0_05: 0.1861 - val_within_eps_0_1: 0.3242\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0198 - loss: 0.0026 - within_eps_0_005: 0.0193 - within_eps_0_01: 0.0391 - within_eps_0_02: 0.0785 - within_eps_0_05: 0.1991 - within_eps_0_1: 0.3871 - val_log_cosh: 0.0864 - val_loss: 0.0052 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0584 - val_within_eps_0_05: 0.1421 - val_within_eps_0_1: 0.2611\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0177 - loss: 0.0025 - within_eps_0_005: 0.0205 - within_eps_0_01: 0.0423 - within_eps_0_02: 0.0854 - within_eps_0_05: 0.2159 - within_eps_0_1: 0.4151 - val_log_cosh: 0.1153 - val_loss: 0.0063 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0347 - val_within_eps_0_02: 0.0702 - val_within_eps_0_05: 0.1679 - val_within_eps_0_1: 0.2904\n",
      "  -> min val_log_cosh=0.057848032564 | min val_huber=0.003941430710\n",
      "\n",
      "--- Entrenando δ=0.02 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 129ms/step - log_cosh: 0.1887 - loss: 0.0102 - within_eps_0_005: 0.0071 - within_eps_0_01: 0.0141 - within_eps_0_02: 0.0270 - within_eps_0_05: 0.0652 - within_eps_0_1: 0.1284 - val_log_cosh: 0.0831 - val_loss: 0.0060 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0250 - val_within_eps_0_02: 0.0502 - val_within_eps_0_05: 0.1153 - val_within_eps_0_1: 0.2348\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - log_cosh: 0.1123 - loss: 0.0077 - within_eps_0_005: 0.0072 - within_eps_0_01: 0.0151 - within_eps_0_02: 0.0310 - within_eps_0_05: 0.0795 - within_eps_0_1: 0.1582 - val_log_cosh: 0.0726 - val_loss: 0.0053 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0353 - val_within_eps_0_02: 0.0710 - val_within_eps_0_05: 0.1587 - val_within_eps_0_1: 0.2959\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.1030 - loss: 0.0074 - within_eps_0_005: 0.0085 - within_eps_0_01: 0.0176 - within_eps_0_02: 0.0342 - within_eps_0_05: 0.0855 - within_eps_0_1: 0.1683 - val_log_cosh: 0.0611 - val_loss: 0.0047 - val_within_eps_0_005: 0.0166 - val_within_eps_0_01: 0.0345 - val_within_eps_0_02: 0.0702 - val_within_eps_0_05: 0.1764 - val_within_eps_0_1: 0.3217\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - log_cosh: 0.0995 - loss: 0.0073 - within_eps_0_005: 0.0083 - within_eps_0_01: 0.0169 - within_eps_0_02: 0.0341 - within_eps_0_05: 0.0850 - within_eps_0_1: 0.1676 - val_log_cosh: 0.0587 - val_loss: 0.0047 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0344 - val_within_eps_0_02: 0.0694 - val_within_eps_0_05: 0.1620 - val_within_eps_0_1: 0.3035\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - log_cosh: 0.0943 - loss: 0.0070 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0185 - within_eps_0_02: 0.0358 - within_eps_0_05: 0.0889 - within_eps_0_1: 0.1759 - val_log_cosh: 0.0555 - val_loss: 0.0045 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0650 - val_within_eps_0_05: 0.1660 - val_within_eps_0_1: 0.3317\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.0899 - loss: 0.0069 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0180 - within_eps_0_02: 0.0370 - within_eps_0_05: 0.0901 - within_eps_0_1: 0.1794 - val_log_cosh: 0.0588 - val_loss: 0.0048 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0321 - val_within_eps_0_02: 0.0668 - val_within_eps_0_05: 0.1565 - val_within_eps_0_1: 0.3104\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - log_cosh: 0.0839 - loss: 0.0066 - within_eps_0_005: 0.0094 - within_eps_0_01: 0.0192 - within_eps_0_02: 0.0382 - within_eps_0_05: 0.0952 - within_eps_0_1: 0.1868 - val_log_cosh: 0.0605 - val_loss: 0.0048 - val_within_eps_0_005: 0.0217 - val_within_eps_0_01: 0.0420 - val_within_eps_0_02: 0.0825 - val_within_eps_0_05: 0.1837 - val_within_eps_0_1: 0.3269\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - log_cosh: 0.0811 - loss: 0.0065 - within_eps_0_005: 0.0097 - within_eps_0_01: 0.0192 - within_eps_0_02: 0.0391 - within_eps_0_05: 0.0965 - within_eps_0_1: 0.1911 - val_log_cosh: 0.0718 - val_loss: 0.0055 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0549 - val_within_eps_0_05: 0.1306 - val_within_eps_0_1: 0.2684\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - log_cosh: 0.0753 - loss: 0.0062 - within_eps_0_005: 0.0094 - within_eps_0_01: 0.0203 - within_eps_0_02: 0.0396 - within_eps_0_05: 0.1007 - within_eps_0_1: 0.2007 - val_log_cosh: 0.0830 - val_loss: 0.0061 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0483 - val_within_eps_0_05: 0.1180 - val_within_eps_0_1: 0.2283\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.0720 - loss: 0.0061 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0198 - within_eps_0_02: 0.0401 - within_eps_0_05: 0.1014 - within_eps_0_1: 0.2029 - val_log_cosh: 0.0894 - val_loss: 0.0061 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0636 - val_within_eps_0_05: 0.1509 - val_within_eps_0_1: 0.2825\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.0710 - loss: 0.0060 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0209 - within_eps_0_02: 0.0419 - within_eps_0_05: 0.1041 - within_eps_0_1: 0.2039 - val_log_cosh: 0.0563 - val_loss: 0.0046 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0569 - val_within_eps_0_05: 0.1553 - val_within_eps_0_1: 0.3164\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - log_cosh: 0.0717 - loss: 0.0060 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0187 - within_eps_0_02: 0.0383 - within_eps_0_05: 0.1022 - within_eps_0_1: 0.2039 - val_log_cosh: 0.1338 - val_loss: 0.0080 - val_within_eps_0_005: 0.0091 - val_within_eps_0_01: 0.0173 - val_within_eps_0_02: 0.0368 - val_within_eps_0_05: 0.0967 - val_within_eps_0_1: 0.1987\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - log_cosh: 0.0790 - loss: 0.0064 - within_eps_0_005: 0.0100 - within_eps_0_01: 0.0203 - within_eps_0_02: 0.0396 - within_eps_0_05: 0.0977 - within_eps_0_1: 0.1930 - val_log_cosh: 0.0695 - val_loss: 0.0056 - val_within_eps_0_005: 0.0108 - val_within_eps_0_01: 0.0205 - val_within_eps_0_02: 0.0434 - val_within_eps_0_05: 0.1164 - val_within_eps_0_1: 0.2343\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - log_cosh: 0.0648 - loss: 0.0057 - within_eps_0_005: 0.0112 - within_eps_0_01: 0.0227 - within_eps_0_02: 0.0435 - within_eps_0_05: 0.1070 - within_eps_0_1: 0.2129 - val_log_cosh: 0.0682 - val_loss: 0.0053 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0580 - val_within_eps_0_05: 0.1384 - val_within_eps_0_1: 0.2630\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - log_cosh: 0.0546 - loss: 0.0052 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0241 - within_eps_0_02: 0.0473 - within_eps_0_05: 0.1214 - within_eps_0_1: 0.2367 - val_log_cosh: 0.1248 - val_loss: 0.0079 - val_within_eps_0_005: 0.0065 - val_within_eps_0_01: 0.0131 - val_within_eps_0_02: 0.0267 - val_within_eps_0_05: 0.0695 - val_within_eps_0_1: 0.1652\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - log_cosh: 0.0519 - loss: 0.0050 - within_eps_0_005: 0.0119 - within_eps_0_01: 0.0237 - within_eps_0_02: 0.0484 - within_eps_0_05: 0.1229 - within_eps_0_1: 0.2424 - val_log_cosh: 0.0596 - val_loss: 0.0048 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0255 - val_within_eps_0_02: 0.0526 - val_within_eps_0_05: 0.1456 - val_within_eps_0_1: 0.2917\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - log_cosh: 0.0438 - loss: 0.0046 - within_eps_0_005: 0.0130 - within_eps_0_01: 0.0259 - within_eps_0_02: 0.0531 - within_eps_0_05: 0.1342 - within_eps_0_1: 0.2624 - val_log_cosh: 0.0583 - val_loss: 0.0046 - val_within_eps_0_005: 0.0202 - val_within_eps_0_01: 0.0399 - val_within_eps_0_02: 0.0748 - val_within_eps_0_05: 0.1790 - val_within_eps_0_1: 0.3318\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.0377 - loss: 0.0042 - within_eps_0_005: 0.0153 - within_eps_0_01: 0.0294 - within_eps_0_02: 0.0583 - within_eps_0_05: 0.1468 - within_eps_0_1: 0.2883 - val_log_cosh: 0.0655 - val_loss: 0.0050 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0391 - val_within_eps_0_02: 0.0758 - val_within_eps_0_05: 0.1772 - val_within_eps_0_1: 0.3132\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.0330 - loss: 0.0040 - within_eps_0_005: 0.0162 - within_eps_0_01: 0.0316 - within_eps_0_02: 0.0621 - within_eps_0_05: 0.1536 - within_eps_0_1: 0.3019 - val_log_cosh: 0.0796 - val_loss: 0.0056 - val_within_eps_0_005: 0.0172 - val_within_eps_0_01: 0.0338 - val_within_eps_0_02: 0.0702 - val_within_eps_0_05: 0.1832 - val_within_eps_0_1: 0.3188\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - log_cosh: 0.0299 - loss: 0.0037 - within_eps_0_005: 0.0164 - within_eps_0_01: 0.0325 - within_eps_0_02: 0.0651 - within_eps_0_05: 0.1644 - within_eps_0_1: 0.3189 - val_log_cosh: 0.0742 - val_loss: 0.0053 - val_within_eps_0_005: 0.0167 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0628 - val_within_eps_0_05: 0.1608 - val_within_eps_0_1: 0.2926\n",
      "  -> min val_log_cosh=0.055525932461 | min val_huber=0.004493620247\n",
      "\n",
      "--- Entrenando δ=0.03049677610397339 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 142ms/step - log_cosh: 0.1937 - loss: 0.0156 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0132 - within_eps_0_02: 0.0266 - within_eps_0_05: 0.0655 - within_eps_0_1: 0.1314 - val_log_cosh: 0.1041 - val_loss: 0.0103 - val_within_eps_0_005: 0.0109 - val_within_eps_0_01: 0.0223 - val_within_eps_0_02: 0.0435 - val_within_eps_0_05: 0.1039 - val_within_eps_0_1: 0.2117\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - log_cosh: 0.1125 - loss: 0.0117 - within_eps_0_005: 0.0078 - within_eps_0_01: 0.0162 - within_eps_0_02: 0.0326 - within_eps_0_05: 0.0807 - within_eps_0_1: 0.1602 - val_log_cosh: 0.0877 - val_loss: 0.0092 - val_within_eps_0_005: 0.0085 - val_within_eps_0_01: 0.0168 - val_within_eps_0_02: 0.0357 - val_within_eps_0_05: 0.0976 - val_within_eps_0_1: 0.2098\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.1099 - loss: 0.0115 - within_eps_0_005: 0.0081 - within_eps_0_01: 0.0164 - within_eps_0_02: 0.0325 - within_eps_0_05: 0.0814 - within_eps_0_1: 0.1596 - val_log_cosh: 0.0718 - val_loss: 0.0081 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0241 - val_within_eps_0_02: 0.0454 - val_within_eps_0_05: 0.1135 - val_within_eps_0_1: 0.2461\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - log_cosh: 0.1044 - loss: 0.0112 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0171 - within_eps_0_02: 0.0345 - within_eps_0_05: 0.0846 - within_eps_0_1: 0.1689 - val_log_cosh: 0.0651 - val_loss: 0.0073 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1608 - val_within_eps_0_1: 0.3412\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.1015 - loss: 0.0110 - within_eps_0_005: 0.0092 - within_eps_0_01: 0.0174 - within_eps_0_02: 0.0341 - within_eps_0_05: 0.0870 - within_eps_0_1: 0.1703 - val_log_cosh: 0.0565 - val_loss: 0.0067 - val_within_eps_0_005: 0.0198 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0755 - val_within_eps_0_05: 0.1762 - val_within_eps_0_1: 0.3472\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - log_cosh: 0.0951 - loss: 0.0106 - within_eps_0_005: 0.0084 - within_eps_0_01: 0.0169 - within_eps_0_02: 0.0335 - within_eps_0_05: 0.0867 - within_eps_0_1: 0.1744 - val_log_cosh: 0.0686 - val_loss: 0.0078 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0266 - val_within_eps_0_02: 0.0506 - val_within_eps_0_05: 0.1293 - val_within_eps_0_1: 0.2604\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.0890 - loss: 0.0102 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0176 - within_eps_0_02: 0.0359 - within_eps_0_05: 0.0891 - within_eps_0_1: 0.1778 - val_log_cosh: 0.0598 - val_loss: 0.0073 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0505 - val_within_eps_0_05: 0.1282 - val_within_eps_0_1: 0.2679\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - log_cosh: 0.0855 - loss: 0.0100 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0183 - within_eps_0_02: 0.0375 - within_eps_0_05: 0.0938 - within_eps_0_1: 0.1869 - val_log_cosh: 0.0636 - val_loss: 0.0075 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0539 - val_within_eps_0_05: 0.1396 - val_within_eps_0_1: 0.2844\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - log_cosh: 0.0777 - loss: 0.0095 - within_eps_0_005: 0.0095 - within_eps_0_01: 0.0192 - within_eps_0_02: 0.0391 - within_eps_0_05: 0.0981 - within_eps_0_1: 0.1946 - val_log_cosh: 0.0750 - val_loss: 0.0081 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0359 - val_within_eps_0_02: 0.0669 - val_within_eps_0_05: 0.1637 - val_within_eps_0_1: 0.3108\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - log_cosh: 0.0728 - loss: 0.0091 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0205 - within_eps_0_02: 0.0415 - within_eps_0_05: 0.1040 - within_eps_0_1: 0.2047 - val_log_cosh: 0.0714 - val_loss: 0.0078 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0334 - val_within_eps_0_02: 0.0659 - val_within_eps_0_05: 0.1602 - val_within_eps_0_1: 0.3002\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - log_cosh: 0.0674 - loss: 0.0087 - within_eps_0_005: 0.0105 - within_eps_0_01: 0.0215 - within_eps_0_02: 0.0435 - within_eps_0_05: 0.1065 - within_eps_0_1: 0.2099 - val_log_cosh: 0.0803 - val_loss: 0.0085 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0345 - val_within_eps_0_02: 0.0708 - val_within_eps_0_05: 0.1772 - val_within_eps_0_1: 0.3162\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - log_cosh: 0.0627 - loss: 0.0084 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0222 - within_eps_0_02: 0.0437 - within_eps_0_05: 0.1097 - within_eps_0_1: 0.2168 - val_log_cosh: 0.0656 - val_loss: 0.0075 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1642 - val_within_eps_0_1: 0.3138\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - log_cosh: 0.0605 - loss: 0.0082 - within_eps_0_005: 0.0109 - within_eps_0_01: 0.0224 - within_eps_0_02: 0.0441 - within_eps_0_05: 0.1106 - within_eps_0_1: 0.2216 - val_log_cosh: 0.0832 - val_loss: 0.0088 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0259 - val_within_eps_0_02: 0.0498 - val_within_eps_0_05: 0.1334 - val_within_eps_0_1: 0.2596\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - log_cosh: 0.0534 - loss: 0.0077 - within_eps_0_005: 0.0110 - within_eps_0_01: 0.0229 - within_eps_0_02: 0.0477 - within_eps_0_05: 0.1177 - within_eps_0_1: 0.2343 - val_log_cosh: 0.1004 - val_loss: 0.0102 - val_within_eps_0_005: 0.0099 - val_within_eps_0_01: 0.0204 - val_within_eps_0_02: 0.0437 - val_within_eps_0_05: 0.1155 - val_within_eps_0_1: 0.2421\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - log_cosh: 0.0502 - loss: 0.0074 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0256 - within_eps_0_02: 0.0510 - within_eps_0_05: 0.1252 - within_eps_0_1: 0.2438 - val_log_cosh: 0.1061 - val_loss: 0.0104 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0539 - val_within_eps_0_05: 0.1233 - val_within_eps_0_1: 0.2249\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - log_cosh: 0.0712 - loss: 0.0090 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0201 - within_eps_0_02: 0.0407 - within_eps_0_05: 0.1009 - within_eps_0_1: 0.2030 - val_log_cosh: 0.0849 - val_loss: 0.0090 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0253 - val_within_eps_0_02: 0.0542 - val_within_eps_0_05: 0.1320 - val_within_eps_0_1: 0.2436\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - log_cosh: 0.0454 - loss: 0.0070 - within_eps_0_005: 0.0137 - within_eps_0_01: 0.0269 - within_eps_0_02: 0.0533 - within_eps_0_05: 0.1313 - within_eps_0_1: 0.2590 - val_log_cosh: 0.0633 - val_loss: 0.0073 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0601 - val_within_eps_0_05: 0.1564 - val_within_eps_0_1: 0.3216\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - log_cosh: 0.0402 - loss: 0.0065 - within_eps_0_005: 0.0143 - within_eps_0_01: 0.0280 - within_eps_0_02: 0.0555 - within_eps_0_05: 0.1399 - within_eps_0_1: 0.2769 - val_log_cosh: 0.0673 - val_loss: 0.0076 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0597 - val_within_eps_0_05: 0.1569 - val_within_eps_0_1: 0.3113\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - log_cosh: 0.0350 - loss: 0.0061 - within_eps_0_005: 0.0159 - within_eps_0_01: 0.0313 - within_eps_0_02: 0.0618 - within_eps_0_05: 0.1533 - within_eps_0_1: 0.2971 - val_log_cosh: 0.0744 - val_loss: 0.0080 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0639 - val_within_eps_0_05: 0.1639 - val_within_eps_0_1: 0.3174\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - log_cosh: 0.0293 - loss: 0.0055 - within_eps_0_005: 0.0171 - within_eps_0_01: 0.0332 - within_eps_0_02: 0.0676 - within_eps_0_05: 0.1655 - within_eps_0_1: 0.3214 - val_log_cosh: 0.1051 - val_loss: 0.0104 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0543 - val_within_eps_0_05: 0.1219 - val_within_eps_0_1: 0.2487\n",
      "  -> min val_log_cosh=0.056463178247 | min val_huber=0.006652056705\n",
      "\n",
      "--- Entrenando δ=0.04116208553314208 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 142ms/step - log_cosh: 0.1779 - loss: 0.0200 - within_eps_0_005: 0.0069 - within_eps_0_01: 0.0137 - within_eps_0_02: 0.0275 - within_eps_0_05: 0.0669 - within_eps_0_1: 0.1326 - val_log_cosh: 0.0665 - val_loss: 0.0102 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0340 - val_within_eps_0_02: 0.0654 - val_within_eps_0_05: 0.1610 - val_within_eps_0_1: 0.3117\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.1118 - loss: 0.0155 - within_eps_0_005: 0.0080 - within_eps_0_01: 0.0161 - within_eps_0_02: 0.0320 - within_eps_0_05: 0.0819 - within_eps_0_1: 0.1626 - val_log_cosh: 0.0685 - val_loss: 0.0106 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0247 - val_within_eps_0_02: 0.0503 - val_within_eps_0_05: 0.1247 - val_within_eps_0_1: 0.2480\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.1044 - loss: 0.0149 - within_eps_0_005: 0.0087 - within_eps_0_01: 0.0175 - within_eps_0_02: 0.0344 - within_eps_0_05: 0.0837 - within_eps_0_1: 0.1656 - val_log_cosh: 0.0584 - val_loss: 0.0094 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1583 - val_within_eps_0_1: 0.3181\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - log_cosh: 0.1002 - loss: 0.0145 - within_eps_0_005: 0.0085 - within_eps_0_01: 0.0182 - within_eps_0_02: 0.0353 - within_eps_0_05: 0.0858 - within_eps_0_1: 0.1707 - val_log_cosh: 0.0486 - val_loss: 0.0084 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0352 - val_within_eps_0_02: 0.0672 - val_within_eps_0_05: 0.1632 - val_within_eps_0_1: 0.3053\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.0956 - loss: 0.0142 - within_eps_0_005: 0.0094 - within_eps_0_01: 0.0176 - within_eps_0_02: 0.0352 - within_eps_0_05: 0.0890 - within_eps_0_1: 0.1714 - val_log_cosh: 0.0474 - val_loss: 0.0085 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0342 - val_within_eps_0_02: 0.0650 - val_within_eps_0_05: 0.1567 - val_within_eps_0_1: 0.3048\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.0905 - loss: 0.0137 - within_eps_0_005: 0.0100 - within_eps_0_01: 0.0193 - within_eps_0_02: 0.0371 - within_eps_0_05: 0.0918 - within_eps_0_1: 0.1791 - val_log_cosh: 0.0546 - val_loss: 0.0088 - val_within_eps_0_005: 0.0190 - val_within_eps_0_01: 0.0372 - val_within_eps_0_02: 0.0757 - val_within_eps_0_05: 0.1807 - val_within_eps_0_1: 0.3298\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0842 - loss: 0.0132 - within_eps_0_005: 0.0092 - within_eps_0_01: 0.0191 - within_eps_0_02: 0.0388 - within_eps_0_05: 0.0943 - within_eps_0_1: 0.1861 - val_log_cosh: 0.0487 - val_loss: 0.0084 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0629 - val_within_eps_0_05: 0.1578 - val_within_eps_0_1: 0.3230\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - log_cosh: 0.0780 - loss: 0.0126 - within_eps_0_005: 0.0097 - within_eps_0_01: 0.0192 - within_eps_0_02: 0.0375 - within_eps_0_05: 0.0957 - within_eps_0_1: 0.1927 - val_log_cosh: 0.0523 - val_loss: 0.0087 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1514 - val_within_eps_0_1: 0.3116\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - log_cosh: 0.0710 - loss: 0.0120 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0203 - within_eps_0_02: 0.0416 - within_eps_0_05: 0.1024 - within_eps_0_1: 0.2036 - val_log_cosh: 0.0465 - val_loss: 0.0082 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0338 - val_within_eps_0_02: 0.0679 - val_within_eps_0_05: 0.1646 - val_within_eps_0_1: 0.3206\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0661 - loss: 0.0115 - within_eps_0_005: 0.0103 - within_eps_0_01: 0.0206 - within_eps_0_02: 0.0420 - within_eps_0_05: 0.1071 - within_eps_0_1: 0.2138 - val_log_cosh: 0.0487 - val_loss: 0.0081 - val_within_eps_0_005: 0.0197 - val_within_eps_0_01: 0.0395 - val_within_eps_0_02: 0.0823 - val_within_eps_0_05: 0.2019 - val_within_eps_0_1: 0.3777\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - log_cosh: 0.0596 - loss: 0.0108 - within_eps_0_005: 0.0115 - within_eps_0_01: 0.0227 - within_eps_0_02: 0.0454 - within_eps_0_05: 0.1131 - within_eps_0_1: 0.2228 - val_log_cosh: 0.0622 - val_loss: 0.0096 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0327 - val_within_eps_0_02: 0.0664 - val_within_eps_0_05: 0.1719 - val_within_eps_0_1: 0.3393\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0566 - loss: 0.0105 - within_eps_0_005: 0.0117 - within_eps_0_01: 0.0231 - within_eps_0_02: 0.0462 - within_eps_0_05: 0.1159 - within_eps_0_1: 0.2294 - val_log_cosh: 0.0659 - val_loss: 0.0101 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0652 - val_within_eps_0_05: 0.1611 - val_within_eps_0_1: 0.3027\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0524 - loss: 0.0100 - within_eps_0_005: 0.0127 - within_eps_0_01: 0.0258 - within_eps_0_02: 0.0494 - within_eps_0_05: 0.1215 - within_eps_0_1: 0.2407 - val_log_cosh: 0.0651 - val_loss: 0.0100 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0577 - val_within_eps_0_05: 0.1486 - val_within_eps_0_1: 0.3106\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0488 - loss: 0.0097 - within_eps_0_005: 0.0136 - within_eps_0_01: 0.0256 - within_eps_0_02: 0.0520 - within_eps_0_05: 0.1247 - within_eps_0_1: 0.2486 - val_log_cosh: 0.0832 - val_loss: 0.0118 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0246 - val_within_eps_0_02: 0.0493 - val_within_eps_0_05: 0.1254 - val_within_eps_0_1: 0.2676\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0449 - loss: 0.0092 - within_eps_0_005: 0.0144 - within_eps_0_01: 0.0286 - within_eps_0_02: 0.0549 - within_eps_0_05: 0.1325 - within_eps_0_1: 0.2588 - val_log_cosh: 0.0730 - val_loss: 0.0107 - val_within_eps_0_005: 0.0192 - val_within_eps_0_01: 0.0374 - val_within_eps_0_02: 0.0680 - val_within_eps_0_05: 0.1646 - val_within_eps_0_1: 0.3182\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0396 - loss: 0.0086 - within_eps_0_005: 0.0144 - within_eps_0_01: 0.0284 - within_eps_0_02: 0.0571 - within_eps_0_05: 0.1397 - within_eps_0_1: 0.2772 - val_log_cosh: 0.0798 - val_loss: 0.0114 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0629 - val_within_eps_0_05: 0.1592 - val_within_eps_0_1: 0.3070\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0348 - loss: 0.0080 - within_eps_0_005: 0.0161 - within_eps_0_01: 0.0296 - within_eps_0_02: 0.0597 - within_eps_0_05: 0.1477 - within_eps_0_1: 0.2908 - val_log_cosh: 0.0895 - val_loss: 0.0120 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0387 - val_within_eps_0_02: 0.0756 - val_within_eps_0_05: 0.1841 - val_within_eps_0_1: 0.3239\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0315 - loss: 0.0075 - within_eps_0_005: 0.0161 - within_eps_0_01: 0.0317 - within_eps_0_02: 0.0632 - within_eps_0_05: 0.1589 - within_eps_0_1: 0.3075 - val_log_cosh: 0.0877 - val_loss: 0.0119 - val_within_eps_0_005: 0.0191 - val_within_eps_0_01: 0.0373 - val_within_eps_0_02: 0.0735 - val_within_eps_0_05: 0.1883 - val_within_eps_0_1: 0.3423\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0279 - loss: 0.0070 - within_eps_0_005: 0.0176 - within_eps_0_01: 0.0346 - within_eps_0_02: 0.0690 - within_eps_0_05: 0.1692 - within_eps_0_1: 0.3321 - val_log_cosh: 0.0523 - val_loss: 0.0086 - val_within_eps_0_005: 0.0191 - val_within_eps_0_01: 0.0375 - val_within_eps_0_02: 0.0748 - val_within_eps_0_05: 0.1958 - val_within_eps_0_1: 0.3613\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0250 - loss: 0.0066 - within_eps_0_005: 0.0181 - within_eps_0_01: 0.0358 - within_eps_0_02: 0.0720 - within_eps_0_05: 0.1780 - within_eps_0_1: 0.3490 - val_log_cosh: 0.1017 - val_loss: 0.0134 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0325 - val_within_eps_0_02: 0.0637 - val_within_eps_0_05: 0.1573 - val_within_eps_0_1: 0.2996\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0222 - loss: 0.0062 - within_eps_0_005: 0.0185 - within_eps_0_01: 0.0369 - within_eps_0_02: 0.0740 - within_eps_0_05: 0.1873 - within_eps_0_1: 0.3662 - val_log_cosh: 0.0787 - val_loss: 0.0112 - val_within_eps_0_005: 0.0177 - val_within_eps_0_01: 0.0345 - val_within_eps_0_02: 0.0662 - val_within_eps_0_05: 0.1559 - val_within_eps_0_1: 0.3046\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0193 - loss: 0.0057 - within_eps_0_005: 0.0210 - within_eps_0_01: 0.0412 - within_eps_0_02: 0.0830 - within_eps_0_05: 0.2049 - within_eps_0_1: 0.3954 - val_log_cosh: 0.0712 - val_loss: 0.0107 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0561 - val_within_eps_0_05: 0.1321 - val_within_eps_0_1: 0.2643\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0161 - loss: 0.0051 - within_eps_0_005: 0.0224 - within_eps_0_01: 0.0456 - within_eps_0_02: 0.0906 - within_eps_0_05: 0.2236 - within_eps_0_1: 0.4277 - val_log_cosh: 0.0718 - val_loss: 0.0106 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0376 - val_within_eps_0_02: 0.0727 - val_within_eps_0_05: 0.1769 - val_within_eps_0_1: 0.3242\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0136 - loss: 0.0046 - within_eps_0_005: 0.0246 - within_eps_0_01: 0.0486 - within_eps_0_02: 0.0964 - within_eps_0_05: 0.2406 - within_eps_0_1: 0.4567 - val_log_cosh: 0.0974 - val_loss: 0.0136 - val_within_eps_0_005: 0.0092 - val_within_eps_0_01: 0.0194 - val_within_eps_0_02: 0.0406 - val_within_eps_0_05: 0.1131 - val_within_eps_0_1: 0.2111\n",
      "  -> min val_log_cosh=0.046458147466 | min val_huber=0.008098780178\n",
      "\n",
      "--- Entrenando δ=0.05 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 120ms/step - log_cosh: 0.1875 - loss: 0.0247 - within_eps_0_005: 0.0068 - within_eps_0_01: 0.0134 - within_eps_0_02: 0.0267 - within_eps_0_05: 0.0671 - within_eps_0_1: 0.1311 - val_log_cosh: 0.1010 - val_loss: 0.0164 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0510 - val_within_eps_0_05: 0.1090 - val_within_eps_0_1: 0.1921\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.1097 - loss: 0.0184 - within_eps_0_005: 0.0078 - within_eps_0_01: 0.0163 - within_eps_0_02: 0.0325 - within_eps_0_05: 0.0806 - within_eps_0_1: 0.1607 - val_log_cosh: 0.0727 - val_loss: 0.0128 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1448 - val_within_eps_0_1: 0.2900\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.1079 - loss: 0.0182 - within_eps_0_005: 0.0085 - within_eps_0_01: 0.0170 - within_eps_0_02: 0.0335 - within_eps_0_05: 0.0846 - within_eps_0_1: 0.1648 - val_log_cosh: 0.0671 - val_loss: 0.0125 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0273 - val_within_eps_0_02: 0.0526 - val_within_eps_0_05: 0.1317 - val_within_eps_0_1: 0.2616\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.1033 - loss: 0.0177 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0175 - within_eps_0_02: 0.0344 - within_eps_0_05: 0.0854 - within_eps_0_1: 0.1695 - val_log_cosh: 0.0601 - val_loss: 0.0112 - val_within_eps_0_005: 0.0184 - val_within_eps_0_01: 0.0341 - val_within_eps_0_02: 0.0686 - val_within_eps_0_05: 0.1727 - val_within_eps_0_1: 0.3201\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0978 - loss: 0.0172 - within_eps_0_005: 0.0087 - within_eps_0_01: 0.0177 - within_eps_0_02: 0.0354 - within_eps_0_05: 0.0880 - within_eps_0_1: 0.1742 - val_log_cosh: 0.0623 - val_loss: 0.0118 - val_within_eps_0_005: 0.0098 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0449 - val_within_eps_0_05: 0.1227 - val_within_eps_0_1: 0.2802\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0940 - loss: 0.0168 - within_eps_0_005: 0.0087 - within_eps_0_01: 0.0182 - within_eps_0_02: 0.0363 - within_eps_0_05: 0.0890 - within_eps_0_1: 0.1776 - val_log_cosh: 0.0674 - val_loss: 0.0122 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0579 - val_within_eps_0_05: 0.1485 - val_within_eps_0_1: 0.2935\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0862 - loss: 0.0160 - within_eps_0_005: 0.0100 - within_eps_0_01: 0.0184 - within_eps_0_02: 0.0371 - within_eps_0_05: 0.0927 - within_eps_0_1: 0.1833 - val_log_cosh: 0.0686 - val_loss: 0.0123 - val_within_eps_0_005: 0.0160 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0699 - val_within_eps_0_05: 0.1704 - val_within_eps_0_1: 0.2964\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0821 - loss: 0.0156 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0187 - within_eps_0_02: 0.0379 - within_eps_0_05: 0.0945 - within_eps_0_1: 0.1872 - val_log_cosh: 0.0790 - val_loss: 0.0136 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1383 - val_within_eps_0_1: 0.2703\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - log_cosh: 0.0779 - loss: 0.0151 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0204 - within_eps_0_02: 0.0405 - within_eps_0_05: 0.0997 - within_eps_0_1: 0.1940 - val_log_cosh: 0.0826 - val_loss: 0.0138 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0569 - val_within_eps_0_05: 0.1526 - val_within_eps_0_1: 0.2976\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0730 - loss: 0.0145 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0199 - within_eps_0_02: 0.0388 - within_eps_0_05: 0.1003 - within_eps_0_1: 0.2009 - val_log_cosh: 0.0744 - val_loss: 0.0129 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0322 - val_within_eps_0_02: 0.0647 - val_within_eps_0_05: 0.1666 - val_within_eps_0_1: 0.3116\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - log_cosh: 0.0678 - loss: 0.0139 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0204 - within_eps_0_02: 0.0424 - within_eps_0_05: 0.1073 - within_eps_0_1: 0.2101 - val_log_cosh: 0.0721 - val_loss: 0.0128 - val_within_eps_0_005: 0.0118 - val_within_eps_0_01: 0.0231 - val_within_eps_0_02: 0.0465 - val_within_eps_0_05: 0.1266 - val_within_eps_0_1: 0.2791\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - log_cosh: 0.0616 - loss: 0.0132 - within_eps_0_005: 0.0110 - within_eps_0_01: 0.0219 - within_eps_0_02: 0.0432 - within_eps_0_05: 0.1097 - within_eps_0_1: 0.2187 - val_log_cosh: 0.0988 - val_loss: 0.0159 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0227 - val_within_eps_0_02: 0.0458 - val_within_eps_0_05: 0.1188 - val_within_eps_0_1: 0.2369\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - log_cosh: 0.0628 - loss: 0.0133 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0214 - within_eps_0_02: 0.0440 - within_eps_0_05: 0.1114 - within_eps_0_1: 0.2168 - val_log_cosh: 0.0546 - val_loss: 0.0106 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1536 - val_within_eps_0_1: 0.3014\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0557 - loss: 0.0124 - within_eps_0_005: 0.0119 - within_eps_0_01: 0.0232 - within_eps_0_02: 0.0459 - within_eps_0_05: 0.1164 - within_eps_0_1: 0.2307 - val_log_cosh: 0.0600 - val_loss: 0.0114 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0257 - val_within_eps_0_02: 0.0510 - val_within_eps_0_05: 0.1441 - val_within_eps_0_1: 0.3050\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - log_cosh: 0.0560 - loss: 0.0124 - within_eps_0_005: 0.0113 - within_eps_0_01: 0.0231 - within_eps_0_02: 0.0464 - within_eps_0_05: 0.1179 - within_eps_0_1: 0.2329 - val_log_cosh: 0.0595 - val_loss: 0.0112 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0394 - val_within_eps_0_02: 0.0763 - val_within_eps_0_05: 0.1823 - val_within_eps_0_1: 0.3341\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0480 - loss: 0.0114 - within_eps_0_005: 0.0134 - within_eps_0_01: 0.0264 - within_eps_0_02: 0.0529 - within_eps_0_05: 0.1288 - within_eps_0_1: 0.2520 - val_log_cosh: 0.0580 - val_loss: 0.0109 - val_within_eps_0_005: 0.0203 - val_within_eps_0_01: 0.0403 - val_within_eps_0_02: 0.0739 - val_within_eps_0_05: 0.1754 - val_within_eps_0_1: 0.3450\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0429 - loss: 0.0107 - within_eps_0_005: 0.0151 - within_eps_0_01: 0.0280 - within_eps_0_02: 0.0557 - within_eps_0_05: 0.1387 - within_eps_0_1: 0.2664 - val_log_cosh: 0.0597 - val_loss: 0.0112 - val_within_eps_0_005: 0.0183 - val_within_eps_0_01: 0.0376 - val_within_eps_0_02: 0.0734 - val_within_eps_0_05: 0.1745 - val_within_eps_0_1: 0.3292\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - log_cosh: 0.0368 - loss: 0.0098 - within_eps_0_005: 0.0148 - within_eps_0_01: 0.0288 - within_eps_0_02: 0.0571 - within_eps_0_05: 0.1446 - within_eps_0_1: 0.2875 - val_log_cosh: 0.0805 - val_loss: 0.0140 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0542 - val_within_eps_0_05: 0.1303 - val_within_eps_0_1: 0.2559\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - log_cosh: 0.0319 - loss: 0.0090 - within_eps_0_005: 0.0159 - within_eps_0_01: 0.0316 - within_eps_0_02: 0.0610 - within_eps_0_05: 0.1544 - within_eps_0_1: 0.3053 - val_log_cosh: 0.0967 - val_loss: 0.0159 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0222 - val_within_eps_0_02: 0.0438 - val_within_eps_0_05: 0.1128 - val_within_eps_0_1: 0.2442\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0272 - loss: 0.0082 - within_eps_0_005: 0.0179 - within_eps_0_01: 0.0356 - within_eps_0_02: 0.0692 - within_eps_0_05: 0.1726 - within_eps_0_1: 0.3362 - val_log_cosh: 0.1153 - val_loss: 0.0177 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0259 - val_within_eps_0_02: 0.0503 - val_within_eps_0_05: 0.1172 - val_within_eps_0_1: 0.2322\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0240 - loss: 0.0076 - within_eps_0_005: 0.0178 - within_eps_0_01: 0.0360 - within_eps_0_02: 0.0726 - within_eps_0_05: 0.1821 - within_eps_0_1: 0.3554 - val_log_cosh: 0.1425 - val_loss: 0.0209 - val_within_eps_0_005: 0.0067 - val_within_eps_0_01: 0.0135 - val_within_eps_0_02: 0.0260 - val_within_eps_0_05: 0.0637 - val_within_eps_0_1: 0.1501\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - log_cosh: 0.0210 - loss: 0.0070 - within_eps_0_005: 0.0199 - within_eps_0_01: 0.0402 - within_eps_0_02: 0.0794 - within_eps_0_05: 0.1976 - within_eps_0_1: 0.3793 - val_log_cosh: 0.1400 - val_loss: 0.0198 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0250 - val_within_eps_0_02: 0.0492 - val_within_eps_0_05: 0.1083 - val_within_eps_0_1: 0.2045\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - log_cosh: 0.0192 - loss: 0.0066 - within_eps_0_005: 0.0211 - within_eps_0_01: 0.0417 - within_eps_0_02: 0.0830 - within_eps_0_05: 0.2079 - within_eps_0_1: 0.3985 - val_log_cosh: 0.0715 - val_loss: 0.0127 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0328 - val_within_eps_0_02: 0.0639 - val_within_eps_0_05: 0.1604 - val_within_eps_0_1: 0.2907\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - log_cosh: 0.0151 - loss: 0.0057 - within_eps_0_005: 0.0225 - within_eps_0_01: 0.0464 - within_eps_0_02: 0.0957 - within_eps_0_05: 0.2356 - within_eps_0_1: 0.4471 - val_log_cosh: 0.2894 - val_loss: 0.0343 - val_within_eps_0_005: 0.0024 - val_within_eps_0_01: 0.0049 - val_within_eps_0_02: 0.0096 - val_within_eps_0_05: 0.0257 - val_within_eps_0_1: 0.0494\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.0152 - loss: 0.0057 - within_eps_0_005: 0.0235 - within_eps_0_01: 0.0460 - within_eps_0_02: 0.0931 - within_eps_0_05: 0.2379 - within_eps_0_1: 0.4524 - val_log_cosh: 0.1165 - val_loss: 0.0181 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0205 - val_within_eps_0_02: 0.0411 - val_within_eps_0_05: 0.1070 - val_within_eps_0_1: 0.2140\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - log_cosh: 0.0157 - loss: 0.0058 - within_eps_0_005: 0.0246 - within_eps_0_01: 0.0490 - within_eps_0_02: 0.0973 - within_eps_0_05: 0.2411 - within_eps_0_1: 0.4549 - val_log_cosh: 0.0778 - val_loss: 0.0139 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0526 - val_within_eps_0_05: 0.1251 - val_within_eps_0_1: 0.2531\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0098 - loss: 0.0044 - within_eps_0_005: 0.0289 - within_eps_0_01: 0.0597 - within_eps_0_02: 0.1200 - within_eps_0_05: 0.2899 - within_eps_0_1: 0.5400 - val_log_cosh: 0.1014 - val_loss: 0.0166 - val_within_eps_0_005: 0.0089 - val_within_eps_0_01: 0.0181 - val_within_eps_0_02: 0.0362 - val_within_eps_0_05: 0.0955 - val_within_eps_0_1: 0.1964\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - log_cosh: 0.0081 - loss: 0.0039 - within_eps_0_005: 0.0325 - within_eps_0_01: 0.0643 - within_eps_0_02: 0.1312 - within_eps_0_05: 0.3205 - within_eps_0_1: 0.5891 - val_log_cosh: 0.1371 - val_loss: 0.0202 - val_within_eps_0_005: 0.0098 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0419 - val_within_eps_0_05: 0.1022 - val_within_eps_0_1: 0.1946\n",
      "  -> min val_log_cosh=0.054581042379 | min val_huber=0.010592723265\n",
      "\n",
      "--- Entrenando δ=0.1 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 140ms/step - log_cosh: 0.1901 - loss: 0.0474 - within_eps_0_005: 0.0067 - within_eps_0_01: 0.0132 - within_eps_0_02: 0.0267 - within_eps_0_05: 0.0654 - within_eps_0_1: 0.1289 - val_log_cosh: 0.1213 - val_loss: 0.0334 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0309 - val_within_eps_0_02: 0.0555 - val_within_eps_0_05: 0.1186 - val_within_eps_0_1: 0.2380\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - log_cosh: 0.1129 - loss: 0.0350 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0169 - within_eps_0_02: 0.0341 - within_eps_0_05: 0.0842 - within_eps_0_1: 0.1637 - val_log_cosh: 0.0841 - val_loss: 0.0261 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1529 - val_within_eps_0_1: 0.2937\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - log_cosh: 0.1091 - loss: 0.0344 - within_eps_0_005: 0.0082 - within_eps_0_01: 0.0162 - within_eps_0_02: 0.0323 - within_eps_0_05: 0.0808 - within_eps_0_1: 0.1644 - val_log_cosh: 0.0644 - val_loss: 0.0208 - val_within_eps_0_005: 0.0182 - val_within_eps_0_01: 0.0366 - val_within_eps_0_02: 0.0725 - val_within_eps_0_05: 0.1780 - val_within_eps_0_1: 0.3352\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - log_cosh: 0.1038 - loss: 0.0333 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0173 - within_eps_0_02: 0.0342 - within_eps_0_05: 0.0821 - within_eps_0_1: 0.1647 - val_log_cosh: 0.0665 - val_loss: 0.0220 - val_within_eps_0_005: 0.0173 - val_within_eps_0_01: 0.0342 - val_within_eps_0_02: 0.0700 - val_within_eps_0_05: 0.1654 - val_within_eps_0_1: 0.3170\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - log_cosh: 0.0984 - loss: 0.0323 - within_eps_0_005: 0.0084 - within_eps_0_01: 0.0173 - within_eps_0_02: 0.0341 - within_eps_0_05: 0.0856 - within_eps_0_1: 0.1702 - val_log_cosh: 0.0631 - val_loss: 0.0209 - val_within_eps_0_005: 0.0181 - val_within_eps_0_01: 0.0355 - val_within_eps_0_02: 0.0716 - val_within_eps_0_05: 0.1734 - val_within_eps_0_1: 0.3217\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0940 - loss: 0.0314 - within_eps_0_005: 0.0083 - within_eps_0_01: 0.0172 - within_eps_0_02: 0.0358 - within_eps_0_05: 0.0910 - within_eps_0_1: 0.1789 - val_log_cosh: 0.0610 - val_loss: 0.0211 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0242 - val_within_eps_0_02: 0.0500 - val_within_eps_0_05: 0.1297 - val_within_eps_0_1: 0.2854\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0891 - loss: 0.0303 - within_eps_0_005: 0.0092 - within_eps_0_01: 0.0183 - within_eps_0_02: 0.0369 - within_eps_0_05: 0.0904 - within_eps_0_1: 0.1808 - val_log_cosh: 0.0648 - val_loss: 0.0216 - val_within_eps_0_005: 0.0176 - val_within_eps_0_01: 0.0343 - val_within_eps_0_02: 0.0670 - val_within_eps_0_05: 0.1525 - val_within_eps_0_1: 0.2878\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0818 - loss: 0.0288 - within_eps_0_005: 0.0095 - within_eps_0_01: 0.0189 - within_eps_0_02: 0.0380 - within_eps_0_05: 0.0954 - within_eps_0_1: 0.1871 - val_log_cosh: 0.0829 - val_loss: 0.0255 - val_within_eps_0_005: 0.0167 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0606 - val_within_eps_0_05: 0.1473 - val_within_eps_0_1: 0.2759\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0807 - loss: 0.0285 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0191 - within_eps_0_02: 0.0386 - within_eps_0_05: 0.0974 - within_eps_0_1: 0.1934 - val_log_cosh: 0.0723 - val_loss: 0.0245 - val_within_eps_0_005: 0.0109 - val_within_eps_0_01: 0.0208 - val_within_eps_0_02: 0.0416 - val_within_eps_0_05: 0.1053 - val_within_eps_0_1: 0.2202\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0756 - loss: 0.0274 - within_eps_0_005: 0.0105 - within_eps_0_01: 0.0212 - within_eps_0_02: 0.0412 - within_eps_0_05: 0.1017 - within_eps_0_1: 0.1995 - val_log_cosh: 0.0623 - val_loss: 0.0214 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0612 - val_within_eps_0_05: 0.1595 - val_within_eps_0_1: 0.3073\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0746 - loss: 0.0271 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0197 - within_eps_0_02: 0.0399 - within_eps_0_05: 0.1022 - within_eps_0_1: 0.2004 - val_log_cosh: 0.0673 - val_loss: 0.0223 - val_within_eps_0_005: 0.0172 - val_within_eps_0_01: 0.0336 - val_within_eps_0_02: 0.0684 - val_within_eps_0_05: 0.1649 - val_within_eps_0_1: 0.3010\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0664 - loss: 0.0253 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0216 - within_eps_0_02: 0.0441 - within_eps_0_05: 0.1101 - within_eps_0_1: 0.2134 - val_log_cosh: 0.0918 - val_loss: 0.0276 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0564 - val_within_eps_0_05: 0.1323 - val_within_eps_0_1: 0.2544\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0633 - loss: 0.0246 - within_eps_0_005: 0.0104 - within_eps_0_01: 0.0216 - within_eps_0_02: 0.0434 - within_eps_0_05: 0.1076 - within_eps_0_1: 0.2140 - val_log_cosh: 0.0862 - val_loss: 0.0266 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0607 - val_within_eps_0_05: 0.1415 - val_within_eps_0_1: 0.2530\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0615 - loss: 0.0241 - within_eps_0_005: 0.0107 - within_eps_0_01: 0.0223 - within_eps_0_02: 0.0439 - within_eps_0_05: 0.1110 - within_eps_0_1: 0.2199 - val_log_cosh: 0.1259 - val_loss: 0.0365 - val_within_eps_0_005: 0.0045 - val_within_eps_0_01: 0.0089 - val_within_eps_0_02: 0.0206 - val_within_eps_0_05: 0.0560 - val_within_eps_0_1: 0.1216\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0896 - loss: 0.0304 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0192 - within_eps_0_02: 0.0374 - within_eps_0_05: 0.0910 - within_eps_0_1: 0.1808 - val_log_cosh: 0.1634 - val_loss: 0.0424 - val_within_eps_0_005: 0.0077 - val_within_eps_0_01: 0.0163 - val_within_eps_0_02: 0.0343 - val_within_eps_0_05: 0.0932 - val_within_eps_0_1: 0.1756\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0677 - loss: 0.0256 - within_eps_0_005: 0.0110 - within_eps_0_01: 0.0218 - within_eps_0_02: 0.0426 - within_eps_0_05: 0.1068 - within_eps_0_1: 0.2125 - val_log_cosh: 0.1578 - val_loss: 0.0421 - val_within_eps_0_005: 0.0084 - val_within_eps_0_01: 0.0171 - val_within_eps_0_02: 0.0328 - val_within_eps_0_05: 0.0789 - val_within_eps_0_1: 0.1560\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0615 - loss: 0.0240 - within_eps_0_005: 0.0117 - within_eps_0_01: 0.0233 - within_eps_0_02: 0.0452 - within_eps_0_05: 0.1112 - within_eps_0_1: 0.2202 - val_log_cosh: 0.1191 - val_loss: 0.0355 - val_within_eps_0_005: 0.0085 - val_within_eps_0_01: 0.0163 - val_within_eps_0_02: 0.0320 - val_within_eps_0_05: 0.0850 - val_within_eps_0_1: 0.1704\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0502 - loss: 0.0212 - within_eps_0_005: 0.0123 - within_eps_0_01: 0.0245 - within_eps_0_02: 0.0503 - within_eps_0_05: 0.1256 - within_eps_0_1: 0.2459 - val_log_cosh: 0.0470 - val_loss: 0.0183 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0323 - val_within_eps_0_02: 0.0683 - val_within_eps_0_05: 0.1751 - val_within_eps_0_1: 0.3358\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0416 - loss: 0.0189 - within_eps_0_005: 0.0136 - within_eps_0_01: 0.0276 - within_eps_0_02: 0.0554 - within_eps_0_05: 0.1382 - within_eps_0_1: 0.2694 - val_log_cosh: 0.0506 - val_loss: 0.0190 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1496 - val_within_eps_0_1: 0.3129\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0353 - loss: 0.0170 - within_eps_0_005: 0.0158 - within_eps_0_01: 0.0309 - within_eps_0_02: 0.0603 - within_eps_0_05: 0.1491 - within_eps_0_1: 0.2924 - val_log_cosh: 0.0508 - val_loss: 0.0182 - val_within_eps_0_005: 0.0169 - val_within_eps_0_01: 0.0337 - val_within_eps_0_02: 0.0678 - val_within_eps_0_05: 0.1737 - val_within_eps_0_1: 0.3322\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0295 - loss: 0.0151 - within_eps_0_005: 0.0158 - within_eps_0_01: 0.0310 - within_eps_0_02: 0.0649 - within_eps_0_05: 0.1632 - within_eps_0_1: 0.3188 - val_log_cosh: 0.0580 - val_loss: 0.0200 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1467 - val_within_eps_0_1: 0.2993\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0261 - loss: 0.0140 - within_eps_0_005: 0.0170 - within_eps_0_01: 0.0343 - within_eps_0_02: 0.0684 - within_eps_0_05: 0.1707 - within_eps_0_1: 0.3375 - val_log_cosh: 0.0689 - val_loss: 0.0225 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0529 - val_within_eps_0_05: 0.1377 - val_within_eps_0_1: 0.2744\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0214 - loss: 0.0122 - within_eps_0_005: 0.0196 - within_eps_0_01: 0.0397 - within_eps_0_02: 0.0792 - within_eps_0_05: 0.1969 - within_eps_0_1: 0.3757 - val_log_cosh: 0.0849 - val_loss: 0.0258 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0577 - val_within_eps_0_05: 0.1490 - val_within_eps_0_1: 0.2966\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0203 - loss: 0.0118 - within_eps_0_005: 0.0197 - within_eps_0_01: 0.0398 - within_eps_0_02: 0.0793 - within_eps_0_05: 0.1987 - within_eps_0_1: 0.3841 - val_log_cosh: 0.1051 - val_loss: 0.0313 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0236 - val_within_eps_0_02: 0.0479 - val_within_eps_0_05: 0.1125 - val_within_eps_0_1: 0.1996\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0195 - loss: 0.0115 - within_eps_0_005: 0.0203 - within_eps_0_01: 0.0410 - within_eps_0_02: 0.0822 - within_eps_0_05: 0.2038 - within_eps_0_1: 0.3921 - val_log_cosh: 0.0756 - val_loss: 0.0242 - val_within_eps_0_005: 0.0101 - val_within_eps_0_01: 0.0201 - val_within_eps_0_02: 0.0424 - val_within_eps_0_05: 0.1173 - val_within_eps_0_1: 0.2463\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0145 - loss: 0.0094 - within_eps_0_005: 0.0234 - within_eps_0_01: 0.0466 - within_eps_0_02: 0.0938 - within_eps_0_05: 0.2364 - within_eps_0_1: 0.4507 - val_log_cosh: 0.1385 - val_loss: 0.0367 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0481 - val_within_eps_0_05: 0.1148 - val_within_eps_0_1: 0.2221\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0146 - loss: 0.0093 - within_eps_0_005: 0.0240 - within_eps_0_01: 0.0478 - within_eps_0_02: 0.0953 - within_eps_0_05: 0.2376 - within_eps_0_1: 0.4534 - val_log_cosh: 0.0825 - val_loss: 0.0256 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1471 - val_within_eps_0_1: 0.2805\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0099 - loss: 0.0071 - within_eps_0_005: 0.0295 - within_eps_0_01: 0.0588 - within_eps_0_02: 0.1185 - within_eps_0_05: 0.2857 - within_eps_0_1: 0.5335 - val_log_cosh: 0.0811 - val_loss: 0.0260 - val_within_eps_0_005: 0.0108 - val_within_eps_0_01: 0.0220 - val_within_eps_0_02: 0.0471 - val_within_eps_0_05: 0.1214 - val_within_eps_0_1: 0.2315\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0078 - loss: 0.0059 - within_eps_0_005: 0.0322 - within_eps_0_01: 0.0654 - within_eps_0_02: 0.1304 - within_eps_0_05: 0.3207 - within_eps_0_1: 0.5891 - val_log_cosh: 0.0906 - val_loss: 0.0274 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0313 - val_within_eps_0_02: 0.0614 - val_within_eps_0_05: 0.1443 - val_within_eps_0_1: 0.2667\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0079 - loss: 0.0059 - within_eps_0_005: 0.0343 - within_eps_0_01: 0.0683 - within_eps_0_02: 0.1333 - within_eps_0_05: 0.3268 - within_eps_0_1: 0.5978 - val_log_cosh: 0.0609 - val_loss: 0.0209 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0281 - val_within_eps_0_02: 0.0584 - val_within_eps_0_05: 0.1436 - val_within_eps_0_1: 0.2812\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0066 - loss: 0.0052 - within_eps_0_005: 0.0369 - within_eps_0_01: 0.0725 - within_eps_0_02: 0.1432 - within_eps_0_05: 0.3499 - within_eps_0_1: 0.6317 - val_log_cosh: 0.1031 - val_loss: 0.0305 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0505 - val_within_eps_0_05: 0.1299 - val_within_eps_0_1: 0.2495\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - log_cosh: 0.0049 - loss: 0.0041 - within_eps_0_005: 0.0417 - within_eps_0_01: 0.0835 - within_eps_0_02: 0.1674 - within_eps_0_05: 0.4024 - within_eps_0_1: 0.7042 - val_log_cosh: 0.2371 - val_loss: 0.0577 - val_within_eps_0_005: 0.0028 - val_within_eps_0_01: 0.0059 - val_within_eps_0_02: 0.0119 - val_within_eps_0_05: 0.0257 - val_within_eps_0_1: 0.0566\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - log_cosh: 0.0067 - loss: 0.0050 - within_eps_0_005: 0.0389 - within_eps_0_01: 0.0787 - within_eps_0_02: 0.1551 - within_eps_0_05: 0.3742 - within_eps_0_1: 0.6615 - val_log_cosh: 0.0538 - val_loss: 0.0188 - val_within_eps_0_005: 0.0215 - val_within_eps_0_01: 0.0428 - val_within_eps_0_02: 0.0851 - val_within_eps_0_05: 0.1989 - val_within_eps_0_1: 0.3700\n",
      "  -> min val_log_cosh=0.047035854310 | min val_huber=0.018203893676\n",
      "\n",
      "Tabla val_log_cosh(min) por δ (orden asc):\n",
      "  δ=0.0411621: val_log_cosh=0.046458147466 | val_huber=0.008098780178\n",
      "  δ=    0.01: val_log_cosh=0.046861279756 | val_huber=0.002146322280\n",
      "  δ=     0.1: val_log_cosh=0.047035854310 | val_huber=0.018203893676\n",
      "  δ=0.00853497: val_log_cosh=0.050636094064 | val_huber=0.001937584835\n",
      "  δ=    0.05: val_log_cosh=0.054581042379 | val_huber=0.010592723265\n",
      "  δ=    0.02: val_log_cosh=0.055525932461 | val_huber=0.004493620247\n",
      "  δ=0.0304968: val_log_cosh=0.056463178247 | val_huber=0.006652056705\n",
      "  δ=0.0173574: val_log_cosh=0.057848032564 | val_huber=0.003941430710\n",
      "\n",
      ">>> Mejor δ por val_log_cosh: 0.04116208553314208 (val_log_cosh=0.046458147466)\n",
      "\n",
      "Resultados TEST - Escenario S (Transformer)\n",
      "  loss (Huber):              0.064830\n",
      "  log_cosh:                  1.311214\n",
      "  within_eps_0_005          : 0.005625\n",
      "  within_eps_0_01           : 0.012031\n",
      "  within_eps_0_02           : 0.024297\n",
      "  within_eps_0_05           : 0.055938\n",
      "  within_eps_0_1            : 0.118166\n",
      "  AUTC[0.005–0.100]:         0.060862\n",
      "\n",
      "Grid δ (calibrado con cuantiles |e| en VAL): [0.01, 0.014598846435546875, 0.02, 0.02976226806640625, 0.05, 0.051824706792831444, 0.07143068313598633, 0.1]\n",
      "\n",
      "=== Barrido Huber delta _M (Transformer) ===\n",
      "\n",
      "--- Entrenando δ=0.01 ---\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 09:28:34.986918: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - log_cosh: 0.1716 - loss: 0.0049 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0140 - within_eps_0_02: 0.0278 - within_eps_0_05: 0.0694 - within_eps_0_1: 0.1394 - val_log_cosh: 0.1224 - val_loss: 0.0039 - val_within_eps_0_005: 0.0089 - val_within_eps_0_01: 0.0177 - val_within_eps_0_02: 0.0368 - val_within_eps_0_05: 0.0914 - val_within_eps_0_1: 0.1758\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0915 - loss: 0.0035 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0178 - within_eps_0_02: 0.0359 - within_eps_0_05: 0.0895 - within_eps_0_1: 0.1785 - val_log_cosh: 0.0822 - val_loss: 0.0030 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0260 - val_within_eps_0_02: 0.0502 - val_within_eps_0_05: 0.1233 - val_within_eps_0_1: 0.2320\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0881 - loss: 0.0034 - within_eps_0_005: 0.0094 - within_eps_0_01: 0.0181 - within_eps_0_02: 0.0367 - within_eps_0_05: 0.0915 - within_eps_0_1: 0.1833 - val_log_cosh: 0.0747 - val_loss: 0.0028 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0252 - val_within_eps_0_02: 0.0500 - val_within_eps_0_05: 0.1266 - val_within_eps_0_1: 0.2547\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0827 - loss: 0.0033 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0198 - within_eps_0_02: 0.0386 - within_eps_0_05: 0.0950 - within_eps_0_1: 0.1896 - val_log_cosh: 0.0688 - val_loss: 0.0027 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0565 - val_within_eps_0_05: 0.1447 - val_within_eps_0_1: 0.2830\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - log_cosh: 0.0758 - loss: 0.0032 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0195 - within_eps_0_02: 0.0399 - within_eps_0_05: 0.0989 - within_eps_0_1: 0.1957 - val_log_cosh: 0.0661 - val_loss: 0.0026 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0616 - val_within_eps_0_05: 0.1528 - val_within_eps_0_1: 0.2908\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0691 - loss: 0.0030 - within_eps_0_005: 0.0102 - within_eps_0_01: 0.0205 - within_eps_0_02: 0.0412 - within_eps_0_05: 0.1033 - within_eps_0_1: 0.2062 - val_log_cosh: 0.0641 - val_loss: 0.0025 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0326 - val_within_eps_0_02: 0.0656 - val_within_eps_0_05: 0.1624 - val_within_eps_0_1: 0.3103\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0640 - loss: 0.0029 - within_eps_0_005: 0.0105 - within_eps_0_01: 0.0213 - within_eps_0_02: 0.0432 - within_eps_0_05: 0.1074 - within_eps_0_1: 0.2142 - val_log_cosh: 0.0631 - val_loss: 0.0025 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0350 - val_within_eps_0_02: 0.0695 - val_within_eps_0_05: 0.1648 - val_within_eps_0_1: 0.3048\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0583 - loss: 0.0027 - within_eps_0_005: 0.0116 - within_eps_0_01: 0.0226 - within_eps_0_02: 0.0452 - within_eps_0_05: 0.1128 - within_eps_0_1: 0.2248 - val_log_cosh: 0.0637 - val_loss: 0.0025 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0348 - val_within_eps_0_02: 0.0690 - val_within_eps_0_05: 0.1686 - val_within_eps_0_1: 0.3116\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0530 - loss: 0.0026 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0246 - within_eps_0_02: 0.0483 - within_eps_0_05: 0.1210 - within_eps_0_1: 0.2380 - val_log_cosh: 0.0646 - val_loss: 0.0025 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0352 - val_within_eps_0_02: 0.0697 - val_within_eps_0_05: 0.1671 - val_within_eps_0_1: 0.3247\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - log_cosh: 0.0481 - loss: 0.0025 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0242 - within_eps_0_02: 0.0497 - within_eps_0_05: 0.1248 - within_eps_0_1: 0.2478 - val_log_cosh: 0.0685 - val_loss: 0.0026 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0361 - val_within_eps_0_02: 0.0725 - val_within_eps_0_05: 0.1772 - val_within_eps_0_1: 0.3313\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0434 - loss: 0.0023 - within_eps_0_005: 0.0134 - within_eps_0_01: 0.0272 - within_eps_0_02: 0.0540 - within_eps_0_05: 0.1346 - within_eps_0_1: 0.2638 - val_log_cosh: 0.0706 - val_loss: 0.0027 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0582 - val_within_eps_0_05: 0.1490 - val_within_eps_0_1: 0.2900\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0386 - loss: 0.0022 - within_eps_0_005: 0.0144 - within_eps_0_01: 0.0284 - within_eps_0_02: 0.0571 - within_eps_0_05: 0.1417 - within_eps_0_1: 0.2788 - val_log_cosh: 0.0743 - val_loss: 0.0028 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0601 - val_within_eps_0_05: 0.1473 - val_within_eps_0_1: 0.2796\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0347 - loss: 0.0021 - within_eps_0_005: 0.0152 - within_eps_0_01: 0.0306 - within_eps_0_02: 0.0606 - within_eps_0_05: 0.1500 - within_eps_0_1: 0.2939 - val_log_cosh: 0.0751 - val_loss: 0.0028 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0309 - val_within_eps_0_02: 0.0611 - val_within_eps_0_05: 0.1469 - val_within_eps_0_1: 0.2834\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0308 - loss: 0.0020 - within_eps_0_005: 0.0166 - within_eps_0_01: 0.0322 - within_eps_0_02: 0.0641 - within_eps_0_05: 0.1592 - within_eps_0_1: 0.3119 - val_log_cosh: 0.0760 - val_loss: 0.0028 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0326 - val_within_eps_0_02: 0.0659 - val_within_eps_0_05: 0.1558 - val_within_eps_0_1: 0.2933\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0272 - loss: 0.0018 - within_eps_0_005: 0.0170 - within_eps_0_01: 0.0343 - within_eps_0_02: 0.0691 - within_eps_0_05: 0.1706 - within_eps_0_1: 0.3317 - val_log_cosh: 0.0845 - val_loss: 0.0030 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0519 - val_within_eps_0_05: 0.1322 - val_within_eps_0_1: 0.2622\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0237 - loss: 0.0017 - within_eps_0_005: 0.0185 - within_eps_0_01: 0.0367 - within_eps_0_02: 0.0731 - within_eps_0_05: 0.1820 - within_eps_0_1: 0.3553 - val_log_cosh: 0.0900 - val_loss: 0.0032 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0473 - val_within_eps_0_05: 0.1184 - val_within_eps_0_1: 0.2368\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0203 - loss: 0.0016 - within_eps_0_005: 0.0199 - within_eps_0_01: 0.0396 - within_eps_0_02: 0.0798 - within_eps_0_05: 0.1974 - within_eps_0_1: 0.3836 - val_log_cosh: 0.1229 - val_loss: 0.0038 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0281 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1364 - val_within_eps_0_1: 0.2554\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0202 - loss: 0.0016 - within_eps_0_005: 0.0201 - within_eps_0_01: 0.0400 - within_eps_0_02: 0.0802 - within_eps_0_05: 0.1999 - within_eps_0_1: 0.3877 - val_log_cosh: 0.0750 - val_loss: 0.0028 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0564 - val_within_eps_0_05: 0.1447 - val_within_eps_0_1: 0.2921\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0169 - loss: 0.0014 - within_eps_0_005: 0.0221 - within_eps_0_01: 0.0439 - within_eps_0_02: 0.0869 - within_eps_0_05: 0.2142 - within_eps_0_1: 0.4151 - val_log_cosh: 0.0725 - val_loss: 0.0028 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1351 - val_within_eps_0_1: 0.2657\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0139 - loss: 0.0013 - within_eps_0_005: 0.0242 - within_eps_0_01: 0.0482 - within_eps_0_02: 0.0958 - within_eps_0_05: 0.2379 - within_eps_0_1: 0.4571 - val_log_cosh: 0.1911 - val_loss: 0.0053 - val_within_eps_0_005: 0.0033 - val_within_eps_0_01: 0.0067 - val_within_eps_0_02: 0.0138 - val_within_eps_0_05: 0.0390 - val_within_eps_0_1: 0.0901\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0190 - loss: 0.0015 - within_eps_0_005: 0.0213 - within_eps_0_01: 0.0425 - within_eps_0_02: 0.0851 - within_eps_0_05: 0.2100 - within_eps_0_1: 0.4045 - val_log_cosh: 0.0997 - val_loss: 0.0034 - val_within_eps_0_005: 0.0119 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0484 - val_within_eps_0_05: 0.1193 - val_within_eps_0_1: 0.2247\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0112 - loss: 0.0011 - within_eps_0_005: 0.0276 - within_eps_0_01: 0.0546 - within_eps_0_02: 0.1089 - within_eps_0_05: 0.2675 - within_eps_0_1: 0.5051 - val_log_cosh: 0.1165 - val_loss: 0.0038 - val_within_eps_0_005: 0.0077 - val_within_eps_0_01: 0.0162 - val_within_eps_0_02: 0.0328 - val_within_eps_0_05: 0.0853 - val_within_eps_0_1: 0.1819\n",
      "  -> min val_log_cosh=0.063117064536 | min val_huber=0.002502671443\n",
      "\n",
      "--- Entrenando δ=0.014598846435546875 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - log_cosh: 0.1801 - loss: 0.0072 - within_eps_0_005: 0.0067 - within_eps_0_01: 0.0141 - within_eps_0_02: 0.0282 - within_eps_0_05: 0.0706 - within_eps_0_1: 0.1399 - val_log_cosh: 0.1111 - val_loss: 0.0053 - val_within_eps_0_005: 0.0110 - val_within_eps_0_01: 0.0220 - val_within_eps_0_02: 0.0436 - val_within_eps_0_05: 0.1002 - val_within_eps_0_1: 0.1926\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - log_cosh: 0.0885 - loss: 0.0050 - within_eps_0_005: 0.0092 - within_eps_0_01: 0.0184 - within_eps_0_02: 0.0368 - within_eps_0_05: 0.0916 - within_eps_0_1: 0.1824 - val_log_cosh: 0.0869 - val_loss: 0.0045 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0422 - val_within_eps_0_05: 0.1106 - val_within_eps_0_1: 0.2303\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0858 - loss: 0.0049 - within_eps_0_005: 0.0093 - within_eps_0_01: 0.0185 - within_eps_0_02: 0.0371 - within_eps_0_05: 0.0928 - within_eps_0_1: 0.1838 - val_log_cosh: 0.0762 - val_loss: 0.0041 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0495 - val_within_eps_0_05: 0.1247 - val_within_eps_0_1: 0.2523\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0799 - loss: 0.0047 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0193 - within_eps_0_02: 0.0383 - within_eps_0_05: 0.0959 - within_eps_0_1: 0.1919 - val_log_cosh: 0.0774 - val_loss: 0.0041 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0243 - val_within_eps_0_02: 0.0498 - val_within_eps_0_05: 0.1262 - val_within_eps_0_1: 0.2610\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0740 - loss: 0.0045 - within_eps_0_005: 0.0103 - within_eps_0_01: 0.0204 - within_eps_0_02: 0.0404 - within_eps_0_05: 0.1008 - within_eps_0_1: 0.1991 - val_log_cosh: 0.0719 - val_loss: 0.0040 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0590 - val_within_eps_0_05: 0.1425 - val_within_eps_0_1: 0.2712\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0681 - loss: 0.0043 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0206 - within_eps_0_02: 0.0421 - within_eps_0_05: 0.1045 - within_eps_0_1: 0.2078 - val_log_cosh: 0.0676 - val_loss: 0.0038 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0562 - val_within_eps_0_05: 0.1424 - val_within_eps_0_1: 0.2858\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0628 - loss: 0.0041 - within_eps_0_005: 0.0109 - within_eps_0_01: 0.0222 - within_eps_0_02: 0.0447 - within_eps_0_05: 0.1105 - within_eps_0_1: 0.2189 - val_log_cosh: 0.0638 - val_loss: 0.0037 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0325 - val_within_eps_0_02: 0.0640 - val_within_eps_0_05: 0.1591 - val_within_eps_0_1: 0.2975\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0577 - loss: 0.0040 - within_eps_0_005: 0.0117 - within_eps_0_01: 0.0233 - within_eps_0_02: 0.0460 - within_eps_0_05: 0.1147 - within_eps_0_1: 0.2257 - val_log_cosh: 0.0694 - val_loss: 0.0039 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1428 - val_within_eps_0_1: 0.2753\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0522 - loss: 0.0037 - within_eps_0_005: 0.0122 - within_eps_0_01: 0.0245 - within_eps_0_02: 0.0490 - within_eps_0_05: 0.1219 - within_eps_0_1: 0.2410 - val_log_cosh: 0.0665 - val_loss: 0.0038 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0580 - val_within_eps_0_05: 0.1510 - val_within_eps_0_1: 0.2894\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0477 - loss: 0.0036 - within_eps_0_005: 0.0129 - within_eps_0_01: 0.0260 - within_eps_0_02: 0.0515 - within_eps_0_05: 0.1279 - within_eps_0_1: 0.2508 - val_log_cosh: 0.0678 - val_loss: 0.0038 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0537 - val_within_eps_0_05: 0.1404 - val_within_eps_0_1: 0.2753\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0424 - loss: 0.0034 - within_eps_0_005: 0.0136 - within_eps_0_01: 0.0269 - within_eps_0_02: 0.0541 - within_eps_0_05: 0.1336 - within_eps_0_1: 0.2641 - val_log_cosh: 0.0695 - val_loss: 0.0038 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0626 - val_within_eps_0_05: 0.1474 - val_within_eps_0_1: 0.2842\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0382 - loss: 0.0032 - within_eps_0_005: 0.0146 - within_eps_0_01: 0.0285 - within_eps_0_02: 0.0574 - within_eps_0_05: 0.1425 - within_eps_0_1: 0.2806 - val_log_cosh: 0.0712 - val_loss: 0.0039 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0628 - val_within_eps_0_05: 0.1544 - val_within_eps_0_1: 0.2897\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0348 - loss: 0.0030 - within_eps_0_005: 0.0151 - within_eps_0_01: 0.0301 - within_eps_0_02: 0.0605 - within_eps_0_05: 0.1504 - within_eps_0_1: 0.2941 - val_log_cosh: 0.0745 - val_loss: 0.0040 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0330 - val_within_eps_0_02: 0.0652 - val_within_eps_0_05: 0.1551 - val_within_eps_0_1: 0.2981\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0304 - loss: 0.0028 - within_eps_0_005: 0.0163 - within_eps_0_01: 0.0325 - within_eps_0_02: 0.0652 - within_eps_0_05: 0.1606 - within_eps_0_1: 0.3148 - val_log_cosh: 0.0756 - val_loss: 0.0040 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0579 - val_within_eps_0_05: 0.1486 - val_within_eps_0_1: 0.2881\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0271 - loss: 0.0026 - within_eps_0_005: 0.0172 - within_eps_0_01: 0.0342 - within_eps_0_02: 0.0681 - within_eps_0_05: 0.1707 - within_eps_0_1: 0.3335 - val_log_cosh: 0.0822 - val_loss: 0.0043 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0509 - val_within_eps_0_05: 0.1324 - val_within_eps_0_1: 0.2649\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0244 - loss: 0.0025 - within_eps_0_005: 0.0180 - within_eps_0_01: 0.0360 - within_eps_0_02: 0.0714 - within_eps_0_05: 0.1784 - within_eps_0_1: 0.3481 - val_log_cosh: 0.0833 - val_loss: 0.0043 - val_within_eps_0_005: 0.0126 - val_within_eps_0_01: 0.0264 - val_within_eps_0_02: 0.0537 - val_within_eps_0_05: 0.1350 - val_within_eps_0_1: 0.2629\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0216 - loss: 0.0023 - within_eps_0_005: 0.0189 - within_eps_0_01: 0.0381 - within_eps_0_02: 0.0770 - within_eps_0_05: 0.1913 - within_eps_0_1: 0.3720 - val_log_cosh: 0.0898 - val_loss: 0.0046 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1369 - val_within_eps_0_1: 0.2468\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0188 - loss: 0.0022 - within_eps_0_005: 0.0209 - within_eps_0_01: 0.0422 - within_eps_0_02: 0.0839 - within_eps_0_05: 0.2064 - within_eps_0_1: 0.3969 - val_log_cosh: 0.0864 - val_loss: 0.0044 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0605 - val_within_eps_0_05: 0.1435 - val_within_eps_0_1: 0.2701\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0163 - loss: 0.0020 - within_eps_0_005: 0.0221 - within_eps_0_01: 0.0446 - within_eps_0_02: 0.0894 - within_eps_0_05: 0.2212 - within_eps_0_1: 0.4243 - val_log_cosh: 0.1128 - val_loss: 0.0053 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0223 - val_within_eps_0_02: 0.0444 - val_within_eps_0_05: 0.1074 - val_within_eps_0_1: 0.2070\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0189 - loss: 0.0022 - within_eps_0_005: 0.0211 - within_eps_0_01: 0.0422 - within_eps_0_02: 0.0840 - within_eps_0_05: 0.2079 - within_eps_0_1: 0.4012 - val_log_cosh: 0.0755 - val_loss: 0.0040 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0285 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1448 - val_within_eps_0_1: 0.2812\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0130 - loss: 0.0018 - within_eps_0_005: 0.0245 - within_eps_0_01: 0.0500 - within_eps_0_02: 0.1001 - within_eps_0_05: 0.2482 - within_eps_0_1: 0.4710 - val_log_cosh: 0.1176 - val_loss: 0.0055 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0241 - val_within_eps_0_02: 0.0481 - val_within_eps_0_05: 0.1180 - val_within_eps_0_1: 0.2207\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0128 - loss: 0.0018 - within_eps_0_005: 0.0257 - within_eps_0_01: 0.0513 - within_eps_0_02: 0.1015 - within_eps_0_05: 0.2513 - within_eps_0_1: 0.4783 - val_log_cosh: 0.1111 - val_loss: 0.0051 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0266 - val_within_eps_0_02: 0.0531 - val_within_eps_0_05: 0.1330 - val_within_eps_0_1: 0.2543\n",
      "  -> min val_log_cosh=0.063764199615 | min val_huber=0.003660931950\n",
      "\n",
      "--- Entrenando δ=0.02 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 122ms/step - log_cosh: 0.1752 - loss: 0.0097 - within_eps_0_005: 0.0071 - within_eps_0_01: 0.0138 - within_eps_0_02: 0.0286 - within_eps_0_05: 0.0708 - within_eps_0_1: 0.1402 - val_log_cosh: 0.1141 - val_loss: 0.0072 - val_within_eps_0_005: 0.0103 - val_within_eps_0_01: 0.0205 - val_within_eps_0_02: 0.0402 - val_within_eps_0_05: 0.1017 - val_within_eps_0_1: 0.1979\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0922 - loss: 0.0069 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0177 - within_eps_0_02: 0.0357 - within_eps_0_05: 0.0891 - within_eps_0_1: 0.1775 - val_log_cosh: 0.0778 - val_loss: 0.0057 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0249 - val_within_eps_0_02: 0.0500 - val_within_eps_0_05: 0.1282 - val_within_eps_0_1: 0.2631\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0877 - loss: 0.0067 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0181 - within_eps_0_02: 0.0361 - within_eps_0_05: 0.0922 - within_eps_0_1: 0.1829 - val_log_cosh: 0.0730 - val_loss: 0.0055 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0250 - val_within_eps_0_02: 0.0510 - val_within_eps_0_05: 0.1286 - val_within_eps_0_1: 0.2583\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0825 - loss: 0.0065 - within_eps_0_005: 0.0095 - within_eps_0_01: 0.0191 - within_eps_0_02: 0.0382 - within_eps_0_05: 0.0946 - within_eps_0_1: 0.1878 - val_log_cosh: 0.0682 - val_loss: 0.0052 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0545 - val_within_eps_0_05: 0.1408 - val_within_eps_0_1: 0.2846\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0766 - loss: 0.0063 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0197 - within_eps_0_02: 0.0396 - within_eps_0_05: 0.0985 - within_eps_0_1: 0.1957 - val_log_cosh: 0.0665 - val_loss: 0.0052 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1435 - val_within_eps_0_1: 0.2774\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0700 - loss: 0.0060 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0204 - within_eps_0_02: 0.0408 - within_eps_0_05: 0.1020 - within_eps_0_1: 0.2039 - val_log_cosh: 0.0701 - val_loss: 0.0053 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1471 - val_within_eps_0_1: 0.2787\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0646 - loss: 0.0057 - within_eps_0_005: 0.0113 - within_eps_0_01: 0.0221 - within_eps_0_02: 0.0437 - within_eps_0_05: 0.1089 - within_eps_0_1: 0.2149 - val_log_cosh: 0.0721 - val_loss: 0.0053 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0304 - val_within_eps_0_02: 0.0581 - val_within_eps_0_05: 0.1405 - val_within_eps_0_1: 0.2866\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0582 - loss: 0.0054 - within_eps_0_005: 0.0114 - within_eps_0_01: 0.0231 - within_eps_0_02: 0.0465 - within_eps_0_05: 0.1155 - within_eps_0_1: 0.2268 - val_log_cosh: 0.0688 - val_loss: 0.0052 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0599 - val_within_eps_0_05: 0.1443 - val_within_eps_0_1: 0.2832\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0544 - loss: 0.0052 - within_eps_0_005: 0.0118 - within_eps_0_01: 0.0239 - within_eps_0_02: 0.0482 - within_eps_0_05: 0.1183 - within_eps_0_1: 0.2345 - val_log_cosh: 0.0760 - val_loss: 0.0055 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0581 - val_within_eps_0_05: 0.1424 - val_within_eps_0_1: 0.2826\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0494 - loss: 0.0049 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0253 - within_eps_0_02: 0.0501 - within_eps_0_05: 0.1252 - within_eps_0_1: 0.2487 - val_log_cosh: 0.0829 - val_loss: 0.0058 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0292 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1472 - val_within_eps_0_1: 0.2776\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0450 - loss: 0.0047 - within_eps_0_005: 0.0131 - within_eps_0_01: 0.0265 - within_eps_0_02: 0.0535 - within_eps_0_05: 0.1324 - within_eps_0_1: 0.2591 - val_log_cosh: 0.0847 - val_loss: 0.0059 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0544 - val_within_eps_0_05: 0.1368 - val_within_eps_0_1: 0.2658\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0405 - loss: 0.0044 - within_eps_0_005: 0.0134 - within_eps_0_01: 0.0274 - within_eps_0_02: 0.0550 - within_eps_0_05: 0.1380 - within_eps_0_1: 0.2707 - val_log_cosh: 0.0887 - val_loss: 0.0061 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0578 - val_within_eps_0_05: 0.1355 - val_within_eps_0_1: 0.2584\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0365 - loss: 0.0042 - within_eps_0_005: 0.0149 - within_eps_0_01: 0.0303 - within_eps_0_02: 0.0588 - within_eps_0_05: 0.1477 - within_eps_0_1: 0.2885 - val_log_cosh: 0.0810 - val_loss: 0.0057 - val_within_eps_0_005: 0.0122 - val_within_eps_0_01: 0.0251 - val_within_eps_0_02: 0.0510 - val_within_eps_0_05: 0.1327 - val_within_eps_0_1: 0.2667\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0333 - loss: 0.0040 - within_eps_0_005: 0.0154 - within_eps_0_01: 0.0311 - within_eps_0_02: 0.0625 - within_eps_0_05: 0.1550 - within_eps_0_1: 0.3014 - val_log_cosh: 0.0846 - val_loss: 0.0059 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1329 - val_within_eps_0_1: 0.2616\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0292 - loss: 0.0037 - within_eps_0_005: 0.0167 - within_eps_0_01: 0.0333 - within_eps_0_02: 0.0662 - within_eps_0_05: 0.1645 - within_eps_0_1: 0.3218 - val_log_cosh: 0.0904 - val_loss: 0.0061 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0273 - val_within_eps_0_02: 0.0550 - val_within_eps_0_05: 0.1346 - val_within_eps_0_1: 0.2574\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0263 - loss: 0.0035 - within_eps_0_005: 0.0177 - within_eps_0_01: 0.0354 - within_eps_0_02: 0.0705 - within_eps_0_05: 0.1744 - within_eps_0_1: 0.3383 - val_log_cosh: 0.0859 - val_loss: 0.0059 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0551 - val_within_eps_0_05: 0.1425 - val_within_eps_0_1: 0.2687\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0247 - loss: 0.0034 - within_eps_0_005: 0.0181 - within_eps_0_01: 0.0365 - within_eps_0_02: 0.0723 - within_eps_0_05: 0.1794 - within_eps_0_1: 0.3499 - val_log_cosh: 0.0696 - val_loss: 0.0052 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0259 - val_within_eps_0_02: 0.0516 - val_within_eps_0_05: 0.1252 - val_within_eps_0_1: 0.2542\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0213 - loss: 0.0031 - within_eps_0_005: 0.0198 - within_eps_0_01: 0.0397 - within_eps_0_02: 0.0791 - within_eps_0_05: 0.1943 - within_eps_0_1: 0.3762 - val_log_cosh: 0.0919 - val_loss: 0.0062 - val_within_eps_0_005: 0.0114 - val_within_eps_0_01: 0.0227 - val_within_eps_0_02: 0.0447 - val_within_eps_0_05: 0.1117 - val_within_eps_0_1: 0.2279\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0219 - loss: 0.0031 - within_eps_0_005: 0.0196 - within_eps_0_01: 0.0386 - within_eps_0_02: 0.0779 - within_eps_0_05: 0.1929 - within_eps_0_1: 0.3726 - val_log_cosh: 0.0812 - val_loss: 0.0057 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0546 - val_within_eps_0_05: 0.1401 - val_within_eps_0_1: 0.2818\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0175 - loss: 0.0028 - within_eps_0_005: 0.0219 - within_eps_0_01: 0.0441 - within_eps_0_02: 0.0875 - within_eps_0_05: 0.2151 - within_eps_0_1: 0.4146 - val_log_cosh: 0.0839 - val_loss: 0.0057 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0523 - val_within_eps_0_05: 0.1352 - val_within_eps_0_1: 0.2677\n",
      "  -> min val_log_cosh=0.066498689353 | min val_huber=0.005154536106\n",
      "\n",
      "--- Entrenando δ=0.02976226806640625 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - log_cosh: 0.1635 - loss: 0.0137 - within_eps_0_005: 0.0070 - within_eps_0_01: 0.0145 - within_eps_0_02: 0.0291 - within_eps_0_05: 0.0729 - within_eps_0_1: 0.1445 - val_log_cosh: 0.1301 - val_loss: 0.0116 - val_within_eps_0_005: 0.0094 - val_within_eps_0_01: 0.0186 - val_within_eps_0_02: 0.0372 - val_within_eps_0_05: 0.0938 - val_within_eps_0_1: 0.1831\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0874 - loss: 0.0099 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0182 - within_eps_0_02: 0.0360 - within_eps_0_05: 0.0911 - within_eps_0_1: 0.1810 - val_log_cosh: 0.0769 - val_loss: 0.0083 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0521 - val_within_eps_0_05: 0.1252 - val_within_eps_0_1: 0.2482\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0848 - loss: 0.0097 - within_eps_0_005: 0.0097 - within_eps_0_01: 0.0187 - within_eps_0_02: 0.0372 - within_eps_0_05: 0.0927 - within_eps_0_1: 0.1852 - val_log_cosh: 0.0665 - val_loss: 0.0075 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0302 - val_within_eps_0_02: 0.0604 - val_within_eps_0_05: 0.1439 - val_within_eps_0_1: 0.2831\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0801 - loss: 0.0094 - within_eps_0_005: 0.0100 - within_eps_0_01: 0.0194 - within_eps_0_02: 0.0388 - within_eps_0_05: 0.0961 - within_eps_0_1: 0.1911 - val_log_cosh: 0.0666 - val_loss: 0.0074 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0603 - val_within_eps_0_05: 0.1500 - val_within_eps_0_1: 0.2927\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0753 - loss: 0.0091 - within_eps_0_005: 0.0099 - within_eps_0_01: 0.0200 - within_eps_0_02: 0.0393 - within_eps_0_05: 0.0994 - within_eps_0_1: 0.1973 - val_log_cosh: 0.0723 - val_loss: 0.0078 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0578 - val_within_eps_0_05: 0.1423 - val_within_eps_0_1: 0.2820\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0690 - loss: 0.0087 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0212 - within_eps_0_02: 0.0421 - within_eps_0_05: 0.1054 - within_eps_0_1: 0.2082 - val_log_cosh: 0.0618 - val_loss: 0.0071 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0608 - val_within_eps_0_05: 0.1520 - val_within_eps_0_1: 0.2948\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0635 - loss: 0.0083 - within_eps_0_005: 0.0111 - within_eps_0_01: 0.0219 - within_eps_0_02: 0.0440 - within_eps_0_05: 0.1091 - within_eps_0_1: 0.2150 - val_log_cosh: 0.0653 - val_loss: 0.0073 - val_within_eps_0_005: 0.0193 - val_within_eps_0_01: 0.0382 - val_within_eps_0_02: 0.0736 - val_within_eps_0_05: 0.1657 - val_within_eps_0_1: 0.2986\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0581 - loss: 0.0079 - within_eps_0_005: 0.0116 - within_eps_0_01: 0.0226 - within_eps_0_02: 0.0450 - within_eps_0_05: 0.1139 - within_eps_0_1: 0.2260 - val_log_cosh: 0.0696 - val_loss: 0.0077 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0576 - val_within_eps_0_05: 0.1405 - val_within_eps_0_1: 0.2752\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0530 - loss: 0.0075 - within_eps_0_005: 0.0119 - within_eps_0_01: 0.0237 - within_eps_0_02: 0.0484 - within_eps_0_05: 0.1204 - within_eps_0_1: 0.2384 - val_log_cosh: 0.0736 - val_loss: 0.0079 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0610 - val_within_eps_0_05: 0.1525 - val_within_eps_0_1: 0.2894\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0484 - loss: 0.0071 - within_eps_0_005: 0.0130 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0502 - within_eps_0_05: 0.1246 - within_eps_0_1: 0.2482 - val_log_cosh: 0.0769 - val_loss: 0.0081 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0615 - val_within_eps_0_05: 0.1465 - val_within_eps_0_1: 0.2773\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0439 - loss: 0.0067 - within_eps_0_005: 0.0136 - within_eps_0_01: 0.0267 - within_eps_0_02: 0.0530 - within_eps_0_05: 0.1330 - within_eps_0_1: 0.2616 - val_log_cosh: 0.0743 - val_loss: 0.0079 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0298 - val_within_eps_0_02: 0.0593 - val_within_eps_0_05: 0.1424 - val_within_eps_0_1: 0.2743\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0396 - loss: 0.0064 - within_eps_0_005: 0.0136 - within_eps_0_01: 0.0271 - within_eps_0_02: 0.0545 - within_eps_0_05: 0.1387 - within_eps_0_1: 0.2730 - val_log_cosh: 0.0802 - val_loss: 0.0083 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1506 - val_within_eps_0_1: 0.2891\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0350 - loss: 0.0059 - within_eps_0_005: 0.0146 - within_eps_0_01: 0.0297 - within_eps_0_02: 0.0601 - within_eps_0_05: 0.1488 - within_eps_0_1: 0.2924 - val_log_cosh: 0.0862 - val_loss: 0.0088 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0494 - val_within_eps_0_05: 0.1268 - val_within_eps_0_1: 0.2525\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0314 - loss: 0.0056 - within_eps_0_005: 0.0157 - within_eps_0_01: 0.0315 - within_eps_0_02: 0.0636 - within_eps_0_05: 0.1581 - within_eps_0_1: 0.3090 - val_log_cosh: 0.0794 - val_loss: 0.0083 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0571 - val_within_eps_0_05: 0.1373 - val_within_eps_0_1: 0.2701\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0297 - loss: 0.0054 - within_eps_0_005: 0.0166 - within_eps_0_01: 0.0326 - within_eps_0_02: 0.0654 - within_eps_0_05: 0.1621 - within_eps_0_1: 0.3176 - val_log_cosh: 0.0860 - val_loss: 0.0089 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0523 - val_within_eps_0_05: 0.1270 - val_within_eps_0_1: 0.2431\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0265 - loss: 0.0051 - within_eps_0_005: 0.0170 - within_eps_0_01: 0.0345 - within_eps_0_02: 0.0696 - within_eps_0_05: 0.1729 - within_eps_0_1: 0.3376 - val_log_cosh: 0.0825 - val_loss: 0.0086 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0260 - val_within_eps_0_02: 0.0519 - val_within_eps_0_05: 0.1282 - val_within_eps_0_1: 0.2483\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0220 - loss: 0.0046 - within_eps_0_005: 0.0196 - within_eps_0_01: 0.0390 - within_eps_0_02: 0.0770 - within_eps_0_05: 0.1898 - within_eps_0_1: 0.3681 - val_log_cosh: 0.0948 - val_loss: 0.0096 - val_within_eps_0_005: 0.0098 - val_within_eps_0_01: 0.0201 - val_within_eps_0_02: 0.0417 - val_within_eps_0_05: 0.1097 - val_within_eps_0_1: 0.2175\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0208 - loss: 0.0044 - within_eps_0_005: 0.0200 - within_eps_0_01: 0.0399 - within_eps_0_02: 0.0802 - within_eps_0_05: 0.1975 - within_eps_0_1: 0.3818 - val_log_cosh: 0.0636 - val_loss: 0.0073 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0554 - val_within_eps_0_05: 0.1470 - val_within_eps_0_1: 0.2915\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0170 - loss: 0.0040 - within_eps_0_005: 0.0221 - within_eps_0_01: 0.0443 - within_eps_0_02: 0.0873 - within_eps_0_05: 0.2154 - within_eps_0_1: 0.4162 - val_log_cosh: 0.0723 - val_loss: 0.0080 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0291 - val_within_eps_0_02: 0.0557 - val_within_eps_0_05: 0.1353 - val_within_eps_0_1: 0.2610\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0146 - loss: 0.0036 - within_eps_0_005: 0.0237 - within_eps_0_01: 0.0477 - within_eps_0_02: 0.0950 - within_eps_0_05: 0.2335 - within_eps_0_1: 0.4462 - val_log_cosh: 0.0977 - val_loss: 0.0096 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0269 - val_within_eps_0_02: 0.0537 - val_within_eps_0_05: 0.1329 - val_within_eps_0_1: 0.2480\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0138 - loss: 0.0035 - within_eps_0_005: 0.0247 - within_eps_0_01: 0.0500 - within_eps_0_02: 0.0995 - within_eps_0_05: 0.2436 - within_eps_0_1: 0.4658 - val_log_cosh: 0.0856 - val_loss: 0.0088 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0258 - val_within_eps_0_02: 0.0522 - val_within_eps_0_05: 0.1365 - val_within_eps_0_1: 0.2679\n",
      "  -> min val_log_cosh=0.061781216413 | min val_huber=0.007059511263\n",
      "\n",
      "--- Entrenando δ=0.05 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 115ms/step - log_cosh: 0.1751 - loss: 0.0235 - within_eps_0_005: 0.0073 - within_eps_0_01: 0.0142 - within_eps_0_02: 0.0283 - within_eps_0_05: 0.0702 - within_eps_0_1: 0.1390 - val_log_cosh: 0.1358 - val_loss: 0.0197 - val_within_eps_0_005: 0.0080 - val_within_eps_0_01: 0.0158 - val_within_eps_0_02: 0.0309 - val_within_eps_0_05: 0.0770 - val_within_eps_0_1: 0.1584\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0914 - loss: 0.0165 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0181 - within_eps_0_02: 0.0363 - within_eps_0_05: 0.0901 - within_eps_0_1: 0.1783 - val_log_cosh: 0.0808 - val_loss: 0.0136 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0242 - val_within_eps_0_02: 0.0484 - val_within_eps_0_05: 0.1234 - val_within_eps_0_1: 0.2568\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0888 - loss: 0.0163 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0184 - within_eps_0_02: 0.0370 - within_eps_0_05: 0.0920 - within_eps_0_1: 0.1817 - val_log_cosh: 0.0676 - val_loss: 0.0120 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0592 - val_within_eps_0_05: 0.1463 - val_within_eps_0_1: 0.2867\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0824 - loss: 0.0156 - within_eps_0_005: 0.0098 - within_eps_0_01: 0.0193 - within_eps_0_02: 0.0382 - within_eps_0_05: 0.0944 - within_eps_0_1: 0.1875 - val_log_cosh: 0.0622 - val_loss: 0.0114 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0599 - val_within_eps_0_05: 0.1481 - val_within_eps_0_1: 0.2901\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0767 - loss: 0.0150 - within_eps_0_005: 0.0100 - within_eps_0_01: 0.0203 - within_eps_0_02: 0.0403 - within_eps_0_05: 0.0993 - within_eps_0_1: 0.1953 - val_log_cosh: 0.0646 - val_loss: 0.0117 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1493 - val_within_eps_0_1: 0.3025\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0711 - loss: 0.0143 - within_eps_0_005: 0.0104 - within_eps_0_01: 0.0208 - within_eps_0_02: 0.0416 - within_eps_0_05: 0.1034 - within_eps_0_1: 0.2041 - val_log_cosh: 0.0617 - val_loss: 0.0114 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0279 - val_within_eps_0_02: 0.0584 - val_within_eps_0_05: 0.1505 - val_within_eps_0_1: 0.2967\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0647 - loss: 0.0136 - within_eps_0_005: 0.0108 - within_eps_0_01: 0.0215 - within_eps_0_02: 0.0431 - within_eps_0_05: 0.1079 - within_eps_0_1: 0.2146 - val_log_cosh: 0.0647 - val_loss: 0.0117 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0313 - val_within_eps_0_02: 0.0635 - val_within_eps_0_05: 0.1598 - val_within_eps_0_1: 0.3064\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0600 - loss: 0.0130 - within_eps_0_005: 0.0114 - within_eps_0_01: 0.0225 - within_eps_0_02: 0.0445 - within_eps_0_05: 0.1117 - within_eps_0_1: 0.2218 - val_log_cosh: 0.0670 - val_loss: 0.0119 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0630 - val_within_eps_0_05: 0.1545 - val_within_eps_0_1: 0.3004\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0544 - loss: 0.0123 - within_eps_0_005: 0.0118 - within_eps_0_01: 0.0237 - within_eps_0_02: 0.0472 - within_eps_0_05: 0.1185 - within_eps_0_1: 0.2352 - val_log_cosh: 0.0650 - val_loss: 0.0117 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0606 - val_within_eps_0_05: 0.1521 - val_within_eps_0_1: 0.2997\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0500 - loss: 0.0117 - within_eps_0_005: 0.0124 - within_eps_0_01: 0.0250 - within_eps_0_02: 0.0498 - within_eps_0_05: 0.1245 - within_eps_0_1: 0.2457 - val_log_cosh: 0.0637 - val_loss: 0.0115 - val_within_eps_0_005: 0.0174 - val_within_eps_0_01: 0.0354 - val_within_eps_0_02: 0.0697 - val_within_eps_0_05: 0.1700 - val_within_eps_0_1: 0.3208\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0446 - loss: 0.0109 - within_eps_0_005: 0.0130 - within_eps_0_01: 0.0261 - within_eps_0_02: 0.0522 - within_eps_0_05: 0.1315 - within_eps_0_1: 0.2605 - val_log_cosh: 0.0745 - val_loss: 0.0129 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0602 - val_within_eps_0_05: 0.1513 - val_within_eps_0_1: 0.2870\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0406 - loss: 0.0104 - within_eps_0_005: 0.0136 - within_eps_0_01: 0.0276 - within_eps_0_02: 0.0550 - within_eps_0_05: 0.1370 - within_eps_0_1: 0.2723 - val_log_cosh: 0.0805 - val_loss: 0.0136 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0585 - val_within_eps_0_05: 0.1421 - val_within_eps_0_1: 0.2696\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0356 - loss: 0.0096 - within_eps_0_005: 0.0147 - within_eps_0_01: 0.0292 - within_eps_0_02: 0.0588 - within_eps_0_05: 0.1480 - within_eps_0_1: 0.2905 - val_log_cosh: 0.0789 - val_loss: 0.0134 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0300 - val_within_eps_0_02: 0.0596 - val_within_eps_0_05: 0.1474 - val_within_eps_0_1: 0.2822\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0320 - loss: 0.0090 - within_eps_0_005: 0.0161 - within_eps_0_01: 0.0321 - within_eps_0_02: 0.0641 - within_eps_0_05: 0.1572 - within_eps_0_1: 0.3067 - val_log_cosh: 0.0837 - val_loss: 0.0142 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0518 - val_within_eps_0_05: 0.1258 - val_within_eps_0_1: 0.2413\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - log_cosh: 0.0284 - loss: 0.0084 - within_eps_0_005: 0.0165 - within_eps_0_01: 0.0333 - within_eps_0_02: 0.0670 - within_eps_0_05: 0.1670 - within_eps_0_1: 0.3257 - val_log_cosh: 0.1128 - val_loss: 0.0170 - val_within_eps_0_005: 0.0102 - val_within_eps_0_01: 0.0207 - val_within_eps_0_02: 0.0427 - val_within_eps_0_05: 0.1139 - val_within_eps_0_1: 0.2370\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0266 - loss: 0.0081 - within_eps_0_005: 0.0179 - within_eps_0_01: 0.0354 - within_eps_0_02: 0.0708 - within_eps_0_05: 0.1736 - within_eps_0_1: 0.3370 - val_log_cosh: 0.0912 - val_loss: 0.0149 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0258 - val_within_eps_0_02: 0.0514 - val_within_eps_0_05: 0.1262 - val_within_eps_0_1: 0.2492\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0230 - loss: 0.0074 - within_eps_0_005: 0.0187 - within_eps_0_01: 0.0375 - within_eps_0_02: 0.0751 - within_eps_0_05: 0.1862 - within_eps_0_1: 0.3625 - val_log_cosh: 0.0747 - val_loss: 0.0131 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0264 - val_within_eps_0_02: 0.0538 - val_within_eps_0_05: 0.1312 - val_within_eps_0_1: 0.2542\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0199 - loss: 0.0068 - within_eps_0_005: 0.0205 - within_eps_0_01: 0.0405 - within_eps_0_02: 0.0814 - within_eps_0_05: 0.2009 - within_eps_0_1: 0.3882 - val_log_cosh: 0.0593 - val_loss: 0.0110 - val_within_eps_0_005: 0.0186 - val_within_eps_0_01: 0.0364 - val_within_eps_0_02: 0.0736 - val_within_eps_0_05: 0.1841 - val_within_eps_0_1: 0.3408\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0175 - loss: 0.0063 - within_eps_0_005: 0.0215 - within_eps_0_01: 0.0432 - within_eps_0_02: 0.0864 - within_eps_0_05: 0.2144 - within_eps_0_1: 0.4131 - val_log_cosh: 0.1024 - val_loss: 0.0163 - val_within_eps_0_005: 0.0114 - val_within_eps_0_01: 0.0228 - val_within_eps_0_02: 0.0455 - val_within_eps_0_05: 0.1143 - val_within_eps_0_1: 0.2204\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0164 - loss: 0.0060 - within_eps_0_005: 0.0222 - within_eps_0_01: 0.0452 - within_eps_0_02: 0.0905 - within_eps_0_05: 0.2240 - within_eps_0_1: 0.4285 - val_log_cosh: 0.0706 - val_loss: 0.0123 - val_within_eps_0_005: 0.0179 - val_within_eps_0_01: 0.0355 - val_within_eps_0_02: 0.0707 - val_within_eps_0_05: 0.1762 - val_within_eps_0_1: 0.3265\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - log_cosh: 0.0127 - loss: 0.0052 - within_eps_0_005: 0.0260 - within_eps_0_01: 0.0517 - within_eps_0_02: 0.1026 - within_eps_0_05: 0.2517 - within_eps_0_1: 0.4790 - val_log_cosh: 0.0860 - val_loss: 0.0143 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0330 - val_within_eps_0_02: 0.0647 - val_within_eps_0_05: 0.1537 - val_within_eps_0_1: 0.2747\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0103 - loss: 0.0045 - within_eps_0_005: 0.0288 - within_eps_0_01: 0.0584 - within_eps_0_02: 0.1157 - within_eps_0_05: 0.2818 - within_eps_0_1: 0.5276 - val_log_cosh: 0.1740 - val_loss: 0.0228 - val_within_eps_0_005: 0.0070 - val_within_eps_0_01: 0.0146 - val_within_eps_0_02: 0.0285 - val_within_eps_0_05: 0.0705 - val_within_eps_0_1: 0.1492\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0105 - loss: 0.0046 - within_eps_0_005: 0.0290 - within_eps_0_01: 0.0575 - within_eps_0_02: 0.1150 - within_eps_0_05: 0.2824 - within_eps_0_1: 0.5278 - val_log_cosh: 0.0761 - val_loss: 0.0133 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0333 - val_within_eps_0_02: 0.0648 - val_within_eps_0_05: 0.1561 - val_within_eps_0_1: 0.2781\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0090 - loss: 0.0041 - within_eps_0_005: 0.0313 - within_eps_0_01: 0.0624 - within_eps_0_02: 0.1258 - within_eps_0_05: 0.3093 - within_eps_0_1: 0.5689 - val_log_cosh: 0.0856 - val_loss: 0.0146 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0593 - val_within_eps_0_05: 0.1414 - val_within_eps_0_1: 0.2526\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0069 - loss: 0.0035 - within_eps_0_005: 0.0357 - within_eps_0_01: 0.0715 - within_eps_0_02: 0.1420 - within_eps_0_05: 0.3437 - within_eps_0_1: 0.6217 - val_log_cosh: 0.1080 - val_loss: 0.0173 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0512 - val_within_eps_0_05: 0.1225 - val_within_eps_0_1: 0.2148\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0060 - loss: 0.0032 - within_eps_0_005: 0.0389 - within_eps_0_01: 0.0786 - within_eps_0_02: 0.1569 - within_eps_0_05: 0.3787 - within_eps_0_1: 0.6686 - val_log_cosh: 0.0875 - val_loss: 0.0147 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0467 - val_within_eps_0_05: 0.1116 - val_within_eps_0_1: 0.2157\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0063 - loss: 0.0032 - within_eps_0_005: 0.0388 - within_eps_0_01: 0.0772 - within_eps_0_02: 0.1538 - within_eps_0_05: 0.3721 - within_eps_0_1: 0.6628 - val_log_cosh: 0.1150 - val_loss: 0.0180 - val_within_eps_0_005: 0.0096 - val_within_eps_0_01: 0.0198 - val_within_eps_0_02: 0.0397 - val_within_eps_0_05: 0.1010 - val_within_eps_0_1: 0.1962\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0042 - loss: 0.0025 - within_eps_0_005: 0.0462 - within_eps_0_01: 0.0930 - within_eps_0_02: 0.1850 - within_eps_0_05: 0.4419 - within_eps_0_1: 0.7480 - val_log_cosh: 0.1218 - val_loss: 0.0186 - val_within_eps_0_005: 0.0101 - val_within_eps_0_01: 0.0199 - val_within_eps_0_02: 0.0393 - val_within_eps_0_05: 0.0947 - val_within_eps_0_1: 0.1812\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0057 - loss: 0.0031 - within_eps_0_005: 0.0416 - within_eps_0_01: 0.0824 - within_eps_0_02: 0.1626 - within_eps_0_05: 0.3886 - within_eps_0_1: 0.6791 - val_log_cosh: 0.1375 - val_loss: 0.0207 - val_within_eps_0_005: 0.0069 - val_within_eps_0_01: 0.0141 - val_within_eps_0_02: 0.0288 - val_within_eps_0_05: 0.0741 - val_within_eps_0_1: 0.1467\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0060 - loss: 0.0030 - within_eps_0_005: 0.0447 - within_eps_0_01: 0.0889 - within_eps_0_02: 0.1774 - within_eps_0_05: 0.4169 - within_eps_0_1: 0.7009 - val_log_cosh: 0.1545 - val_loss: 0.0220 - val_within_eps_0_005: 0.0068 - val_within_eps_0_01: 0.0137 - val_within_eps_0_02: 0.0275 - val_within_eps_0_05: 0.0715 - val_within_eps_0_1: 0.1454\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0041 - loss: 0.0024 - within_eps_0_005: 0.0494 - within_eps_0_01: 0.0981 - within_eps_0_02: 0.1937 - within_eps_0_05: 0.4579 - within_eps_0_1: 0.7623 - val_log_cosh: 0.2827 - val_loss: 0.0342 - val_within_eps_0_005: 0.0011 - val_within_eps_0_01: 0.0025 - val_within_eps_0_02: 0.0055 - val_within_eps_0_05: 0.0156 - val_within_eps_0_1: 0.0304\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0052 - loss: 0.0028 - within_eps_0_005: 0.0449 - within_eps_0_01: 0.0898 - within_eps_0_02: 0.1775 - within_eps_0_05: 0.4252 - within_eps_0_1: 0.7229 - val_log_cosh: 0.2168 - val_loss: 0.0279 - val_within_eps_0_005: 0.0026 - val_within_eps_0_01: 0.0049 - val_within_eps_0_02: 0.0101 - val_within_eps_0_05: 0.0284 - val_within_eps_0_1: 0.0720\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - log_cosh: 0.0040 - loss: 0.0024 - within_eps_0_005: 0.0496 - within_eps_0_01: 0.0986 - within_eps_0_02: 0.1965 - within_eps_0_05: 0.4631 - within_eps_0_1: 0.7700 - val_log_cosh: 0.1263 - val_loss: 0.0184 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0225 - val_within_eps_0_02: 0.0445 - val_within_eps_0_05: 0.1109 - val_within_eps_0_1: 0.2223\n",
      "  -> min val_log_cosh=0.059345129877 | min val_huber=0.010994167067\n",
      "\n",
      "--- Entrenando δ=0.051824706792831444 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 116ms/step - log_cosh: 0.1644 - loss: 0.0234 - within_eps_0_005: 0.0074 - within_eps_0_01: 0.0147 - within_eps_0_02: 0.0294 - within_eps_0_05: 0.0728 - within_eps_0_1: 0.1445 - val_log_cosh: 0.1278 - val_loss: 0.0191 - val_within_eps_0_005: 0.0090 - val_within_eps_0_01: 0.0187 - val_within_eps_0_02: 0.0384 - val_within_eps_0_05: 0.0952 - val_within_eps_0_1: 0.1900\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0889 - loss: 0.0168 - within_eps_0_005: 0.0088 - within_eps_0_01: 0.0179 - within_eps_0_02: 0.0358 - within_eps_0_05: 0.0911 - within_eps_0_1: 0.1823 - val_log_cosh: 0.0824 - val_loss: 0.0146 - val_within_eps_0_005: 0.0102 - val_within_eps_0_01: 0.0204 - val_within_eps_0_02: 0.0434 - val_within_eps_0_05: 0.1125 - val_within_eps_0_1: 0.2279\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0831 - loss: 0.0162 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0186 - within_eps_0_02: 0.0379 - within_eps_0_05: 0.0945 - within_eps_0_1: 0.1875 - val_log_cosh: 0.0761 - val_loss: 0.0137 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0551 - val_within_eps_0_05: 0.1314 - val_within_eps_0_1: 0.2549\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0786 - loss: 0.0157 - within_eps_0_005: 0.0097 - within_eps_0_01: 0.0193 - within_eps_0_02: 0.0386 - within_eps_0_05: 0.0969 - within_eps_0_1: 0.1916 - val_log_cosh: 0.0690 - val_loss: 0.0127 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0536 - val_within_eps_0_05: 0.1385 - val_within_eps_0_1: 0.2767\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - log_cosh: 0.0722 - loss: 0.0149 - within_eps_0_005: 0.0101 - within_eps_0_01: 0.0201 - within_eps_0_02: 0.0398 - within_eps_0_05: 0.1009 - within_eps_0_1: 0.2010 - val_log_cosh: 0.0635 - val_loss: 0.0120 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0605 - val_within_eps_0_05: 0.1487 - val_within_eps_0_1: 0.2875\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0667 - loss: 0.0143 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0211 - within_eps_0_02: 0.0419 - within_eps_0_05: 0.1053 - within_eps_0_1: 0.2105 - val_log_cosh: 0.0590 - val_loss: 0.0115 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0626 - val_within_eps_0_05: 0.1610 - val_within_eps_0_1: 0.3103\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0621 - loss: 0.0137 - within_eps_0_005: 0.0110 - within_eps_0_01: 0.0220 - within_eps_0_02: 0.0437 - within_eps_0_05: 0.1095 - within_eps_0_1: 0.2193 - val_log_cosh: 0.0596 - val_loss: 0.0117 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0289 - val_within_eps_0_02: 0.0595 - val_within_eps_0_05: 0.1498 - val_within_eps_0_1: 0.2930\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0569 - loss: 0.0130 - within_eps_0_005: 0.0114 - within_eps_0_01: 0.0230 - within_eps_0_02: 0.0463 - within_eps_0_05: 0.1153 - within_eps_0_1: 0.2290 - val_log_cosh: 0.0611 - val_loss: 0.0117 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0300 - val_within_eps_0_02: 0.0603 - val_within_eps_0_05: 0.1527 - val_within_eps_0_1: 0.3035\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0531 - loss: 0.0125 - within_eps_0_005: 0.0120 - within_eps_0_01: 0.0234 - within_eps_0_02: 0.0477 - within_eps_0_05: 0.1194 - within_eps_0_1: 0.2359 - val_log_cosh: 0.0675 - val_loss: 0.0125 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0606 - val_within_eps_0_05: 0.1454 - val_within_eps_0_1: 0.2853\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0477 - loss: 0.0117 - within_eps_0_005: 0.0127 - within_eps_0_01: 0.0256 - within_eps_0_02: 0.0510 - within_eps_0_05: 0.1280 - within_eps_0_1: 0.2509 - val_log_cosh: 0.0694 - val_loss: 0.0123 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0357 - val_within_eps_0_02: 0.0718 - val_within_eps_0_05: 0.1812 - val_within_eps_0_1: 0.3332\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0428 - loss: 0.0110 - within_eps_0_005: 0.0134 - within_eps_0_01: 0.0267 - within_eps_0_02: 0.0538 - within_eps_0_05: 0.1347 - within_eps_0_1: 0.2653 - val_log_cosh: 0.0774 - val_loss: 0.0136 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0324 - val_within_eps_0_02: 0.0635 - val_within_eps_0_05: 0.1521 - val_within_eps_0_1: 0.2894\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0392 - loss: 0.0105 - within_eps_0_005: 0.0141 - within_eps_0_01: 0.0278 - within_eps_0_02: 0.0556 - within_eps_0_05: 0.1404 - within_eps_0_1: 0.2769 - val_log_cosh: 0.0852 - val_loss: 0.0145 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1453 - val_within_eps_0_1: 0.2833\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0349 - loss: 0.0098 - within_eps_0_005: 0.0147 - within_eps_0_01: 0.0290 - within_eps_0_02: 0.0586 - within_eps_0_05: 0.1474 - within_eps_0_1: 0.2923 - val_log_cosh: 0.0865 - val_loss: 0.0146 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0575 - val_within_eps_0_05: 0.1413 - val_within_eps_0_1: 0.2676\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0311 - loss: 0.0092 - within_eps_0_005: 0.0162 - within_eps_0_01: 0.0317 - within_eps_0_02: 0.0637 - within_eps_0_05: 0.1584 - within_eps_0_1: 0.3119 - val_log_cosh: 0.0926 - val_loss: 0.0154 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0543 - val_within_eps_0_05: 0.1305 - val_within_eps_0_1: 0.2552\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0272 - loss: 0.0085 - within_eps_0_005: 0.0169 - within_eps_0_01: 0.0343 - within_eps_0_02: 0.0684 - within_eps_0_05: 0.1695 - within_eps_0_1: 0.3310 - val_log_cosh: 0.1030 - val_loss: 0.0168 - val_within_eps_0_005: 0.0121 - val_within_eps_0_01: 0.0241 - val_within_eps_0_02: 0.0473 - val_within_eps_0_05: 0.1120 - val_within_eps_0_1: 0.2224\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0245 - loss: 0.0079 - within_eps_0_005: 0.0181 - within_eps_0_01: 0.0362 - within_eps_0_02: 0.0720 - within_eps_0_05: 0.1797 - within_eps_0_1: 0.3503 - val_log_cosh: 0.1110 - val_loss: 0.0176 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0224 - val_within_eps_0_02: 0.0452 - val_within_eps_0_05: 0.1149 - val_within_eps_0_1: 0.2260\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0210 - loss: 0.0073 - within_eps_0_005: 0.0197 - within_eps_0_01: 0.0395 - within_eps_0_02: 0.0790 - within_eps_0_05: 0.1941 - within_eps_0_1: 0.3762 - val_log_cosh: 0.0645 - val_loss: 0.0122 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0557 - val_within_eps_0_05: 0.1456 - val_within_eps_0_1: 0.2926\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0187 - loss: 0.0068 - within_eps_0_005: 0.0210 - within_eps_0_01: 0.0417 - within_eps_0_02: 0.0833 - within_eps_0_05: 0.2066 - within_eps_0_1: 0.3985 - val_log_cosh: 0.0919 - val_loss: 0.0155 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0555 - val_within_eps_0_05: 0.1360 - val_within_eps_0_1: 0.2503\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0182 - loss: 0.0067 - within_eps_0_005: 0.0212 - within_eps_0_01: 0.0425 - within_eps_0_02: 0.0845 - within_eps_0_05: 0.2093 - within_eps_0_1: 0.4035 - val_log_cosh: 0.0790 - val_loss: 0.0135 - val_within_eps_0_005: 0.0183 - val_within_eps_0_01: 0.0366 - val_within_eps_0_02: 0.0712 - val_within_eps_0_05: 0.1692 - val_within_eps_0_1: 0.3120\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0147 - loss: 0.0059 - within_eps_0_005: 0.0235 - within_eps_0_01: 0.0468 - within_eps_0_02: 0.0940 - within_eps_0_05: 0.2330 - within_eps_0_1: 0.4444 - val_log_cosh: 0.0814 - val_loss: 0.0140 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0308 - val_within_eps_0_02: 0.0610 - val_within_eps_0_05: 0.1468 - val_within_eps_0_1: 0.2881\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0116 - loss: 0.0051 - within_eps_0_005: 0.0263 - within_eps_0_01: 0.0533 - within_eps_0_02: 0.1066 - within_eps_0_05: 0.2614 - within_eps_0_1: 0.4952 - val_log_cosh: 0.1018 - val_loss: 0.0170 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0217 - val_within_eps_0_02: 0.0428 - val_within_eps_0_05: 0.1021 - val_within_eps_0_1: 0.2080\n",
      "  -> min val_log_cosh=0.059031356126 | min val_huber=0.011455063708\n",
      "\n",
      "--- Entrenando δ=0.07143068313598633 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 117ms/step - log_cosh: 0.1817 - loss: 0.0336 - within_eps_0_005: 0.0069 - within_eps_0_01: 0.0139 - within_eps_0_02: 0.0279 - within_eps_0_05: 0.0694 - within_eps_0_1: 0.1371 - val_log_cosh: 0.1327 - val_loss: 0.0268 - val_within_eps_0_005: 0.0099 - val_within_eps_0_01: 0.0194 - val_within_eps_0_02: 0.0389 - val_within_eps_0_05: 0.0941 - val_within_eps_0_1: 0.1792\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0926 - loss: 0.0231 - within_eps_0_005: 0.0085 - within_eps_0_01: 0.0176 - within_eps_0_02: 0.0355 - within_eps_0_05: 0.0895 - within_eps_0_1: 0.1781 - val_log_cosh: 0.0791 - val_loss: 0.0190 - val_within_eps_0_005: 0.0110 - val_within_eps_0_01: 0.0230 - val_within_eps_0_02: 0.0456 - val_within_eps_0_05: 0.1111 - val_within_eps_0_1: 0.2278\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0886 - loss: 0.0225 - within_eps_0_005: 0.0094 - within_eps_0_01: 0.0184 - within_eps_0_02: 0.0371 - within_eps_0_05: 0.0926 - within_eps_0_1: 0.1832 - val_log_cosh: 0.0656 - val_loss: 0.0166 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0567 - val_within_eps_0_05: 0.1392 - val_within_eps_0_1: 0.2718\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0829 - loss: 0.0216 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0194 - within_eps_0_02: 0.0383 - within_eps_0_05: 0.0948 - within_eps_0_1: 0.1881 - val_log_cosh: 0.0681 - val_loss: 0.0168 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0281 - val_within_eps_0_02: 0.0566 - val_within_eps_0_05: 0.1454 - val_within_eps_0_1: 0.2814\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0780 - loss: 0.0209 - within_eps_0_005: 0.0097 - within_eps_0_01: 0.0194 - within_eps_0_02: 0.0384 - within_eps_0_05: 0.0971 - within_eps_0_1: 0.1933 - val_log_cosh: 0.0646 - val_loss: 0.0163 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0554 - val_within_eps_0_05: 0.1447 - val_within_eps_0_1: 0.2830\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0710 - loss: 0.0197 - within_eps_0_005: 0.0102 - within_eps_0_01: 0.0206 - within_eps_0_02: 0.0408 - within_eps_0_05: 0.1028 - within_eps_0_1: 0.2033 - val_log_cosh: 0.0666 - val_loss: 0.0166 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0319 - val_within_eps_0_02: 0.0646 - val_within_eps_0_05: 0.1501 - val_within_eps_0_1: 0.2877\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0649 - loss: 0.0187 - within_eps_0_005: 0.0105 - within_eps_0_01: 0.0214 - within_eps_0_02: 0.0428 - within_eps_0_05: 0.1076 - within_eps_0_1: 0.2127 - val_log_cosh: 0.0639 - val_loss: 0.0160 - val_within_eps_0_005: 0.0167 - val_within_eps_0_01: 0.0336 - val_within_eps_0_02: 0.0668 - val_within_eps_0_05: 0.1574 - val_within_eps_0_1: 0.2968\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0585 - loss: 0.0176 - within_eps_0_005: 0.0116 - within_eps_0_01: 0.0226 - within_eps_0_02: 0.0455 - within_eps_0_05: 0.1136 - within_eps_0_1: 0.2251 - val_log_cosh: 0.0717 - val_loss: 0.0172 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0585 - val_within_eps_0_05: 0.1469 - val_within_eps_0_1: 0.2890\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0540 - loss: 0.0168 - within_eps_0_005: 0.0120 - within_eps_0_01: 0.0234 - within_eps_0_02: 0.0469 - within_eps_0_05: 0.1168 - within_eps_0_1: 0.2334 - val_log_cosh: 0.0695 - val_loss: 0.0168 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0299 - val_within_eps_0_02: 0.0591 - val_within_eps_0_05: 0.1512 - val_within_eps_0_1: 0.3016\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0486 - loss: 0.0157 - within_eps_0_005: 0.0123 - within_eps_0_01: 0.0252 - within_eps_0_02: 0.0502 - within_eps_0_05: 0.1255 - within_eps_0_1: 0.2470 - val_log_cosh: 0.0725 - val_loss: 0.0174 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1469 - val_within_eps_0_1: 0.2892\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0440 - loss: 0.0148 - within_eps_0_005: 0.0135 - within_eps_0_01: 0.0265 - within_eps_0_02: 0.0534 - within_eps_0_05: 0.1324 - within_eps_0_1: 0.2630 - val_log_cosh: 0.0707 - val_loss: 0.0171 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0300 - val_within_eps_0_02: 0.0587 - val_within_eps_0_05: 0.1453 - val_within_eps_0_1: 0.2812\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0388 - loss: 0.0137 - within_eps_0_005: 0.0142 - within_eps_0_01: 0.0283 - within_eps_0_02: 0.0569 - within_eps_0_05: 0.1412 - within_eps_0_1: 0.2784 - val_log_cosh: 0.0723 - val_loss: 0.0173 - val_within_eps_0_005: 0.0166 - val_within_eps_0_01: 0.0329 - val_within_eps_0_02: 0.0661 - val_within_eps_0_05: 0.1637 - val_within_eps_0_1: 0.3102\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0346 - loss: 0.0128 - within_eps_0_005: 0.0153 - within_eps_0_01: 0.0305 - within_eps_0_02: 0.0612 - within_eps_0_05: 0.1507 - within_eps_0_1: 0.2952 - val_log_cosh: 0.0784 - val_loss: 0.0182 - val_within_eps_0_005: 0.0180 - val_within_eps_0_01: 0.0355 - val_within_eps_0_02: 0.0713 - val_within_eps_0_05: 0.1692 - val_within_eps_0_1: 0.3077\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0306 - loss: 0.0119 - within_eps_0_005: 0.0161 - within_eps_0_01: 0.0319 - within_eps_0_02: 0.0645 - within_eps_0_05: 0.1597 - within_eps_0_1: 0.3128 - val_log_cosh: 0.0797 - val_loss: 0.0184 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1538 - val_within_eps_0_1: 0.2988\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0267 - loss: 0.0109 - within_eps_0_005: 0.0172 - within_eps_0_01: 0.0342 - within_eps_0_02: 0.0694 - within_eps_0_05: 0.1709 - within_eps_0_1: 0.3349 - val_log_cosh: 0.0853 - val_loss: 0.0194 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0311 - val_within_eps_0_02: 0.0613 - val_within_eps_0_05: 0.1462 - val_within_eps_0_1: 0.2791\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0236 - loss: 0.0101 - within_eps_0_005: 0.0188 - within_eps_0_01: 0.0371 - within_eps_0_02: 0.0738 - within_eps_0_05: 0.1833 - within_eps_0_1: 0.3570 - val_log_cosh: 0.0819 - val_loss: 0.0188 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0575 - val_within_eps_0_05: 0.1433 - val_within_eps_0_1: 0.2858\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0201 - loss: 0.0092 - within_eps_0_005: 0.0199 - within_eps_0_01: 0.0401 - within_eps_0_02: 0.0802 - within_eps_0_05: 0.1986 - within_eps_0_1: 0.3838 - val_log_cosh: 0.0990 - val_loss: 0.0218 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0230 - val_within_eps_0_02: 0.0477 - val_within_eps_0_05: 0.1227 - val_within_eps_0_1: 0.2384\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0178 - loss: 0.0085 - within_eps_0_005: 0.0212 - within_eps_0_01: 0.0425 - within_eps_0_02: 0.0846 - within_eps_0_05: 0.2110 - within_eps_0_1: 0.4072 - val_log_cosh: 0.0822 - val_loss: 0.0192 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0310 - val_within_eps_0_02: 0.0619 - val_within_eps_0_05: 0.1441 - val_within_eps_0_1: 0.2693\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0161 - loss: 0.0079 - within_eps_0_005: 0.0232 - within_eps_0_01: 0.0453 - within_eps_0_02: 0.0901 - within_eps_0_05: 0.2238 - within_eps_0_1: 0.4282 - val_log_cosh: 0.1104 - val_loss: 0.0240 - val_within_eps_0_005: 0.0103 - val_within_eps_0_01: 0.0208 - val_within_eps_0_02: 0.0419 - val_within_eps_0_05: 0.1041 - val_within_eps_0_1: 0.2115\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0157 - loss: 0.0078 - within_eps_0_005: 0.0231 - within_eps_0_01: 0.0456 - within_eps_0_02: 0.0921 - within_eps_0_05: 0.2277 - within_eps_0_1: 0.4351 - val_log_cosh: 0.0792 - val_loss: 0.0186 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0519 - val_within_eps_0_05: 0.1344 - val_within_eps_0_1: 0.2719\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0148 - loss: 0.0074 - within_eps_0_005: 0.0238 - within_eps_0_01: 0.0482 - within_eps_0_02: 0.0962 - within_eps_0_05: 0.2385 - within_eps_0_1: 0.4543 - val_log_cosh: 0.1043 - val_loss: 0.0226 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0244 - val_within_eps_0_02: 0.0482 - val_within_eps_0_05: 0.1184 - val_within_eps_0_1: 0.2217\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0112 - loss: 0.0063 - within_eps_0_005: 0.0274 - within_eps_0_01: 0.0550 - within_eps_0_02: 0.1102 - within_eps_0_05: 0.2688 - within_eps_0_1: 0.5054 - val_log_cosh: 0.1388 - val_loss: 0.0285 - val_within_eps_0_005: 0.0066 - val_within_eps_0_01: 0.0125 - val_within_eps_0_02: 0.0246 - val_within_eps_0_05: 0.0658 - val_within_eps_0_1: 0.1426\n",
      "  -> min val_log_cosh=0.063935145736 | min val_huber=0.016042359173\n",
      "\n",
      "--- Entrenando δ=0.1 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - log_cosh: 0.1653 - loss: 0.0434 - within_eps_0_005: 0.0072 - within_eps_0_01: 0.0142 - within_eps_0_02: 0.0280 - within_eps_0_05: 0.0702 - within_eps_0_1: 0.1399 - val_log_cosh: 0.1160 - val_loss: 0.0320 - val_within_eps_0_005: 0.0099 - val_within_eps_0_01: 0.0198 - val_within_eps_0_02: 0.0401 - val_within_eps_0_05: 0.1000 - val_within_eps_0_1: 0.2080\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0920 - loss: 0.0309 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0178 - within_eps_0_02: 0.0357 - within_eps_0_05: 0.0895 - within_eps_0_1: 0.1783 - val_log_cosh: 0.0721 - val_loss: 0.0232 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0278 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1362 - val_within_eps_0_1: 0.2640\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0862 - loss: 0.0297 - within_eps_0_005: 0.0093 - within_eps_0_01: 0.0188 - within_eps_0_02: 0.0374 - within_eps_0_05: 0.0929 - within_eps_0_1: 0.1853 - val_log_cosh: 0.0634 - val_loss: 0.0213 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0565 - val_within_eps_0_05: 0.1454 - val_within_eps_0_1: 0.2810\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0804 - loss: 0.0285 - within_eps_0_005: 0.0096 - within_eps_0_01: 0.0194 - within_eps_0_02: 0.0386 - within_eps_0_05: 0.0963 - within_eps_0_1: 0.1902 - val_log_cosh: 0.0661 - val_loss: 0.0218 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0549 - val_within_eps_0_05: 0.1428 - val_within_eps_0_1: 0.2790\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0743 - loss: 0.0272 - within_eps_0_005: 0.0099 - within_eps_0_01: 0.0198 - within_eps_0_02: 0.0398 - within_eps_0_05: 0.0984 - within_eps_0_1: 0.1965 - val_log_cosh: 0.0603 - val_loss: 0.0202 - val_within_eps_0_005: 0.0163 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0646 - val_within_eps_0_05: 0.1607 - val_within_eps_0_1: 0.3082\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0687 - loss: 0.0258 - within_eps_0_005: 0.0106 - within_eps_0_01: 0.0211 - within_eps_0_02: 0.0417 - within_eps_0_05: 0.1052 - within_eps_0_1: 0.2077 - val_log_cosh: 0.0568 - val_loss: 0.0195 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0318 - val_within_eps_0_02: 0.0648 - val_within_eps_0_05: 0.1623 - val_within_eps_0_1: 0.3150\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0613 - loss: 0.0240 - within_eps_0_005: 0.0114 - within_eps_0_01: 0.0226 - within_eps_0_02: 0.0450 - within_eps_0_05: 0.1114 - within_eps_0_1: 0.2204 - val_log_cosh: 0.0615 - val_loss: 0.0206 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0635 - val_within_eps_0_05: 0.1538 - val_within_eps_0_1: 0.2973\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0560 - loss: 0.0227 - within_eps_0_005: 0.0117 - within_eps_0_01: 0.0234 - within_eps_0_02: 0.0467 - within_eps_0_05: 0.1161 - within_eps_0_1: 0.2296 - val_log_cosh: 0.0586 - val_loss: 0.0198 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0311 - val_within_eps_0_02: 0.0608 - val_within_eps_0_05: 0.1575 - val_within_eps_0_1: 0.3100\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0512 - loss: 0.0215 - within_eps_0_005: 0.0120 - within_eps_0_01: 0.0241 - within_eps_0_02: 0.0493 - within_eps_0_05: 0.1224 - within_eps_0_1: 0.2412 - val_log_cosh: 0.0613 - val_loss: 0.0206 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0580 - val_within_eps_0_05: 0.1456 - val_within_eps_0_1: 0.2857\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0454 - loss: 0.0199 - within_eps_0_005: 0.0133 - within_eps_0_01: 0.0263 - within_eps_0_02: 0.0524 - within_eps_0_05: 0.1308 - within_eps_0_1: 0.2562 - val_log_cosh: 0.0619 - val_loss: 0.0207 - val_within_eps_0_005: 0.0159 - val_within_eps_0_01: 0.0313 - val_within_eps_0_02: 0.0615 - val_within_eps_0_05: 0.1522 - val_within_eps_0_1: 0.3011\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - log_cosh: 0.0405 - loss: 0.0186 - within_eps_0_005: 0.0142 - within_eps_0_01: 0.0281 - within_eps_0_02: 0.0558 - within_eps_0_05: 0.1373 - within_eps_0_1: 0.2708 - val_log_cosh: 0.0605 - val_loss: 0.0201 - val_within_eps_0_005: 0.0179 - val_within_eps_0_01: 0.0357 - val_within_eps_0_02: 0.0712 - val_within_eps_0_05: 0.1747 - val_within_eps_0_1: 0.3288\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0370 - loss: 0.0175 - within_eps_0_005: 0.0149 - within_eps_0_01: 0.0295 - within_eps_0_02: 0.0588 - within_eps_0_05: 0.1457 - within_eps_0_1: 0.2844 - val_log_cosh: 0.0613 - val_loss: 0.0204 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0339 - val_within_eps_0_02: 0.0678 - val_within_eps_0_05: 0.1686 - val_within_eps_0_1: 0.3128\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - log_cosh: 0.0328 - loss: 0.0162 - within_eps_0_005: 0.0155 - within_eps_0_01: 0.0309 - within_eps_0_02: 0.0620 - within_eps_0_05: 0.1545 - within_eps_0_1: 0.3028 - val_log_cosh: 0.0676 - val_loss: 0.0222 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0346 - val_within_eps_0_02: 0.0671 - val_within_eps_0_05: 0.1592 - val_within_eps_0_1: 0.2978\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0287 - loss: 0.0149 - within_eps_0_005: 0.0165 - within_eps_0_01: 0.0332 - within_eps_0_02: 0.0670 - within_eps_0_05: 0.1655 - within_eps_0_1: 0.3234 - val_log_cosh: 0.0707 - val_loss: 0.0229 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0326 - val_within_eps_0_02: 0.0648 - val_within_eps_0_05: 0.1535 - val_within_eps_0_1: 0.2930\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0251 - loss: 0.0136 - within_eps_0_005: 0.0178 - within_eps_0_01: 0.0358 - within_eps_0_02: 0.0714 - within_eps_0_05: 0.1767 - within_eps_0_1: 0.3461 - val_log_cosh: 0.0740 - val_loss: 0.0236 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0628 - val_within_eps_0_05: 0.1549 - val_within_eps_0_1: 0.2923\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0215 - loss: 0.0123 - within_eps_0_005: 0.0195 - within_eps_0_01: 0.0389 - within_eps_0_02: 0.0774 - within_eps_0_05: 0.1916 - within_eps_0_1: 0.3718 - val_log_cosh: 0.0778 - val_loss: 0.0244 - val_within_eps_0_005: 0.0168 - val_within_eps_0_01: 0.0342 - val_within_eps_0_02: 0.0662 - val_within_eps_0_05: 0.1584 - val_within_eps_0_1: 0.2921\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0190 - loss: 0.0113 - within_eps_0_005: 0.0209 - within_eps_0_01: 0.0414 - within_eps_0_02: 0.0826 - within_eps_0_05: 0.2037 - within_eps_0_1: 0.3943 - val_log_cosh: 0.0672 - val_loss: 0.0218 - val_within_eps_0_005: 0.0175 - val_within_eps_0_01: 0.0351 - val_within_eps_0_02: 0.0711 - val_within_eps_0_05: 0.1783 - val_within_eps_0_1: 0.3251\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0174 - loss: 0.0106 - within_eps_0_005: 0.0220 - within_eps_0_01: 0.0436 - within_eps_0_02: 0.0866 - within_eps_0_05: 0.2137 - within_eps_0_1: 0.4115 - val_log_cosh: 0.0735 - val_loss: 0.0237 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0308 - val_within_eps_0_02: 0.0622 - val_within_eps_0_05: 0.1524 - val_within_eps_0_1: 0.2875\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0161 - loss: 0.0100 - within_eps_0_005: 0.0230 - within_eps_0_01: 0.0466 - within_eps_0_02: 0.0914 - within_eps_0_05: 0.2253 - within_eps_0_1: 0.4316 - val_log_cosh: 0.0686 - val_loss: 0.0221 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0315 - val_within_eps_0_02: 0.0647 - val_within_eps_0_05: 0.1654 - val_within_eps_0_1: 0.3108\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0135 - loss: 0.0089 - within_eps_0_005: 0.0250 - within_eps_0_01: 0.0493 - within_eps_0_02: 0.0990 - within_eps_0_05: 0.2439 - within_eps_0_1: 0.4637 - val_log_cosh: 0.0852 - val_loss: 0.0257 - val_within_eps_0_005: 0.0110 - val_within_eps_0_01: 0.0227 - val_within_eps_0_02: 0.0475 - val_within_eps_0_05: 0.1239 - val_within_eps_0_1: 0.2511\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - log_cosh: 0.0159 - loss: 0.0098 - within_eps_0_005: 0.0238 - within_eps_0_01: 0.0474 - within_eps_0_02: 0.0945 - within_eps_0_05: 0.2314 - within_eps_0_1: 0.4422 - val_log_cosh: 0.1432 - val_loss: 0.0367 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0219 - val_within_eps_0_02: 0.0434 - val_within_eps_0_05: 0.1065 - val_within_eps_0_1: 0.2024\n",
      "  -> min val_log_cosh=0.056828793138 | min val_huber=0.019490720704\n",
      "\n",
      "Tabla val_log_cosh(min) por δ (orden asc):\n",
      "  δ=     0.1: val_log_cosh=0.056828793138 | val_huber=0.019490720704\n",
      "  δ=0.0518247: val_log_cosh=0.059031356126 | val_huber=0.011455063708\n",
      "  δ=    0.05: val_log_cosh=0.059345129877 | val_huber=0.010994167067\n",
      "  δ=0.0297623: val_log_cosh=0.061781216413 | val_huber=0.007059511263\n",
      "  δ=    0.01: val_log_cosh=0.063117064536 | val_huber=0.002502671443\n",
      "  δ=0.0145988: val_log_cosh=0.063764199615 | val_huber=0.003660931950\n",
      "  δ=0.0714307: val_log_cosh=0.063935145736 | val_huber=0.016042359173\n",
      "  δ=    0.02: val_log_cosh=0.066498689353 | val_huber=0.005154536106\n",
      "\n",
      ">>> Mejor δ por val_log_cosh: 0.1 (val_log_cosh=0.056828793138)\n",
      "\n",
      "Resultados TEST - Escenario M (Transformer)\n",
      "  loss (Huber):              0.171053\n",
      "  log_cosh:                  1.493869\n",
      "  within_eps_0_005          : 0.007363\n",
      "  within_eps_0_01           : 0.014226\n",
      "  within_eps_0_02           : 0.027789\n",
      "  within_eps_0_05           : 0.063313\n",
      "  within_eps_0_1            : 0.122257\n",
      "  AUTC[0.005–0.100]:         0.065998\n",
      "\n",
      "Grid δ (calibrado con cuantiles |e| en VAL): [0.01, 0.02, 0.02793753147125244, 0.05, 0.05683806538581848, 0.09924322143197067, 0.1, 0.13649090826511381]\n",
      "\n",
      "=== Barrido Huber delta _L (Transformer) ===\n",
      "\n",
      "--- Entrenando δ=0.01 ---\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 09:55:09.976337: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 117ms/step - log_cosh: 0.1198 - loss: 0.0039 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0180 - within_eps_0_02: 0.0360 - within_eps_0_05: 0.0896 - within_eps_0_1: 0.1773 - val_log_cosh: 0.1083 - val_loss: 0.0035 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0203 - val_within_eps_0_02: 0.0405 - val_within_eps_0_05: 0.1015 - val_within_eps_0_1: 0.2062\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0524 - loss: 0.0026 - within_eps_0_005: 0.0121 - within_eps_0_01: 0.0242 - within_eps_0_02: 0.0484 - within_eps_0_05: 0.1206 - within_eps_0_1: 0.2387 - val_log_cosh: 0.0741 - val_loss: 0.0028 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0527 - val_within_eps_0_05: 0.1340 - val_within_eps_0_1: 0.2610\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0487 - loss: 0.0025 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0510 - within_eps_0_05: 0.1259 - within_eps_0_1: 0.2487 - val_log_cosh: 0.0684 - val_loss: 0.0026 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0585 - val_within_eps_0_05: 0.1420 - val_within_eps_0_1: 0.2730\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0449 - loss: 0.0024 - within_eps_0_005: 0.0132 - within_eps_0_01: 0.0264 - within_eps_0_02: 0.0526 - within_eps_0_05: 0.1313 - within_eps_0_1: 0.2591 - val_log_cosh: 0.0638 - val_loss: 0.0025 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0271 - val_within_eps_0_02: 0.0548 - val_within_eps_0_05: 0.1375 - val_within_eps_0_1: 0.2773\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0403 - loss: 0.0023 - within_eps_0_005: 0.0141 - within_eps_0_01: 0.0279 - within_eps_0_02: 0.0556 - within_eps_0_05: 0.1383 - within_eps_0_1: 0.2731 - val_log_cosh: 0.0659 - val_loss: 0.0026 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1395 - val_within_eps_0_1: 0.2781\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0367 - loss: 0.0021 - within_eps_0_005: 0.0146 - within_eps_0_01: 0.0294 - within_eps_0_02: 0.0586 - within_eps_0_05: 0.1460 - within_eps_0_1: 0.2862 - val_log_cosh: 0.0711 - val_loss: 0.0027 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0276 - val_within_eps_0_02: 0.0556 - val_within_eps_0_05: 0.1412 - val_within_eps_0_1: 0.2754\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0327 - loss: 0.0020 - within_eps_0_005: 0.0155 - within_eps_0_01: 0.0309 - within_eps_0_02: 0.0620 - within_eps_0_05: 0.1547 - within_eps_0_1: 0.3038 - val_log_cosh: 0.0723 - val_loss: 0.0027 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1431 - val_within_eps_0_1: 0.2733\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0290 - loss: 0.0019 - within_eps_0_005: 0.0167 - within_eps_0_01: 0.0334 - within_eps_0_02: 0.0666 - within_eps_0_05: 0.1644 - within_eps_0_1: 0.3215 - val_log_cosh: 0.0780 - val_loss: 0.0028 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0522 - val_within_eps_0_05: 0.1292 - val_within_eps_0_1: 0.2569\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0258 - loss: 0.0018 - within_eps_0_005: 0.0177 - within_eps_0_01: 0.0353 - within_eps_0_02: 0.0702 - within_eps_0_05: 0.1742 - within_eps_0_1: 0.3407 - val_log_cosh: 0.0783 - val_loss: 0.0028 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0610 - val_within_eps_0_05: 0.1500 - val_within_eps_0_1: 0.2837\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0227 - loss: 0.0017 - within_eps_0_005: 0.0189 - within_eps_0_01: 0.0379 - within_eps_0_02: 0.0755 - within_eps_0_05: 0.1861 - within_eps_0_1: 0.3620 - val_log_cosh: 0.0878 - val_loss: 0.0030 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0567 - val_within_eps_0_05: 0.1405 - val_within_eps_0_1: 0.2624\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0198 - loss: 0.0015 - within_eps_0_005: 0.0201 - within_eps_0_01: 0.0403 - within_eps_0_02: 0.0809 - within_eps_0_05: 0.2001 - within_eps_0_1: 0.3866 - val_log_cosh: 0.0973 - val_loss: 0.0033 - val_within_eps_0_005: 0.0118 - val_within_eps_0_01: 0.0234 - val_within_eps_0_02: 0.0470 - val_within_eps_0_05: 0.1188 - val_within_eps_0_1: 0.2336\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0174 - loss: 0.0014 - within_eps_0_005: 0.0217 - within_eps_0_01: 0.0433 - within_eps_0_02: 0.0866 - within_eps_0_05: 0.2136 - within_eps_0_1: 0.4120 - val_log_cosh: 0.0925 - val_loss: 0.0032 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0523 - val_within_eps_0_05: 0.1280 - val_within_eps_0_1: 0.2441\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0150 - loss: 0.0013 - within_eps_0_005: 0.0235 - within_eps_0_01: 0.0468 - within_eps_0_02: 0.0939 - within_eps_0_05: 0.2315 - within_eps_0_1: 0.4423 - val_log_cosh: 0.1133 - val_loss: 0.0036 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0225 - val_within_eps_0_02: 0.0449 - val_within_eps_0_05: 0.1071 - val_within_eps_0_1: 0.2049\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0149 - loss: 0.0013 - within_eps_0_005: 0.0238 - within_eps_0_01: 0.0474 - within_eps_0_02: 0.0945 - within_eps_0_05: 0.2335 - within_eps_0_1: 0.4476 - val_log_cosh: 0.0780 - val_loss: 0.0028 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0302 - val_within_eps_0_02: 0.0606 - val_within_eps_0_05: 0.1486 - val_within_eps_0_1: 0.2812\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0141 - loss: 0.0013 - within_eps_0_005: 0.0247 - within_eps_0_01: 0.0497 - within_eps_0_02: 0.0990 - within_eps_0_05: 0.2433 - within_eps_0_1: 0.4635 - val_log_cosh: 0.0721 - val_loss: 0.0027 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0596 - val_within_eps_0_05: 0.1494 - val_within_eps_0_1: 0.2971\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0103 - loss: 0.0011 - within_eps_0_005: 0.0289 - within_eps_0_01: 0.0573 - within_eps_0_02: 0.1143 - within_eps_0_05: 0.2803 - within_eps_0_1: 0.5260 - val_log_cosh: 0.0833 - val_loss: 0.0029 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0303 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1441 - val_within_eps_0_1: 0.2653\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0091 - loss: 0.0010 - within_eps_0_005: 0.0310 - within_eps_0_01: 0.0621 - within_eps_0_02: 0.1240 - within_eps_0_05: 0.3020 - within_eps_0_1: 0.5597 - val_log_cosh: 0.0787 - val_loss: 0.0028 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1408 - val_within_eps_0_1: 0.2786\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0085 - loss: 9.7545e-04 - within_eps_0_005: 0.0322 - within_eps_0_01: 0.0642 - within_eps_0_02: 0.1285 - within_eps_0_05: 0.3130 - within_eps_0_1: 0.5767 - val_log_cosh: 0.1149 - val_loss: 0.0038 - val_within_eps_0_005: 0.0091 - val_within_eps_0_01: 0.0181 - val_within_eps_0_02: 0.0354 - val_within_eps_0_05: 0.0874 - val_within_eps_0_1: 0.1756\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0097 - loss: 0.0010 - within_eps_0_005: 0.0308 - within_eps_0_01: 0.0616 - within_eps_0_02: 0.1230 - within_eps_0_05: 0.3009 - within_eps_0_1: 0.5557 - val_log_cosh: 0.0721 - val_loss: 0.0027 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0599 - val_within_eps_0_05: 0.1497 - val_within_eps_0_1: 0.2964\n",
      "  -> min val_log_cosh=0.063755229115 | min val_huber=0.002534710336\n",
      "\n",
      "--- Entrenando δ=0.02 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 183ms/step - log_cosh: 0.1296 - loss: 0.0080 - within_eps_0_005: 0.0086 - within_eps_0_01: 0.0174 - within_eps_0_02: 0.0349 - within_eps_0_05: 0.0870 - within_eps_0_1: 0.1728 - val_log_cosh: 0.1162 - val_loss: 0.0072 - val_within_eps_0_005: 0.0104 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0411 - val_within_eps_0_05: 0.1036 - val_within_eps_0_1: 0.2020\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0542 - loss: 0.0052 - within_eps_0_005: 0.0117 - within_eps_0_01: 0.0236 - within_eps_0_02: 0.0479 - within_eps_0_05: 0.1191 - within_eps_0_1: 0.2357 - val_log_cosh: 0.0710 - val_loss: 0.0053 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0281 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1354 - val_within_eps_0_1: 0.2679\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0502 - loss: 0.0050 - within_eps_0_005: 0.0125 - within_eps_0_01: 0.0247 - within_eps_0_02: 0.0497 - within_eps_0_05: 0.1235 - within_eps_0_1: 0.2439 - val_log_cosh: 0.0663 - val_loss: 0.0051 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0300 - val_within_eps_0_02: 0.0603 - val_within_eps_0_05: 0.1484 - val_within_eps_0_1: 0.2813\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - log_cosh: 0.0461 - loss: 0.0047 - within_eps_0_005: 0.0129 - within_eps_0_01: 0.0258 - within_eps_0_02: 0.0516 - within_eps_0_05: 0.1294 - within_eps_0_1: 0.2554 - val_log_cosh: 0.0676 - val_loss: 0.0051 - val_within_eps_0_005: 0.0138 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1390 - val_within_eps_0_1: 0.2758\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0416 - loss: 0.0045 - within_eps_0_005: 0.0138 - within_eps_0_01: 0.0275 - within_eps_0_02: 0.0546 - within_eps_0_05: 0.1365 - within_eps_0_1: 0.2692 - val_log_cosh: 0.0705 - val_loss: 0.0053 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0549 - val_within_eps_0_05: 0.1364 - val_within_eps_0_1: 0.2645\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0378 - loss: 0.0043 - within_eps_0_005: 0.0144 - within_eps_0_01: 0.0291 - within_eps_0_02: 0.0582 - within_eps_0_05: 0.1440 - within_eps_0_1: 0.2830 - val_log_cosh: 0.0774 - val_loss: 0.0055 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1391 - val_within_eps_0_1: 0.2713\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0339 - loss: 0.0040 - within_eps_0_005: 0.0152 - within_eps_0_01: 0.0309 - within_eps_0_02: 0.0616 - within_eps_0_05: 0.1524 - within_eps_0_1: 0.2981 - val_log_cosh: 0.0835 - val_loss: 0.0058 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0278 - val_within_eps_0_02: 0.0561 - val_within_eps_0_05: 0.1410 - val_within_eps_0_1: 0.2646\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0302 - loss: 0.0038 - within_eps_0_005: 0.0162 - within_eps_0_01: 0.0326 - within_eps_0_02: 0.0648 - within_eps_0_05: 0.1619 - within_eps_0_1: 0.3163 - val_log_cosh: 0.0864 - val_loss: 0.0059 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0277 - val_within_eps_0_02: 0.0558 - val_within_eps_0_05: 0.1376 - val_within_eps_0_1: 0.2625\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0276 - loss: 0.0036 - within_eps_0_005: 0.0171 - within_eps_0_01: 0.0340 - within_eps_0_02: 0.0681 - within_eps_0_05: 0.1693 - within_eps_0_1: 0.3304 - val_log_cosh: 0.0736 - val_loss: 0.0054 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0273 - val_within_eps_0_02: 0.0546 - val_within_eps_0_05: 0.1383 - val_within_eps_0_1: 0.2689\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0261 - loss: 0.0035 - within_eps_0_005: 0.0177 - within_eps_0_01: 0.0355 - within_eps_0_02: 0.0703 - within_eps_0_05: 0.1750 - within_eps_0_1: 0.3406 - val_log_cosh: 0.0776 - val_loss: 0.0056 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0494 - val_within_eps_0_05: 0.1221 - val_within_eps_0_1: 0.2470\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0238 - loss: 0.0033 - within_eps_0_005: 0.0183 - within_eps_0_01: 0.0368 - within_eps_0_02: 0.0735 - within_eps_0_05: 0.1824 - within_eps_0_1: 0.3554 - val_log_cosh: 0.0848 - val_loss: 0.0060 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0239 - val_within_eps_0_02: 0.0478 - val_within_eps_0_05: 0.1173 - val_within_eps_0_1: 0.2296\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0208 - loss: 0.0031 - within_eps_0_005: 0.0199 - within_eps_0_01: 0.0397 - within_eps_0_02: 0.0793 - within_eps_0_05: 0.1969 - within_eps_0_1: 0.3802 - val_log_cosh: 0.0748 - val_loss: 0.0054 - val_within_eps_0_005: 0.0123 - val_within_eps_0_01: 0.0246 - val_within_eps_0_02: 0.0487 - val_within_eps_0_05: 0.1268 - val_within_eps_0_1: 0.2670\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0178 - loss: 0.0028 - within_eps_0_005: 0.0214 - within_eps_0_01: 0.0430 - within_eps_0_02: 0.0860 - within_eps_0_05: 0.2134 - within_eps_0_1: 0.4100 - val_log_cosh: 0.0771 - val_loss: 0.0056 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0237 - val_within_eps_0_02: 0.0480 - val_within_eps_0_05: 0.1218 - val_within_eps_0_1: 0.2426\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0228 - loss: 0.0032 - within_eps_0_005: 0.0191 - within_eps_0_01: 0.0383 - within_eps_0_02: 0.0765 - within_eps_0_05: 0.1894 - within_eps_0_1: 0.3675 - val_log_cosh: 0.0741 - val_loss: 0.0053 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0287 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1470 - val_within_eps_0_1: 0.2907\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0143 - loss: 0.0025 - within_eps_0_005: 0.0243 - within_eps_0_01: 0.0487 - within_eps_0_02: 0.0968 - within_eps_0_05: 0.2385 - within_eps_0_1: 0.4556 - val_log_cosh: 0.0710 - val_loss: 0.0052 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0311 - val_within_eps_0_02: 0.0615 - val_within_eps_0_05: 0.1521 - val_within_eps_0_1: 0.2929\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0120 - loss: 0.0023 - within_eps_0_005: 0.0268 - within_eps_0_01: 0.0535 - within_eps_0_02: 0.1071 - within_eps_0_05: 0.2632 - within_eps_0_1: 0.4969 - val_log_cosh: 0.0872 - val_loss: 0.0060 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0560 - val_within_eps_0_05: 0.1369 - val_within_eps_0_1: 0.2597\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0109 - loss: 0.0021 - within_eps_0_005: 0.0283 - within_eps_0_01: 0.0567 - within_eps_0_02: 0.1127 - within_eps_0_05: 0.2770 - within_eps_0_1: 0.5203 - val_log_cosh: 0.0803 - val_loss: 0.0057 - val_within_eps_0_005: 0.0125 - val_within_eps_0_01: 0.0253 - val_within_eps_0_02: 0.0508 - val_within_eps_0_05: 0.1304 - val_within_eps_0_1: 0.2654\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0096 - loss: 0.0020 - within_eps_0_005: 0.0309 - within_eps_0_01: 0.0618 - within_eps_0_02: 0.1228 - within_eps_0_05: 0.2997 - within_eps_0_1: 0.5558 - val_log_cosh: 0.1767 - val_loss: 0.0094 - val_within_eps_0_005: 0.0113 - val_within_eps_0_01: 0.0224 - val_within_eps_0_02: 0.0443 - val_within_eps_0_05: 0.1053 - val_within_eps_0_1: 0.1887\n",
      "  -> min val_log_cosh=0.066299453378 | min val_huber=0.005066788755\n",
      "\n",
      "--- Entrenando δ=0.02793753147125244 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 130ms/step - log_cosh: 0.1221 - loss: 0.0108 - within_eps_0_005: 0.0091 - within_eps_0_01: 0.0179 - within_eps_0_02: 0.0356 - within_eps_0_05: 0.0886 - within_eps_0_1: 0.1760 - val_log_cosh: 0.1168 - val_loss: 0.0099 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0219 - val_within_eps_0_02: 0.0436 - val_within_eps_0_05: 0.1064 - val_within_eps_0_1: 0.2086\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - log_cosh: 0.0530 - loss: 0.0070 - within_eps_0_005: 0.0119 - within_eps_0_01: 0.0237 - within_eps_0_02: 0.0480 - within_eps_0_05: 0.1196 - within_eps_0_1: 0.2373 - val_log_cosh: 0.0836 - val_loss: 0.0080 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0261 - val_within_eps_0_02: 0.0517 - val_within_eps_0_05: 0.1275 - val_within_eps_0_1: 0.2533\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0486 - loss: 0.0067 - within_eps_0_005: 0.0127 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0505 - within_eps_0_05: 0.1252 - within_eps_0_1: 0.2475 - val_log_cosh: 0.0812 - val_loss: 0.0079 - val_within_eps_0_005: 0.0119 - val_within_eps_0_01: 0.0238 - val_within_eps_0_02: 0.0484 - val_within_eps_0_05: 0.1227 - val_within_eps_0_1: 0.2484\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - log_cosh: 0.0442 - loss: 0.0064 - within_eps_0_005: 0.0135 - within_eps_0_01: 0.0269 - within_eps_0_02: 0.0534 - within_eps_0_05: 0.1318 - within_eps_0_1: 0.2598 - val_log_cosh: 0.0808 - val_loss: 0.0078 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0269 - val_within_eps_0_02: 0.0535 - val_within_eps_0_05: 0.1316 - val_within_eps_0_1: 0.2589\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0396 - loss: 0.0060 - within_eps_0_005: 0.0139 - within_eps_0_01: 0.0279 - within_eps_0_02: 0.0560 - within_eps_0_05: 0.1396 - within_eps_0_1: 0.2746 - val_log_cosh: 0.0788 - val_loss: 0.0077 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0254 - val_within_eps_0_02: 0.0512 - val_within_eps_0_05: 0.1300 - val_within_eps_0_1: 0.2612\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0353 - loss: 0.0056 - within_eps_0_005: 0.0148 - within_eps_0_01: 0.0298 - within_eps_0_02: 0.0599 - within_eps_0_05: 0.1485 - within_eps_0_1: 0.2918 - val_log_cosh: 0.0919 - val_loss: 0.0085 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0544 - val_within_eps_0_05: 0.1304 - val_within_eps_0_1: 0.2449\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0317 - loss: 0.0053 - within_eps_0_005: 0.0160 - within_eps_0_01: 0.0316 - within_eps_0_02: 0.0631 - within_eps_0_05: 0.1561 - within_eps_0_1: 0.3069 - val_log_cosh: 0.0847 - val_loss: 0.0081 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0242 - val_within_eps_0_02: 0.0493 - val_within_eps_0_05: 0.1245 - val_within_eps_0_1: 0.2499\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0277 - loss: 0.0049 - within_eps_0_005: 0.0171 - within_eps_0_01: 0.0341 - within_eps_0_02: 0.0676 - within_eps_0_05: 0.1683 - within_eps_0_1: 0.3288 - val_log_cosh: 0.0879 - val_loss: 0.0083 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0258 - val_within_eps_0_02: 0.0510 - val_within_eps_0_05: 0.1242 - val_within_eps_0_1: 0.2417\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0242 - loss: 0.0046 - within_eps_0_005: 0.0182 - within_eps_0_01: 0.0363 - within_eps_0_02: 0.0727 - within_eps_0_05: 0.1801 - within_eps_0_1: 0.3507 - val_log_cosh: 0.0873 - val_loss: 0.0082 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0524 - val_within_eps_0_05: 0.1326 - val_within_eps_0_1: 0.2608\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0209 - loss: 0.0042 - within_eps_0_005: 0.0194 - within_eps_0_01: 0.0391 - within_eps_0_02: 0.0780 - within_eps_0_05: 0.1931 - within_eps_0_1: 0.3757 - val_log_cosh: 0.0898 - val_loss: 0.0083 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0584 - val_within_eps_0_05: 0.1412 - val_within_eps_0_1: 0.2637\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0188 - loss: 0.0040 - within_eps_0_005: 0.0206 - within_eps_0_01: 0.0414 - within_eps_0_02: 0.0830 - within_eps_0_05: 0.2052 - within_eps_0_1: 0.3962 - val_log_cosh: 0.0956 - val_loss: 0.0088 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0258 - val_within_eps_0_02: 0.0517 - val_within_eps_0_05: 0.1242 - val_within_eps_0_1: 0.2316\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0168 - loss: 0.0037 - within_eps_0_005: 0.0223 - within_eps_0_01: 0.0444 - within_eps_0_02: 0.0886 - within_eps_0_05: 0.2183 - within_eps_0_1: 0.4192 - val_log_cosh: 0.0862 - val_loss: 0.0081 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0271 - val_within_eps_0_02: 0.0542 - val_within_eps_0_05: 0.1376 - val_within_eps_0_1: 0.2660\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0161 - loss: 0.0036 - within_eps_0_005: 0.0230 - within_eps_0_01: 0.0456 - within_eps_0_02: 0.0910 - within_eps_0_05: 0.2250 - within_eps_0_1: 0.4316 - val_log_cosh: 0.0919 - val_loss: 0.0085 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0298 - val_within_eps_0_02: 0.0593 - val_within_eps_0_05: 0.1420 - val_within_eps_0_1: 0.2671\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0134 - loss: 0.0033 - within_eps_0_005: 0.0250 - within_eps_0_01: 0.0498 - within_eps_0_02: 0.0990 - within_eps_0_05: 0.2445 - within_eps_0_1: 0.4655 - val_log_cosh: 0.0771 - val_loss: 0.0076 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0589 - val_within_eps_0_05: 0.1458 - val_within_eps_0_1: 0.2869\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0131 - loss: 0.0032 - within_eps_0_005: 0.0251 - within_eps_0_01: 0.0503 - within_eps_0_02: 0.1011 - within_eps_0_05: 0.2492 - within_eps_0_1: 0.4725 - val_log_cosh: 0.0934 - val_loss: 0.0087 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0228 - val_within_eps_0_02: 0.0447 - val_within_eps_0_05: 0.1101 - val_within_eps_0_1: 0.2181\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0118 - loss: 0.0030 - within_eps_0_005: 0.0269 - within_eps_0_01: 0.0537 - within_eps_0_02: 0.1069 - within_eps_0_05: 0.2627 - within_eps_0_1: 0.4972 - val_log_cosh: 0.0908 - val_loss: 0.0085 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0272 - val_within_eps_0_02: 0.0554 - val_within_eps_0_05: 0.1374 - val_within_eps_0_1: 0.2581\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0088 - loss: 0.0026 - within_eps_0_005: 0.0309 - within_eps_0_01: 0.0620 - within_eps_0_02: 0.1240 - within_eps_0_05: 0.3027 - within_eps_0_1: 0.5609 - val_log_cosh: 0.1244 - val_loss: 0.0105 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0223 - val_within_eps_0_02: 0.0448 - val_within_eps_0_05: 0.1085 - val_within_eps_0_1: 0.2099\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0119 - loss: 0.0030 - within_eps_0_005: 0.0278 - within_eps_0_01: 0.0557 - within_eps_0_02: 0.1113 - within_eps_0_05: 0.2727 - within_eps_0_1: 0.5099 - val_log_cosh: 0.0997 - val_loss: 0.0090 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0577 - val_within_eps_0_05: 0.1379 - val_within_eps_0_1: 0.2496\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - log_cosh: 0.0073 - loss: 0.0023 - within_eps_0_005: 0.0350 - within_eps_0_01: 0.0704 - within_eps_0_02: 0.1404 - within_eps_0_05: 0.3409 - within_eps_0_1: 0.6170 - val_log_cosh: 0.0961 - val_loss: 0.0089 - val_within_eps_0_005: 0.0126 - val_within_eps_0_01: 0.0253 - val_within_eps_0_02: 0.0508 - val_within_eps_0_05: 0.1260 - val_within_eps_0_1: 0.2430\n",
      "Epoch 20/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0065 - loss: 0.0021 - within_eps_0_005: 0.0372 - within_eps_0_01: 0.0740 - within_eps_0_02: 0.1470 - within_eps_0_05: 0.3556 - within_eps_0_1: 0.6385 - val_log_cosh: 0.0897 - val_loss: 0.0085 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0247 - val_within_eps_0_02: 0.0489 - val_within_eps_0_05: 0.1234 - val_within_eps_0_1: 0.2486\n",
      "Epoch 21/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0059 - loss: 0.0020 - within_eps_0_005: 0.0408 - within_eps_0_01: 0.0813 - within_eps_0_02: 0.1612 - within_eps_0_05: 0.3876 - within_eps_0_1: 0.6809 - val_log_cosh: 0.0780 - val_loss: 0.0076 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0294 - val_within_eps_0_02: 0.0588 - val_within_eps_0_05: 0.1478 - val_within_eps_0_1: 0.2980\n",
      "Epoch 22/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0044 - loss: 0.0017 - within_eps_0_005: 0.0460 - within_eps_0_01: 0.0920 - within_eps_0_02: 0.1831 - within_eps_0_05: 0.4342 - within_eps_0_1: 0.7383 - val_log_cosh: 0.0937 - val_loss: 0.0088 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0605 - val_within_eps_0_05: 0.1458 - val_within_eps_0_1: 0.2569\n",
      "Epoch 23/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0085 - loss: 0.0024 - within_eps_0_005: 0.0356 - within_eps_0_01: 0.0713 - within_eps_0_02: 0.1419 - within_eps_0_05: 0.3439 - within_eps_0_1: 0.6152 - val_log_cosh: 0.0757 - val_loss: 0.0075 - val_within_eps_0_005: 0.0171 - val_within_eps_0_01: 0.0344 - val_within_eps_0_02: 0.0697 - val_within_eps_0_05: 0.1736 - val_within_eps_0_1: 0.3250\n",
      "Epoch 24/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0040 - loss: 0.0016 - within_eps_0_005: 0.0484 - within_eps_0_01: 0.0971 - within_eps_0_02: 0.1930 - within_eps_0_05: 0.4551 - within_eps_0_1: 0.7626 - val_log_cosh: 0.0863 - val_loss: 0.0083 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0304 - val_within_eps_0_02: 0.0601 - val_within_eps_0_05: 0.1440 - val_within_eps_0_1: 0.2741\n",
      "Epoch 25/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0045 - loss: 0.0016 - within_eps_0_005: 0.0489 - within_eps_0_01: 0.0977 - within_eps_0_02: 0.1932 - within_eps_0_05: 0.4539 - within_eps_0_1: 0.7527 - val_log_cosh: 0.0881 - val_loss: 0.0084 - val_within_eps_0_005: 0.0162 - val_within_eps_0_01: 0.0317 - val_within_eps_0_02: 0.0629 - val_within_eps_0_05: 0.1523 - val_within_eps_0_1: 0.2741\n",
      "Epoch 26/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0035 - loss: 0.0014 - within_eps_0_005: 0.0549 - within_eps_0_01: 0.1088 - within_eps_0_02: 0.2152 - within_eps_0_05: 0.4996 - within_eps_0_1: 0.8022 - val_log_cosh: 0.1284 - val_loss: 0.0110 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0220 - val_within_eps_0_02: 0.0434 - val_within_eps_0_05: 0.1015 - val_within_eps_0_1: 0.1764\n",
      "Epoch 27/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - log_cosh: 0.0076 - loss: 0.0022 - within_eps_0_005: 0.0403 - within_eps_0_01: 0.0804 - within_eps_0_02: 0.1601 - within_eps_0_05: 0.3823 - within_eps_0_1: 0.6626 - val_log_cosh: 0.0795 - val_loss: 0.0080 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0237 - val_within_eps_0_02: 0.0468 - val_within_eps_0_05: 0.1135 - val_within_eps_0_1: 0.2247\n",
      "Epoch 28/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - log_cosh: 0.0041 - loss: 0.0016 - within_eps_0_005: 0.0498 - within_eps_0_01: 0.0995 - within_eps_0_02: 0.1970 - within_eps_0_05: 0.4611 - within_eps_0_1: 0.7640 - val_log_cosh: 0.1120 - val_loss: 0.0099 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0204 - val_within_eps_0_02: 0.0403 - val_within_eps_0_05: 0.0992 - val_within_eps_0_1: 0.2025\n",
      "Epoch 29/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - log_cosh: 0.0035 - loss: 0.0014 - within_eps_0_005: 0.0543 - within_eps_0_01: 0.1087 - within_eps_0_02: 0.2147 - within_eps_0_05: 0.4985 - within_eps_0_1: 0.7991 - val_log_cosh: 0.1831 - val_loss: 0.0141 - val_within_eps_0_005: 0.0078 - val_within_eps_0_01: 0.0153 - val_within_eps_0_02: 0.0306 - val_within_eps_0_05: 0.0714 - val_within_eps_0_1: 0.1317\n",
      "Epoch 30/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0042 - loss: 0.0016 - within_eps_0_005: 0.0507 - within_eps_0_01: 0.1015 - within_eps_0_02: 0.2003 - within_eps_0_05: 0.4668 - within_eps_0_1: 0.7614 - val_log_cosh: 0.2611 - val_loss: 0.0185 - val_within_eps_0_005: 0.0013 - val_within_eps_0_01: 0.0026 - val_within_eps_0_02: 0.0058 - val_within_eps_0_05: 0.0166 - val_within_eps_0_1: 0.0310\n",
      "Epoch 31/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0054 - loss: 0.0018 - within_eps_0_005: 0.0446 - within_eps_0_01: 0.0888 - within_eps_0_02: 0.1765 - within_eps_0_05: 0.4194 - within_eps_0_1: 0.7139 - val_log_cosh: 0.1908 - val_loss: 0.0146 - val_within_eps_0_005: 0.0048 - val_within_eps_0_01: 0.0098 - val_within_eps_0_02: 0.0196 - val_within_eps_0_05: 0.0509 - val_within_eps_0_1: 0.1077\n",
      "Epoch 32/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0040 - loss: 0.0015 - within_eps_0_005: 0.0544 - within_eps_0_01: 0.1085 - within_eps_0_02: 0.2142 - within_eps_0_05: 0.4951 - within_eps_0_1: 0.7860 - val_log_cosh: 0.0853 - val_loss: 0.0081 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0534 - val_within_eps_0_05: 0.1354 - val_within_eps_0_1: 0.2650\n",
      "Epoch 33/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - log_cosh: 0.0034 - loss: 0.0014 - within_eps_0_005: 0.0549 - within_eps_0_01: 0.1095 - within_eps_0_02: 0.2166 - within_eps_0_05: 0.5026 - within_eps_0_1: 0.8039 - val_log_cosh: 0.1963 - val_loss: 0.0153 - val_within_eps_0_005: 0.0049 - val_within_eps_0_01: 0.0098 - val_within_eps_0_02: 0.0194 - val_within_eps_0_05: 0.0447 - val_within_eps_0_1: 0.0764\n",
      "Epoch 34/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0135 - loss: 0.0030 - within_eps_0_005: 0.0326 - within_eps_0_01: 0.0657 - within_eps_0_02: 0.1309 - within_eps_0_05: 0.3133 - within_eps_0_1: 0.5573 - val_log_cosh: 0.1255 - val_loss: 0.0105 - val_within_eps_0_005: 0.0103 - val_within_eps_0_01: 0.0204 - val_within_eps_0_02: 0.0406 - val_within_eps_0_05: 0.0993 - val_within_eps_0_1: 0.1980\n",
      "Epoch 35/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - log_cosh: 0.0054 - loss: 0.0018 - within_eps_0_005: 0.0451 - within_eps_0_01: 0.0898 - within_eps_0_02: 0.1775 - within_eps_0_05: 0.4207 - within_eps_0_1: 0.7141 - val_log_cosh: 0.1092 - val_loss: 0.0098 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0236 - val_within_eps_0_02: 0.0470 - val_within_eps_0_05: 0.1133 - val_within_eps_0_1: 0.2097\n",
      "Epoch 36/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - log_cosh: 0.0039 - loss: 0.0015 - within_eps_0_005: 0.0522 - within_eps_0_01: 0.1036 - within_eps_0_02: 0.2049 - within_eps_0_05: 0.4792 - within_eps_0_1: 0.7792 - val_log_cosh: 0.2964 - val_loss: 0.0198 - val_within_eps_0_005: 0.0030 - val_within_eps_0_01: 0.0060 - val_within_eps_0_02: 0.0121 - val_within_eps_0_05: 0.0291 - val_within_eps_0_1: 0.0619\n",
      "Epoch 37/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - log_cosh: 0.0120 - loss: 0.0028 - within_eps_0_005: 0.0357 - within_eps_0_01: 0.0714 - within_eps_0_02: 0.1425 - within_eps_0_05: 0.3386 - within_eps_0_1: 0.5885 - val_log_cosh: 0.1627 - val_loss: 0.0129 - val_within_eps_0_005: 0.0077 - val_within_eps_0_01: 0.0154 - val_within_eps_0_02: 0.0317 - val_within_eps_0_05: 0.0779 - val_within_eps_0_1: 0.1497\n",
      "Epoch 38/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - log_cosh: 0.0063 - loss: 0.0019 - within_eps_0_005: 0.0448 - within_eps_0_01: 0.0891 - within_eps_0_02: 0.1764 - within_eps_0_05: 0.4210 - within_eps_0_1: 0.7075 - val_log_cosh: 0.2044 - val_loss: 0.0154 - val_within_eps_0_005: 0.0041 - val_within_eps_0_01: 0.0085 - val_within_eps_0_02: 0.0182 - val_within_eps_0_05: 0.0454 - val_within_eps_0_1: 0.0760\n",
      "  -> min val_log_cosh=0.075747221708 | min val_huber=0.007478351705\n",
      "\n",
      "--- Entrenando δ=0.05 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - log_cosh: 0.1175 - loss: 0.0185 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0178 - within_eps_0_02: 0.0358 - within_eps_0_05: 0.0890 - within_eps_0_1: 0.1766 - val_log_cosh: 0.0993 - val_loss: 0.0155 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0228 - val_within_eps_0_02: 0.0456 - val_within_eps_0_05: 0.1127 - val_within_eps_0_1: 0.2229\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0540 - loss: 0.0122 - within_eps_0_005: 0.0121 - within_eps_0_01: 0.0240 - within_eps_0_02: 0.0480 - within_eps_0_05: 0.1193 - within_eps_0_1: 0.2355 - val_log_cosh: 0.0733 - val_loss: 0.0127 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0547 - val_within_eps_0_05: 0.1383 - val_within_eps_0_1: 0.2699\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0503 - loss: 0.0117 - within_eps_0_005: 0.0122 - within_eps_0_01: 0.0247 - within_eps_0_02: 0.0495 - within_eps_0_05: 0.1233 - within_eps_0_1: 0.2447 - val_log_cosh: 0.0727 - val_loss: 0.0126 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1466 - val_within_eps_0_1: 0.2824\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0447 - loss: 0.0110 - within_eps_0_005: 0.0133 - within_eps_0_01: 0.0266 - within_eps_0_02: 0.0528 - within_eps_0_05: 0.1312 - within_eps_0_1: 0.2588 - val_log_cosh: 0.0707 - val_loss: 0.0124 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0566 - val_within_eps_0_05: 0.1393 - val_within_eps_0_1: 0.2743\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0406 - loss: 0.0104 - within_eps_0_005: 0.0137 - within_eps_0_01: 0.0277 - within_eps_0_02: 0.0553 - within_eps_0_05: 0.1373 - within_eps_0_1: 0.2714 - val_log_cosh: 0.0734 - val_loss: 0.0126 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0602 - val_within_eps_0_05: 0.1475 - val_within_eps_0_1: 0.2821\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - log_cosh: 0.0366 - loss: 0.0098 - within_eps_0_005: 0.0146 - within_eps_0_01: 0.0292 - within_eps_0_02: 0.0584 - within_eps_0_05: 0.1456 - within_eps_0_1: 0.2862 - val_log_cosh: 0.0751 - val_loss: 0.0129 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1418 - val_within_eps_0_1: 0.2755\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0324 - loss: 0.0091 - within_eps_0_005: 0.0156 - within_eps_0_01: 0.0311 - within_eps_0_02: 0.0621 - within_eps_0_05: 0.1551 - within_eps_0_1: 0.3036 - val_log_cosh: 0.0789 - val_loss: 0.0133 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0600 - val_within_eps_0_05: 0.1495 - val_within_eps_0_1: 0.2799\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0288 - loss: 0.0085 - within_eps_0_005: 0.0165 - within_eps_0_01: 0.0334 - within_eps_0_02: 0.0668 - within_eps_0_05: 0.1651 - within_eps_0_1: 0.3226 - val_log_cosh: 0.0841 - val_loss: 0.0138 - val_within_eps_0_005: 0.0137 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0553 - val_within_eps_0_05: 0.1412 - val_within_eps_0_1: 0.2740\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0250 - loss: 0.0078 - within_eps_0_005: 0.0179 - within_eps_0_01: 0.0359 - within_eps_0_02: 0.0715 - within_eps_0_05: 0.1772 - within_eps_0_1: 0.3451 - val_log_cosh: 0.0864 - val_loss: 0.0141 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0585 - val_within_eps_0_05: 0.1435 - val_within_eps_0_1: 0.2722\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0220 - loss: 0.0072 - within_eps_0_005: 0.0191 - within_eps_0_01: 0.0383 - within_eps_0_02: 0.0762 - within_eps_0_05: 0.1892 - within_eps_0_1: 0.3674 - val_log_cosh: 0.0903 - val_loss: 0.0146 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0549 - val_within_eps_0_05: 0.1347 - val_within_eps_0_1: 0.2620\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0193 - loss: 0.0067 - within_eps_0_005: 0.0206 - within_eps_0_01: 0.0411 - within_eps_0_02: 0.0822 - within_eps_0_05: 0.2040 - within_eps_0_1: 0.3932 - val_log_cosh: 0.0857 - val_loss: 0.0140 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0307 - val_within_eps_0_02: 0.0611 - val_within_eps_0_05: 0.1494 - val_within_eps_0_1: 0.2762\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0165 - loss: 0.0061 - within_eps_0_005: 0.0226 - within_eps_0_01: 0.0450 - within_eps_0_02: 0.0892 - within_eps_0_05: 0.2203 - within_eps_0_1: 0.4236 - val_log_cosh: 0.0815 - val_loss: 0.0135 - val_within_eps_0_005: 0.0151 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0616 - val_within_eps_0_05: 0.1515 - val_within_eps_0_1: 0.2841\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - log_cosh: 0.0142 - loss: 0.0056 - within_eps_0_005: 0.0241 - within_eps_0_01: 0.0481 - within_eps_0_02: 0.0963 - within_eps_0_05: 0.2374 - within_eps_0_1: 0.4533 - val_log_cosh: 0.0992 - val_loss: 0.0157 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0506 - val_within_eps_0_05: 0.1230 - val_within_eps_0_1: 0.2305\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0123 - loss: 0.0051 - within_eps_0_005: 0.0262 - within_eps_0_01: 0.0517 - within_eps_0_02: 0.1031 - within_eps_0_05: 0.2550 - within_eps_0_1: 0.4842 - val_log_cosh: 0.0709 - val_loss: 0.0123 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0290 - val_within_eps_0_02: 0.0579 - val_within_eps_0_05: 0.1428 - val_within_eps_0_1: 0.2868\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0111 - loss: 0.0048 - within_eps_0_005: 0.0276 - within_eps_0_01: 0.0553 - within_eps_0_02: 0.1104 - within_eps_0_05: 0.2705 - within_eps_0_1: 0.5093 - val_log_cosh: 0.0866 - val_loss: 0.0141 - val_within_eps_0_005: 0.0120 - val_within_eps_0_01: 0.0248 - val_within_eps_0_02: 0.0511 - val_within_eps_0_05: 0.1346 - val_within_eps_0_1: 0.2691\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0102 - loss: 0.0045 - within_eps_0_005: 0.0284 - within_eps_0_01: 0.0569 - within_eps_0_02: 0.1137 - within_eps_0_05: 0.2803 - within_eps_0_1: 0.5257 - val_log_cosh: 0.0872 - val_loss: 0.0143 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0601 - val_within_eps_0_05: 0.1448 - val_within_eps_0_1: 0.2653\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0091 - loss: 0.0042 - within_eps_0_005: 0.0308 - within_eps_0_01: 0.0614 - within_eps_0_02: 0.1229 - within_eps_0_05: 0.3009 - within_eps_0_1: 0.5579 - val_log_cosh: 0.0853 - val_loss: 0.0140 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0622 - val_within_eps_0_05: 0.1456 - val_within_eps_0_1: 0.2668\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0076 - loss: 0.0037 - within_eps_0_005: 0.0339 - within_eps_0_01: 0.0679 - within_eps_0_02: 0.1347 - within_eps_0_05: 0.3282 - within_eps_0_1: 0.6001 - val_log_cosh: 0.1113 - val_loss: 0.0171 - val_within_eps_0_005: 0.0100 - val_within_eps_0_01: 0.0201 - val_within_eps_0_02: 0.0403 - val_within_eps_0_05: 0.1014 - val_within_eps_0_1: 0.2059\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0093 - loss: 0.0042 - within_eps_0_005: 0.0312 - within_eps_0_01: 0.0626 - within_eps_0_02: 0.1244 - within_eps_0_05: 0.3040 - within_eps_0_1: 0.5598 - val_log_cosh: 0.0959 - val_loss: 0.0153 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0526 - val_within_eps_0_05: 0.1306 - val_within_eps_0_1: 0.2497\n",
      "  -> min val_log_cosh=0.070718660951 | min val_huber=0.012302746996\n",
      "\n",
      "--- Entrenando δ=0.05683806538581848 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 105ms/step - log_cosh: 0.1236 - loss: 0.0212 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0180 - within_eps_0_02: 0.0361 - within_eps_0_05: 0.0896 - within_eps_0_1: 0.1779 - val_log_cosh: 0.0936 - val_loss: 0.0169 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0232 - val_within_eps_0_02: 0.0463 - val_within_eps_0_05: 0.1146 - val_within_eps_0_1: 0.2300\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0492 - loss: 0.0130 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0251 - within_eps_0_02: 0.0503 - within_eps_0_05: 0.1254 - within_eps_0_1: 0.2474 - val_log_cosh: 0.0663 - val_loss: 0.0135 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0280 - val_within_eps_0_02: 0.0561 - val_within_eps_0_05: 0.1398 - val_within_eps_0_1: 0.2719\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0460 - loss: 0.0125 - within_eps_0_005: 0.0130 - within_eps_0_01: 0.0259 - within_eps_0_02: 0.0518 - within_eps_0_05: 0.1296 - within_eps_0_1: 0.2557 - val_log_cosh: 0.0642 - val_loss: 0.0133 - val_within_eps_0_005: 0.0155 - val_within_eps_0_01: 0.0308 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1494 - val_within_eps_0_1: 0.2846\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0413 - loss: 0.0117 - within_eps_0_005: 0.0138 - within_eps_0_01: 0.0277 - within_eps_0_02: 0.0552 - within_eps_0_05: 0.1367 - within_eps_0_1: 0.2693 - val_log_cosh: 0.0643 - val_loss: 0.0132 - val_within_eps_0_005: 0.0156 - val_within_eps_0_01: 0.0306 - val_within_eps_0_02: 0.0612 - val_within_eps_0_05: 0.1535 - val_within_eps_0_1: 0.2939\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0370 - loss: 0.0110 - within_eps_0_005: 0.0145 - within_eps_0_01: 0.0293 - within_eps_0_02: 0.0581 - within_eps_0_05: 0.1449 - within_eps_0_1: 0.2847 - val_log_cosh: 0.0641 - val_loss: 0.0131 - val_within_eps_0_005: 0.0158 - val_within_eps_0_01: 0.0314 - val_within_eps_0_02: 0.0624 - val_within_eps_0_05: 0.1552 - val_within_eps_0_1: 0.2979\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0332 - loss: 0.0103 - within_eps_0_005: 0.0153 - within_eps_0_01: 0.0307 - within_eps_0_02: 0.0616 - within_eps_0_05: 0.1531 - within_eps_0_1: 0.3002 - val_log_cosh: 0.0674 - val_loss: 0.0136 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0297 - val_within_eps_0_02: 0.0594 - val_within_eps_0_05: 0.1469 - val_within_eps_0_1: 0.2819\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0294 - loss: 0.0096 - within_eps_0_005: 0.0165 - within_eps_0_01: 0.0327 - within_eps_0_02: 0.0655 - within_eps_0_05: 0.1625 - within_eps_0_1: 0.3181 - val_log_cosh: 0.0673 - val_loss: 0.0135 - val_within_eps_0_005: 0.0157 - val_within_eps_0_01: 0.0312 - val_within_eps_0_02: 0.0624 - val_within_eps_0_05: 0.1538 - val_within_eps_0_1: 0.2953\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0262 - loss: 0.0090 - within_eps_0_005: 0.0175 - within_eps_0_01: 0.0348 - within_eps_0_02: 0.0698 - within_eps_0_05: 0.1734 - within_eps_0_1: 0.3374 - val_log_cosh: 0.0639 - val_loss: 0.0130 - val_within_eps_0_005: 0.0165 - val_within_eps_0_01: 0.0332 - val_within_eps_0_02: 0.0656 - val_within_eps_0_05: 0.1596 - val_within_eps_0_1: 0.2989\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0235 - loss: 0.0084 - within_eps_0_005: 0.0185 - within_eps_0_01: 0.0371 - within_eps_0_02: 0.0740 - within_eps_0_05: 0.1840 - within_eps_0_1: 0.3569 - val_log_cosh: 0.0739 - val_loss: 0.0143 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0594 - val_within_eps_0_05: 0.1477 - val_within_eps_0_1: 0.2823\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0201 - loss: 0.0076 - within_eps_0_005: 0.0201 - within_eps_0_01: 0.0404 - within_eps_0_02: 0.0803 - within_eps_0_05: 0.1990 - within_eps_0_1: 0.3848 - val_log_cosh: 0.0781 - val_loss: 0.0148 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0296 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1474 - val_within_eps_0_1: 0.2784\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0177 - loss: 0.0071 - within_eps_0_005: 0.0214 - within_eps_0_01: 0.0429 - within_eps_0_02: 0.0852 - within_eps_0_05: 0.2106 - within_eps_0_1: 0.4075 - val_log_cosh: 0.0811 - val_loss: 0.0153 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0565 - val_within_eps_0_05: 0.1386 - val_within_eps_0_1: 0.2678\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0155 - loss: 0.0065 - within_eps_0_005: 0.0231 - within_eps_0_01: 0.0462 - within_eps_0_02: 0.0918 - within_eps_0_05: 0.2269 - within_eps_0_1: 0.4345 - val_log_cosh: 0.0978 - val_loss: 0.0176 - val_within_eps_0_005: 0.0104 - val_within_eps_0_01: 0.0209 - val_within_eps_0_02: 0.0415 - val_within_eps_0_05: 0.1039 - val_within_eps_0_1: 0.2137\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0135 - loss: 0.0060 - within_eps_0_005: 0.0250 - within_eps_0_01: 0.0496 - within_eps_0_02: 0.0991 - within_eps_0_05: 0.2444 - within_eps_0_1: 0.4650 - val_log_cosh: 0.0910 - val_loss: 0.0162 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0252 - val_within_eps_0_02: 0.0495 - val_within_eps_0_05: 0.1212 - val_within_eps_0_1: 0.2457\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0140 - loss: 0.0061 - within_eps_0_005: 0.0246 - within_eps_0_01: 0.0489 - within_eps_0_02: 0.0977 - within_eps_0_05: 0.2406 - within_eps_0_1: 0.4592 - val_log_cosh: 0.0859 - val_loss: 0.0159 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0238 - val_within_eps_0_02: 0.0477 - val_within_eps_0_05: 0.1182 - val_within_eps_0_1: 0.2288\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0119 - loss: 0.0055 - within_eps_0_005: 0.0268 - within_eps_0_01: 0.0539 - within_eps_0_02: 0.1072 - within_eps_0_05: 0.2634 - within_eps_0_1: 0.4969 - val_log_cosh: 0.1669 - val_loss: 0.0260 - val_within_eps_0_005: 0.0045 - val_within_eps_0_01: 0.0092 - val_within_eps_0_02: 0.0185 - val_within_eps_0_05: 0.0490 - val_within_eps_0_1: 0.1104\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0156 - loss: 0.0064 - within_eps_0_005: 0.0237 - within_eps_0_01: 0.0474 - within_eps_0_02: 0.0943 - within_eps_0_05: 0.2334 - within_eps_0_1: 0.4466 - val_log_cosh: 0.0687 - val_loss: 0.0135 - val_within_eps_0_005: 0.0147 - val_within_eps_0_01: 0.0298 - val_within_eps_0_02: 0.0599 - val_within_eps_0_05: 0.1493 - val_within_eps_0_1: 0.2920\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0091 - loss: 0.0046 - within_eps_0_005: 0.0310 - within_eps_0_01: 0.0616 - within_eps_0_02: 0.1231 - within_eps_0_05: 0.3012 - within_eps_0_1: 0.5578 - val_log_cosh: 0.0768 - val_loss: 0.0145 - val_within_eps_0_005: 0.0164 - val_within_eps_0_01: 0.0332 - val_within_eps_0_02: 0.0650 - val_within_eps_0_05: 0.1591 - val_within_eps_0_1: 0.2968\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0070 - loss: 0.0039 - within_eps_0_005: 0.0353 - within_eps_0_01: 0.0707 - within_eps_0_02: 0.1410 - within_eps_0_05: 0.3424 - within_eps_0_1: 0.6196 - val_log_cosh: 0.1118 - val_loss: 0.0186 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0216 - val_within_eps_0_02: 0.0432 - val_within_eps_0_05: 0.1051 - val_within_eps_0_1: 0.2056\n",
      "Epoch 19/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0089 - loss: 0.0045 - within_eps_0_005: 0.0320 - within_eps_0_01: 0.0641 - within_eps_0_02: 0.1275 - within_eps_0_05: 0.3108 - within_eps_0_1: 0.5719 - val_log_cosh: 0.1138 - val_loss: 0.0195 - val_within_eps_0_005: 0.0110 - val_within_eps_0_01: 0.0217 - val_within_eps_0_02: 0.0442 - val_within_eps_0_05: 0.1116 - val_within_eps_0_1: 0.2138\n",
      "Epoch 20/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0086 - loss: 0.0042 - within_eps_0_005: 0.0350 - within_eps_0_01: 0.0701 - within_eps_0_02: 0.1399 - within_eps_0_05: 0.3394 - within_eps_0_1: 0.6125 - val_log_cosh: 0.0750 - val_loss: 0.0147 - val_within_eps_0_005: 0.0145 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0580 - val_within_eps_0_05: 0.1394 - val_within_eps_0_1: 0.2656\n",
      "Epoch 21/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0052 - loss: 0.0031 - within_eps_0_005: 0.0434 - within_eps_0_01: 0.0863 - within_eps_0_02: 0.1713 - within_eps_0_05: 0.4094 - within_eps_0_1: 0.7079 - val_log_cosh: 0.0736 - val_loss: 0.0145 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0316 - val_within_eps_0_02: 0.0622 - val_within_eps_0_05: 0.1496 - val_within_eps_0_1: 0.2783\n",
      "Epoch 22/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0045 - loss: 0.0028 - within_eps_0_005: 0.0461 - within_eps_0_01: 0.0921 - within_eps_0_02: 0.1824 - within_eps_0_05: 0.4327 - within_eps_0_1: 0.7349 - val_log_cosh: 0.1132 - val_loss: 0.0197 - val_within_eps_0_005: 0.0102 - val_within_eps_0_01: 0.0204 - val_within_eps_0_02: 0.0411 - val_within_eps_0_05: 0.1041 - val_within_eps_0_1: 0.2090\n",
      "Epoch 23/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0076 - loss: 0.0039 - within_eps_0_005: 0.0393 - within_eps_0_01: 0.0783 - within_eps_0_02: 0.1560 - within_eps_0_05: 0.3721 - within_eps_0_1: 0.6476 - val_log_cosh: 0.1161 - val_loss: 0.0202 - val_within_eps_0_005: 0.0115 - val_within_eps_0_01: 0.0230 - val_within_eps_0_02: 0.0456 - val_within_eps_0_05: 0.1078 - val_within_eps_0_1: 0.2010\n",
      "  -> min val_log_cosh=0.063852488995 | min val_huber=0.012976211496\n",
      "\n",
      "--- Entrenando δ=0.09924322143197067 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - log_cosh: 0.1158 - loss: 0.0339 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0181 - within_eps_0_02: 0.0364 - within_eps_0_05: 0.0912 - within_eps_0_1: 0.1816 - val_log_cosh: 0.1127 - val_loss: 0.0314 - val_within_eps_0_005: 0.0105 - val_within_eps_0_01: 0.0213 - val_within_eps_0_02: 0.0424 - val_within_eps_0_05: 0.1075 - val_within_eps_0_1: 0.2142\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0522 - loss: 0.0216 - within_eps_0_005: 0.0122 - within_eps_0_01: 0.0243 - within_eps_0_02: 0.0488 - within_eps_0_05: 0.1211 - within_eps_0_1: 0.2398 - val_log_cosh: 0.0754 - val_loss: 0.0237 - val_within_eps_0_005: 0.0129 - val_within_eps_0_01: 0.0256 - val_within_eps_0_02: 0.0513 - val_within_eps_0_05: 0.1283 - val_within_eps_0_1: 0.2576\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0482 - loss: 0.0206 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0507 - within_eps_0_05: 0.1266 - within_eps_0_1: 0.2499 - val_log_cosh: 0.0711 - val_loss: 0.0228 - val_within_eps_0_005: 0.0128 - val_within_eps_0_01: 0.0257 - val_within_eps_0_02: 0.0518 - val_within_eps_0_05: 0.1304 - val_within_eps_0_1: 0.2639\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0434 - loss: 0.0192 - within_eps_0_005: 0.0133 - within_eps_0_01: 0.0268 - within_eps_0_02: 0.0538 - within_eps_0_05: 0.1341 - within_eps_0_1: 0.2642 - val_log_cosh: 0.0750 - val_loss: 0.0235 - val_within_eps_0_005: 0.0139 - val_within_eps_0_01: 0.0275 - val_within_eps_0_02: 0.0543 - val_within_eps_0_05: 0.1325 - val_within_eps_0_1: 0.2670\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0389 - loss: 0.0179 - within_eps_0_005: 0.0144 - within_eps_0_01: 0.0288 - within_eps_0_02: 0.0569 - within_eps_0_05: 0.1414 - within_eps_0_1: 0.2786 - val_log_cosh: 0.0735 - val_loss: 0.0231 - val_within_eps_0_005: 0.0153 - val_within_eps_0_01: 0.0304 - val_within_eps_0_02: 0.0609 - val_within_eps_0_05: 0.1494 - val_within_eps_0_1: 0.2861\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0352 - loss: 0.0168 - within_eps_0_005: 0.0151 - within_eps_0_01: 0.0300 - within_eps_0_02: 0.0597 - within_eps_0_05: 0.1493 - within_eps_0_1: 0.2930 - val_log_cosh: 0.0755 - val_loss: 0.0234 - val_within_eps_0_005: 0.0130 - val_within_eps_0_01: 0.0262 - val_within_eps_0_02: 0.0527 - val_within_eps_0_05: 0.1341 - val_within_eps_0_1: 0.2728\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0310 - loss: 0.0155 - within_eps_0_005: 0.0161 - within_eps_0_01: 0.0321 - within_eps_0_02: 0.0640 - within_eps_0_05: 0.1593 - within_eps_0_1: 0.3116 - val_log_cosh: 0.0797 - val_loss: 0.0243 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0270 - val_within_eps_0_02: 0.0541 - val_within_eps_0_05: 0.1345 - val_within_eps_0_1: 0.2680\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0271 - loss: 0.0142 - within_eps_0_005: 0.0171 - within_eps_0_01: 0.0340 - within_eps_0_02: 0.0683 - within_eps_0_05: 0.1698 - within_eps_0_1: 0.3326 - val_log_cosh: 0.0841 - val_loss: 0.0253 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0268 - val_within_eps_0_02: 0.0548 - val_within_eps_0_05: 0.1376 - val_within_eps_0_1: 0.2663\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0241 - loss: 0.0131 - within_eps_0_005: 0.0183 - within_eps_0_01: 0.0365 - within_eps_0_02: 0.0731 - within_eps_0_05: 0.1810 - within_eps_0_1: 0.3532 - val_log_cosh: 0.0850 - val_loss: 0.0255 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1434 - val_within_eps_0_1: 0.2733\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0209 - loss: 0.0120 - within_eps_0_005: 0.0196 - within_eps_0_01: 0.0395 - within_eps_0_02: 0.0789 - within_eps_0_05: 0.1947 - within_eps_0_1: 0.3774 - val_log_cosh: 0.0768 - val_loss: 0.0236 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0269 - val_within_eps_0_02: 0.0541 - val_within_eps_0_05: 0.1359 - val_within_eps_0_1: 0.2687\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - log_cosh: 0.0184 - loss: 0.0110 - within_eps_0_005: 0.0212 - within_eps_0_01: 0.0422 - within_eps_0_02: 0.0842 - within_eps_0_05: 0.2085 - within_eps_0_1: 0.4022 - val_log_cosh: 0.0826 - val_loss: 0.0249 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0286 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1433 - val_within_eps_0_1: 0.2739\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0159 - loss: 0.0099 - within_eps_0_005: 0.0230 - within_eps_0_01: 0.0458 - within_eps_0_02: 0.0912 - within_eps_0_05: 0.2252 - within_eps_0_1: 0.4315 - val_log_cosh: 0.0839 - val_loss: 0.0254 - val_within_eps_0_005: 0.0146 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0595 - val_within_eps_0_05: 0.1490 - val_within_eps_0_1: 0.2824\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - log_cosh: 0.0141 - loss: 0.0091 - within_eps_0_005: 0.0244 - within_eps_0_01: 0.0486 - within_eps_0_02: 0.0974 - within_eps_0_05: 0.2405 - within_eps_0_1: 0.4581 - val_log_cosh: 0.0908 - val_loss: 0.0267 - val_within_eps_0_005: 0.0144 - val_within_eps_0_01: 0.0285 - val_within_eps_0_02: 0.0573 - val_within_eps_0_05: 0.1442 - val_within_eps_0_1: 0.2764\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0119 - loss: 0.0081 - within_eps_0_005: 0.0267 - within_eps_0_01: 0.0533 - within_eps_0_02: 0.1065 - within_eps_0_05: 0.2622 - within_eps_0_1: 0.4958 - val_log_cosh: 0.1111 - val_loss: 0.0319 - val_within_eps_0_005: 0.0079 - val_within_eps_0_01: 0.0158 - val_within_eps_0_02: 0.0318 - val_within_eps_0_05: 0.0817 - val_within_eps_0_1: 0.1622\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0130 - loss: 0.0085 - within_eps_0_005: 0.0256 - within_eps_0_01: 0.0515 - within_eps_0_02: 0.1026 - within_eps_0_05: 0.2530 - within_eps_0_1: 0.4804 - val_log_cosh: 0.0850 - val_loss: 0.0254 - val_within_eps_0_005: 0.0132 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1371 - val_within_eps_0_1: 0.2743\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0089 - loss: 0.0065 - within_eps_0_005: 0.0314 - within_eps_0_01: 0.0626 - within_eps_0_02: 0.1241 - within_eps_0_05: 0.3032 - within_eps_0_1: 0.5617 - val_log_cosh: 0.1334 - val_loss: 0.0357 - val_within_eps_0_005: 0.0103 - val_within_eps_0_01: 0.0205 - val_within_eps_0_02: 0.0414 - val_within_eps_0_05: 0.1040 - val_within_eps_0_1: 0.2004\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0106 - loss: 0.0073 - within_eps_0_005: 0.0290 - within_eps_0_01: 0.0580 - within_eps_0_02: 0.1156 - within_eps_0_05: 0.2838 - within_eps_0_1: 0.5307 - val_log_cosh: 0.1454 - val_loss: 0.0384 - val_within_eps_0_005: 0.0093 - val_within_eps_0_01: 0.0186 - val_within_eps_0_02: 0.0373 - val_within_eps_0_05: 0.0895 - val_within_eps_0_1: 0.1670\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0098 - loss: 0.0069 - within_eps_0_005: 0.0302 - within_eps_0_01: 0.0604 - within_eps_0_02: 0.1208 - within_eps_0_05: 0.2950 - within_eps_0_1: 0.5480 - val_log_cosh: 0.0845 - val_loss: 0.0251 - val_within_eps_0_005: 0.0161 - val_within_eps_0_01: 0.0320 - val_within_eps_0_02: 0.0637 - val_within_eps_0_05: 0.1539 - val_within_eps_0_1: 0.2845\n",
      "  -> min val_log_cosh=0.071138031781 | min val_huber=0.022777425125\n",
      "\n",
      "--- Entrenando δ=0.1 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - log_cosh: 0.1220 - loss: 0.0352 - within_eps_0_005: 0.0090 - within_eps_0_01: 0.0179 - within_eps_0_02: 0.0357 - within_eps_0_05: 0.0895 - within_eps_0_1: 0.1772 - val_log_cosh: 0.1074 - val_loss: 0.0305 - val_within_eps_0_005: 0.0111 - val_within_eps_0_01: 0.0218 - val_within_eps_0_02: 0.0431 - val_within_eps_0_05: 0.1079 - val_within_eps_0_1: 0.2124\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - log_cosh: 0.0533 - loss: 0.0220 - within_eps_0_005: 0.0120 - within_eps_0_01: 0.0241 - within_eps_0_02: 0.0482 - within_eps_0_05: 0.1205 - within_eps_0_1: 0.2379 - val_log_cosh: 0.0744 - val_loss: 0.0238 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0267 - val_within_eps_0_02: 0.0533 - val_within_eps_0_05: 0.1311 - val_within_eps_0_1: 0.2516\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0493 - loss: 0.0210 - within_eps_0_005: 0.0125 - within_eps_0_01: 0.0250 - within_eps_0_02: 0.0498 - within_eps_0_05: 0.1246 - within_eps_0_1: 0.2462 - val_log_cosh: 0.0667 - val_loss: 0.0219 - val_within_eps_0_005: 0.0142 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0570 - val_within_eps_0_05: 0.1419 - val_within_eps_0_1: 0.2750\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0445 - loss: 0.0197 - within_eps_0_005: 0.0133 - within_eps_0_01: 0.0264 - within_eps_0_02: 0.0527 - within_eps_0_05: 0.1315 - within_eps_0_1: 0.2594 - val_log_cosh: 0.0681 - val_loss: 0.0221 - val_within_eps_0_005: 0.0154 - val_within_eps_0_01: 0.0305 - val_within_eps_0_02: 0.0602 - val_within_eps_0_05: 0.1449 - val_within_eps_0_1: 0.2776\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0402 - loss: 0.0185 - within_eps_0_005: 0.0138 - within_eps_0_01: 0.0277 - within_eps_0_02: 0.0554 - within_eps_0_05: 0.1388 - within_eps_0_1: 0.2734 - val_log_cosh: 0.0670 - val_loss: 0.0219 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0298 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1453 - val_within_eps_0_1: 0.2775\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0353 - loss: 0.0170 - within_eps_0_005: 0.0147 - within_eps_0_01: 0.0298 - within_eps_0_02: 0.0595 - within_eps_0_05: 0.1483 - within_eps_0_1: 0.2914 - val_log_cosh: 0.0678 - val_loss: 0.0220 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0300 - val_within_eps_0_02: 0.0599 - val_within_eps_0_05: 0.1470 - val_within_eps_0_1: 0.2775\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0317 - loss: 0.0158 - within_eps_0_005: 0.0159 - within_eps_0_01: 0.0319 - within_eps_0_02: 0.0637 - within_eps_0_05: 0.1574 - within_eps_0_1: 0.3082 - val_log_cosh: 0.0725 - val_loss: 0.0230 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0293 - val_within_eps_0_02: 0.0586 - val_within_eps_0_05: 0.1442 - val_within_eps_0_1: 0.2761\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0281 - loss: 0.0146 - within_eps_0_005: 0.0170 - within_eps_0_01: 0.0338 - within_eps_0_02: 0.0674 - within_eps_0_05: 0.1672 - within_eps_0_1: 0.3271 - val_log_cosh: 0.0791 - val_loss: 0.0244 - val_within_eps_0_005: 0.0136 - val_within_eps_0_01: 0.0274 - val_within_eps_0_02: 0.0548 - val_within_eps_0_05: 0.1363 - val_within_eps_0_1: 0.2697\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0246 - loss: 0.0134 - within_eps_0_005: 0.0183 - within_eps_0_01: 0.0362 - within_eps_0_02: 0.0722 - within_eps_0_05: 0.1789 - within_eps_0_1: 0.3480 - val_log_cosh: 0.0925 - val_loss: 0.0279 - val_within_eps_0_005: 0.0104 - val_within_eps_0_01: 0.0213 - val_within_eps_0_02: 0.0443 - val_within_eps_0_05: 0.1152 - val_within_eps_0_1: 0.2358\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0216 - loss: 0.0123 - within_eps_0_005: 0.0192 - within_eps_0_01: 0.0385 - within_eps_0_02: 0.0768 - within_eps_0_05: 0.1909 - within_eps_0_1: 0.3707 - val_log_cosh: 0.0776 - val_loss: 0.0242 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0578 - val_within_eps_0_05: 0.1438 - val_within_eps_0_1: 0.2780\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0193 - loss: 0.0114 - within_eps_0_005: 0.0205 - within_eps_0_01: 0.0411 - within_eps_0_02: 0.0817 - within_eps_0_05: 0.2027 - within_eps_0_1: 0.3920 - val_log_cosh: 0.0763 - val_loss: 0.0240 - val_within_eps_0_005: 0.0131 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0532 - val_within_eps_0_05: 0.1312 - val_within_eps_0_1: 0.2597\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0166 - loss: 0.0103 - within_eps_0_005: 0.0223 - within_eps_0_01: 0.0446 - within_eps_0_02: 0.0886 - within_eps_0_05: 0.2190 - within_eps_0_1: 0.4204 - val_log_cosh: 0.0882 - val_loss: 0.0266 - val_within_eps_0_005: 0.0133 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0525 - val_within_eps_0_05: 0.1298 - val_within_eps_0_1: 0.2497\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0138 - loss: 0.0090 - within_eps_0_005: 0.0245 - within_eps_0_01: 0.0488 - within_eps_0_02: 0.0976 - within_eps_0_05: 0.2411 - within_eps_0_1: 0.4604 - val_log_cosh: 0.0843 - val_loss: 0.0258 - val_within_eps_0_005: 0.0124 - val_within_eps_0_01: 0.0245 - val_within_eps_0_02: 0.0489 - val_within_eps_0_05: 0.1218 - val_within_eps_0_1: 0.2315\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0149 - loss: 0.0095 - within_eps_0_005: 0.0241 - within_eps_0_01: 0.0479 - within_eps_0_02: 0.0952 - within_eps_0_05: 0.2356 - within_eps_0_1: 0.4497 - val_log_cosh: 0.1087 - val_loss: 0.0310 - val_within_eps_0_005: 0.0117 - val_within_eps_0_01: 0.0234 - val_within_eps_0_02: 0.0471 - val_within_eps_0_05: 0.1161 - val_within_eps_0_1: 0.2175\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0131 - loss: 0.0086 - within_eps_0_005: 0.0253 - within_eps_0_01: 0.0510 - within_eps_0_02: 0.1024 - within_eps_0_05: 0.2521 - within_eps_0_1: 0.4780 - val_log_cosh: 0.0935 - val_loss: 0.0280 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0265 - val_within_eps_0_02: 0.0523 - val_within_eps_0_05: 0.1267 - val_within_eps_0_1: 0.2370\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - log_cosh: 0.0096 - loss: 0.0069 - within_eps_0_005: 0.0298 - within_eps_0_01: 0.0594 - within_eps_0_02: 0.1187 - within_eps_0_05: 0.2909 - within_eps_0_1: 0.5417 - val_log_cosh: 0.0755 - val_loss: 0.0239 - val_within_eps_0_005: 0.0112 - val_within_eps_0_01: 0.0228 - val_within_eps_0_02: 0.0468 - val_within_eps_0_05: 0.1234 - val_within_eps_0_1: 0.2639\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0086 - loss: 0.0063 - within_eps_0_005: 0.0318 - within_eps_0_01: 0.0633 - within_eps_0_02: 0.1267 - within_eps_0_05: 0.3095 - within_eps_0_1: 0.5713 - val_log_cosh: 0.0889 - val_loss: 0.0270 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0251 - val_within_eps_0_02: 0.0498 - val_within_eps_0_05: 0.1255 - val_within_eps_0_1: 0.2444\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0068 - loss: 0.0053 - within_eps_0_005: 0.0362 - within_eps_0_01: 0.0724 - within_eps_0_02: 0.1441 - within_eps_0_05: 0.3493 - within_eps_0_1: 0.6299 - val_log_cosh: 0.1021 - val_loss: 0.0303 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0212 - val_within_eps_0_02: 0.0426 - val_within_eps_0_05: 0.1046 - val_within_eps_0_1: 0.2059\n",
      "  -> min val_log_cosh=0.066684223711 | min val_huber=0.021930458024\n",
      "\n",
      "--- Entrenando δ=0.13649090826511381 ---\n",
      "Epoch 1/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - log_cosh: 0.1182 - loss: 0.0453 - within_eps_0_005: 0.0089 - within_eps_0_01: 0.0179 - within_eps_0_02: 0.0356 - within_eps_0_05: 0.0891 - within_eps_0_1: 0.1768 - val_log_cosh: 0.1020 - val_loss: 0.0381 - val_within_eps_0_005: 0.0104 - val_within_eps_0_01: 0.0211 - val_within_eps_0_02: 0.0425 - val_within_eps_0_05: 0.1057 - val_within_eps_0_1: 0.2159\n",
      "Epoch 2/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - log_cosh: 0.0510 - loss: 0.0273 - within_eps_0_005: 0.0123 - within_eps_0_01: 0.0245 - within_eps_0_02: 0.0491 - within_eps_0_05: 0.1227 - within_eps_0_1: 0.2421 - val_log_cosh: 0.0664 - val_loss: 0.0279 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0284 - val_within_eps_0_02: 0.0563 - val_within_eps_0_05: 0.1378 - val_within_eps_0_1: 0.2696\n",
      "Epoch 3/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0473 - loss: 0.0259 - within_eps_0_005: 0.0126 - within_eps_0_01: 0.0254 - within_eps_0_02: 0.0511 - within_eps_0_05: 0.1269 - within_eps_0_1: 0.2516 - val_log_cosh: 0.0647 - val_loss: 0.0274 - val_within_eps_0_005: 0.0149 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0583 - val_within_eps_0_05: 0.1441 - val_within_eps_0_1: 0.2783\n",
      "Epoch 4/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - log_cosh: 0.0429 - loss: 0.0243 - within_eps_0_005: 0.0133 - within_eps_0_01: 0.0270 - within_eps_0_02: 0.0537 - within_eps_0_05: 0.1338 - within_eps_0_1: 0.2643 - val_log_cosh: 0.0685 - val_loss: 0.0284 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0598 - val_within_eps_0_05: 0.1483 - val_within_eps_0_1: 0.2827\n",
      "Epoch 5/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0383 - loss: 0.0225 - within_eps_0_005: 0.0143 - within_eps_0_01: 0.0286 - within_eps_0_02: 0.0570 - within_eps_0_05: 0.1422 - within_eps_0_1: 0.2794 - val_log_cosh: 0.0675 - val_loss: 0.0280 - val_within_eps_0_005: 0.0150 - val_within_eps_0_01: 0.0301 - val_within_eps_0_02: 0.0607 - val_within_eps_0_05: 0.1483 - val_within_eps_0_1: 0.2859\n",
      "Epoch 6/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0340 - loss: 0.0208 - within_eps_0_005: 0.0150 - within_eps_0_01: 0.0300 - within_eps_0_02: 0.0603 - within_eps_0_05: 0.1500 - within_eps_0_1: 0.2958 - val_log_cosh: 0.0741 - val_loss: 0.0300 - val_within_eps_0_005: 0.0152 - val_within_eps_0_01: 0.0302 - val_within_eps_0_02: 0.0604 - val_within_eps_0_05: 0.1474 - val_within_eps_0_1: 0.2846\n",
      "Epoch 7/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - log_cosh: 0.0307 - loss: 0.0193 - within_eps_0_005: 0.0160 - within_eps_0_01: 0.0319 - within_eps_0_02: 0.0639 - within_eps_0_05: 0.1596 - within_eps_0_1: 0.3120 - val_log_cosh: 0.0788 - val_loss: 0.0315 - val_within_eps_0_005: 0.0143 - val_within_eps_0_01: 0.0288 - val_within_eps_0_02: 0.0578 - val_within_eps_0_05: 0.1438 - val_within_eps_0_1: 0.2792\n",
      "Epoch 8/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0266 - loss: 0.0174 - within_eps_0_005: 0.0173 - within_eps_0_01: 0.0346 - within_eps_0_02: 0.0692 - within_eps_0_05: 0.1723 - within_eps_0_1: 0.3358 - val_log_cosh: 0.0836 - val_loss: 0.0330 - val_within_eps_0_005: 0.0141 - val_within_eps_0_01: 0.0283 - val_within_eps_0_02: 0.0568 - val_within_eps_0_05: 0.1391 - val_within_eps_0_1: 0.2681\n",
      "Epoch 9/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - log_cosh: 0.0232 - loss: 0.0159 - within_eps_0_005: 0.0186 - within_eps_0_01: 0.0372 - within_eps_0_02: 0.0743 - within_eps_0_05: 0.1831 - within_eps_0_1: 0.3574 - val_log_cosh: 0.0867 - val_loss: 0.0340 - val_within_eps_0_005: 0.0140 - val_within_eps_0_01: 0.0282 - val_within_eps_0_02: 0.0554 - val_within_eps_0_05: 0.1358 - val_within_eps_0_1: 0.2570\n",
      "Epoch 10/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0202 - loss: 0.0143 - within_eps_0_005: 0.0202 - within_eps_0_01: 0.0400 - within_eps_0_02: 0.0798 - within_eps_0_05: 0.1979 - within_eps_0_1: 0.3829 - val_log_cosh: 0.0832 - val_loss: 0.0324 - val_within_eps_0_005: 0.0148 - val_within_eps_0_01: 0.0295 - val_within_eps_0_02: 0.0585 - val_within_eps_0_05: 0.1438 - val_within_eps_0_1: 0.2715\n",
      "Epoch 11/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - log_cosh: 0.0195 - loss: 0.0139 - within_eps_0_005: 0.0205 - within_eps_0_01: 0.0411 - within_eps_0_02: 0.0817 - within_eps_0_05: 0.2019 - within_eps_0_1: 0.3911 - val_log_cosh: 0.0800 - val_loss: 0.0316 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0273 - val_within_eps_0_02: 0.0555 - val_within_eps_0_05: 0.1406 - val_within_eps_0_1: 0.2742\n",
      "Epoch 12/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0169 - loss: 0.0125 - within_eps_0_005: 0.0221 - within_eps_0_01: 0.0443 - within_eps_0_02: 0.0883 - within_eps_0_05: 0.2176 - within_eps_0_1: 0.4186 - val_log_cosh: 0.0868 - val_loss: 0.0344 - val_within_eps_0_005: 0.0134 - val_within_eps_0_01: 0.0264 - val_within_eps_0_02: 0.0524 - val_within_eps_0_05: 0.1282 - val_within_eps_0_1: 0.2486\n",
      "Epoch 13/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0139 - loss: 0.0108 - within_eps_0_005: 0.0242 - within_eps_0_01: 0.0485 - within_eps_0_02: 0.0969 - within_eps_0_05: 0.2394 - within_eps_0_1: 0.4576 - val_log_cosh: 0.0901 - val_loss: 0.0356 - val_within_eps_0_005: 0.0109 - val_within_eps_0_01: 0.0216 - val_within_eps_0_02: 0.0434 - val_within_eps_0_05: 0.1123 - val_within_eps_0_1: 0.2260\n",
      "Epoch 14/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0116 - loss: 0.0093 - within_eps_0_005: 0.0266 - within_eps_0_01: 0.0536 - within_eps_0_02: 0.1076 - within_eps_0_05: 0.2636 - within_eps_0_1: 0.4981 - val_log_cosh: 0.0816 - val_loss: 0.0331 - val_within_eps_0_005: 0.0135 - val_within_eps_0_01: 0.0263 - val_within_eps_0_02: 0.0520 - val_within_eps_0_05: 0.1266 - val_within_eps_0_1: 0.2456\n",
      "Epoch 15/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0101 - loss: 0.0083 - within_eps_0_005: 0.0291 - within_eps_0_01: 0.0581 - within_eps_0_02: 0.1156 - within_eps_0_05: 0.2835 - within_eps_0_1: 0.5314 - val_log_cosh: 0.1020 - val_loss: 0.0395 - val_within_eps_0_005: 0.0098 - val_within_eps_0_01: 0.0193 - val_within_eps_0_02: 0.0387 - val_within_eps_0_05: 0.0972 - val_within_eps_0_1: 0.1856\n",
      "Epoch 16/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0111 - loss: 0.0090 - within_eps_0_005: 0.0282 - within_eps_0_01: 0.0563 - within_eps_0_02: 0.1120 - within_eps_0_05: 0.2743 - within_eps_0_1: 0.5154 - val_log_cosh: 0.0993 - val_loss: 0.0385 - val_within_eps_0_005: 0.0106 - val_within_eps_0_01: 0.0210 - val_within_eps_0_02: 0.0415 - val_within_eps_0_05: 0.0990 - val_within_eps_0_1: 0.1946\n",
      "Epoch 17/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0075 - loss: 0.0065 - within_eps_0_005: 0.0339 - within_eps_0_01: 0.0678 - within_eps_0_02: 0.1345 - within_eps_0_05: 0.3283 - within_eps_0_1: 0.6002 - val_log_cosh: 0.0870 - val_loss: 0.0352 - val_within_eps_0_005: 0.0116 - val_within_eps_0_01: 0.0230 - val_within_eps_0_02: 0.0458 - val_within_eps_0_05: 0.1136 - val_within_eps_0_1: 0.2173\n",
      "Epoch 18/160\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - log_cosh: 0.0071 - loss: 0.0062 - within_eps_0_005: 0.0362 - within_eps_0_01: 0.0719 - within_eps_0_02: 0.1428 - within_eps_0_05: 0.3457 - within_eps_0_1: 0.6245 - val_log_cosh: 0.0790 - val_loss: 0.0319 - val_within_eps_0_005: 0.0127 - val_within_eps_0_01: 0.0252 - val_within_eps_0_02: 0.0501 - val_within_eps_0_05: 0.1282 - val_within_eps_0_1: 0.2507\n",
      "  -> min val_log_cosh=0.064745962620 | min val_huber=0.027365813032\n",
      "\n",
      "Tabla val_log_cosh(min) por δ (orden asc):\n",
      "  δ=    0.01: val_log_cosh=0.063755229115 | val_huber=0.002534710336\n",
      "  δ=0.0568381: val_log_cosh=0.063852488995 | val_huber=0.012976211496\n",
      "  δ=0.136491: val_log_cosh=0.064745962620 | val_huber=0.027365813032\n",
      "  δ=    0.02: val_log_cosh=0.066299453378 | val_huber=0.005066788755\n",
      "  δ=     0.1: val_log_cosh=0.066684223711 | val_huber=0.021930458024\n",
      "  δ=    0.05: val_log_cosh=0.070718660951 | val_huber=0.012302746996\n",
      "  δ=0.0992432: val_log_cosh=0.071138031781 | val_huber=0.022777425125\n",
      "  δ=0.0279375: val_log_cosh=0.075747221708 | val_huber=0.007478351705\n",
      "\n",
      ">>> Mejor δ por val_log_cosh: 0.01 (val_log_cosh=0.063755229115)\n",
      "\n",
      "Resultados TEST - Escenario L (Transformer)\n",
      "  loss (Huber):              0.019598\n",
      "  log_cosh:                  1.585774\n",
      "  within_eps_0_005          : 0.004878\n",
      "  within_eps_0_01           : 0.009488\n",
      "  within_eps_0_02           : 0.019273\n",
      "  within_eps_0_05           : 0.046995\n",
      "  within_eps_0_1            : 0.089028\n",
      "  AUTC[0.005–0.100]:         0.048151\n",
      "\n",
      "=== Mejor δ por escenario (Transformer, métrica común: val_log_cosh) ===\n",
      "  S: 0.04116208553314208  -> ./models_transformer_huber_sweep/transformer_huber_w20_h1_delta0_04116208553_S.keras\n",
      "  M: 0.1  -> ./models_transformer_huber_sweep/transformer_huber_w60_h5_delta0_1_M.keras\n",
      "  L: 0.01  -> ./models_transformer_huber_sweep/transformer_huber_w120_h20_delta0_01_L.keras\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# TRANSFORMER + Huber (sweep delta)\n",
    "# Selección de δ por métrica común: val_log_cosh\n",
    "# Grid de δ calibrado con cuantiles de |e| (baseline persistencia) en VAL\n",
    "# Guardado .keras (Flask-ready, compile=False)\n",
    "# =========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import List, Tuple\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization, Embedding,\n",
    "    MultiHeadAttention, Reshape\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ---------- Scaler único (MinMax) ----------\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    from joblib import load\n",
    "    scaler = load(\"scaler_modelos.joblib\")\n",
    "\n",
    "# ---------- Config ----------\n",
    "MODEL_DIR = \"./models_transformer_huber_sweep\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# EPS para métricas within (escala normalizada [0,1])\n",
    "EPS_LIST = [0.005, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def infer_shapes_from_dataset(ds: tf.data.Dataset) -> Tuple[int, int, int]:\n",
    "    for xb, yb in ds.take(1):\n",
    "        w = int(xb.shape[1]); f = int(xb.shape[2]); h = int(yb.shape[1])\n",
    "        return w, f, h\n",
    "    raise ValueError(\"Dataset vacío\")\n",
    "\n",
    "def _eps_tag(x: float) -> str:\n",
    "    s = f\"{x:.10g}\"\n",
    "    s = s.rstrip('0').rstrip('.') if '.' in s else s\n",
    "    return s.replace('.', '_')\n",
    "\n",
    "# ---------- Métricas ----------\n",
    "def log_cosh_metric(y_true, y_pred):\n",
    "    e = tf.cast(y_pred, tf.float32) - tf.cast(y_true, tf.float32)\n",
    "    ae = tf.abs(e)\n",
    "    return tf.reduce_mean(ae + tf.nn.softplus(-2.0 * ae) - tf.math.log(2.0))\n",
    "log_cosh_metric.__name__ = \"log_cosh\"\n",
    "\n",
    "def make_within_eps_vector_metric(eps_vec: np.ndarray, tag: str):\n",
    "    eps_tf = tf.constant(eps_vec.astype(np.float32), dtype=tf.float32)  # (F,)\n",
    "    def within_eps(y_true, y_pred):\n",
    "        diff = tf.abs(tf.cast(y_pred, tf.float32) - tf.cast(y_true, tf.float32))  # (B,H,F)\n",
    "        thr  = eps_tf[tf.newaxis, tf.newaxis, :]\n",
    "        hit  = tf.cast(diff <= thr, tf.float32)\n",
    "        return tf.reduce_mean(hit)\n",
    "    within_eps.__name__ = tag\n",
    "    return within_eps\n",
    "\n",
    "def build_within_metrics_minmax(scaler, eps_list: List[float], n_features: int):\n",
    "    if not hasattr(scaler, \"data_range_\"):\n",
    "        raise ValueError(\"Se esperaba MinMaxScaler con data_range_.\")\n",
    "    if len(scaler.data_range_) != n_features:\n",
    "        raise ValueError(\"scaler.data_range_ no coincide con n_features.\")\n",
    "    metrics = [log_cosh_metric]\n",
    "    for e in eps_list:\n",
    "        eps_vec = np.full((n_features,), float(e), dtype=np.float32)\n",
    "        metrics.append(make_within_eps_vector_metric(eps_vec, f\"within_eps_{_eps_tag(e)}\"))\n",
    "    return metrics\n",
    "\n",
    "def _get_metric_value_relaxed(res: dict, base_name: str):\n",
    "    \"\"\"\n",
    "    Devuelve res[base_name] si existe; si no, busca cualquier clave que empiece por base_name + '_'\n",
    "    (para cubrir sufijos que Keras añade como '_1', '_2', etc.). Si no hay match, devuelve NaN.\n",
    "    \"\"\"\n",
    "    if base_name in res and np.isfinite(res[base_name]):\n",
    "        return float(res[base_name])\n",
    "    # Busca con sufijo\n",
    "    for k, v in res.items():\n",
    "        if k.startswith(base_name + \"_\"):\n",
    "            try:\n",
    "                v = float(v)\n",
    "                if np.isfinite(v):\n",
    "                    return v\n",
    "            except Exception:\n",
    "                pass\n",
    "    return float(\"nan\")\n",
    "\n",
    "def compute_autc_from_results(res: dict, eps_list) -> float:\n",
    "    eps = np.array(sorted(eps_list), dtype=np.float64)\n",
    "    acc = []\n",
    "    missing = []\n",
    "    for e in eps:\n",
    "        base = f\"within_eps_{_eps_tag(e)}\"\n",
    "        val = _get_metric_value_relaxed(res, base)\n",
    "        acc.append(val)\n",
    "        if not np.isfinite(val):\n",
    "            missing.append(base)\n",
    "    acc = np.array(acc, dtype=np.float64)\n",
    "\n",
    "    # Debug útil si algo falla\n",
    "    if missing:\n",
    "        print(\"[AUTC] Aviso: no se encontraron métricas:\", missing)\n",
    "        print(\"[AUTC] Claves disponibles:\", sorted([k for k in res.keys() if \"within_eps_\" in k]))\n",
    "\n",
    "    mask = np.isfinite(acc)\n",
    "    if mask.sum() < 2:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    return float(np.trapz(acc[mask], eps[mask]) / (eps[mask][-1] - eps[mask][0]))\n",
    "\n",
    "\n",
    "# ---------- Bloque Transformer ----------\n",
    "def transformer_encoder(x, d_model: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "    attn_out = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model // num_heads,\n",
    "        dropout=dropout\n",
    "    )(x, x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + Dropout(dropout)(attn_out))\n",
    "\n",
    "    ffn = Dense(ff_dim, activation='relu')(x)\n",
    "    ffn = Dropout(dropout)(ffn)\n",
    "    ffn = Dense(d_model)(ffn)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + Dropout(dropout)(ffn))\n",
    "    return x\n",
    "\n",
    "# ---------- Modelo Transformer ----------\n",
    "def build_transformer_point_model(window: int, n_features: int, horizon: int,\n",
    "                                  d_model: int = 128, num_heads: int = 4,\n",
    "                                  num_layers: int = 2, ff_dim: int = 256,\n",
    "                                  dropout: float = 0.1) -> Model:\n",
    "    inp = Input(shape=(window, n_features))\n",
    "    x = Dense(d_model)(inp)  # (B, W, d_model)\n",
    "\n",
    "    positions = tf.range(start=0, limit=window, delta=1)\n",
    "    pos_emb = Embedding(input_dim=window, output_dim=d_model)(positions)  # (W, d_model)\n",
    "    x = x + pos_emb  # broadcast sobre batch\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_encoder(x, d_model, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x_last = x[:, -1, :]  # (B, d_model)\n",
    "\n",
    "    h = Dense(ff_dim, activation='relu')(x_last)\n",
    "    h = Dropout(dropout)(h)\n",
    "    h = Dense(horizon * n_features)(h)\n",
    "    out = Reshape((horizon, n_features))(h)\n",
    "    return Model(inp, out, name=f\"TRANSFORMER_POINT_H{horizon}_F{n_features}\")\n",
    "\n",
    "# ---------- Pérdida Huber ----------\n",
    "def make_huber_loss(delta: float):\n",
    "    base = tf.keras.losses.Huber(delta=float(delta))\n",
    "    def huber_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32); y_pred = tf.cast(y_pred, tf.float32)\n",
    "        return base(y_true, y_pred)\n",
    "    huber_loss.__name__ = f\"huber_delta_{_eps_tag(delta)}\"\n",
    "    return huber_loss\n",
    "\n",
    "# ---------- Calibración del grid de δ (cuantiles de |e| con baseline persistencia) ----------\n",
    "def estimate_error_quantiles_persistence(val_ds: tf.data.Dataset, max_batches: int = 256):\n",
    "    \"\"\"Cuantiles de |e| en VAL usando baseline de persistencia (y_hat = último paso repetido).\"\"\"\n",
    "    errs = []\n",
    "    taken = 0\n",
    "    for xb, yb in val_ds:\n",
    "        yhat = tf.repeat(xb[:, -1:, :], repeats=tf.shape(yb)[1], axis=1)  # (B,H,F)\n",
    "        e = tf.abs(tf.cast(yb, tf.float32) - tf.cast(yhat, tf.float32)).numpy().ravel()\n",
    "        errs.append(e); taken += 1\n",
    "        if taken >= max_batches:\n",
    "            break\n",
    "    if not errs:\n",
    "        return [0.01, 0.02, 0.05, 0.1]\n",
    "    e = np.concatenate(errs)\n",
    "    qs = np.quantile(e, [0.5, 0.75, 0.9, 0.95])  # p50, p75, p90, p95\n",
    "    return list(qs)\n",
    "\n",
    "def build_delta_grid(val_ds: tf.data.Dataset):\n",
    "    base = [0.01, 0.02, 0.05, 0.1]\n",
    "    qs = estimate_error_quantiles_persistence(val_ds, max_batches=256)\n",
    "    cand = sorted(set(base + qs))\n",
    "    cand = [float(np.clip(c, 1e-4, 0.5)) for c in cand]\n",
    "    cand = sorted(set(cand))\n",
    "    print(\"\\nGrid δ (calibrado con cuantiles |e| en VAL):\", cand)\n",
    "    return cand\n",
    "\n",
    "# ---------- Entrenamiento para un δ (callbacks en val_log_cosh) ----------\n",
    "def train_for_delta(train_ds: tf.data.Dataset,\n",
    "                    val_ds: tf.data.Dataset,\n",
    "                    delta: float,\n",
    "                    scenario_tag: str,\n",
    "                    scaler) -> tuple[Model, float, str]:\n",
    "    w, f, h = infer_shapes_from_dataset(train_ds)\n",
    "    model = build_transformer_point_model(w, f, h)\n",
    "    metrics = build_within_metrics_minmax(scaler, EPS_LIST, n_features=f)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, clipnorm=1.0),\n",
    "        loss=make_huber_loss(delta),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    ckpt_path = os.path.join(\n",
    "        MODEL_DIR, f\"transformer_huber_w{w}_h{h}_delta{_eps_tag(delta)}{scenario_tag}.keras\"\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TerminateOnNaN(),\n",
    "        EarlyStopping(monitor=\"val_log_cosh\", mode=\"min\", patience=15, restore_best_weights=True),\n",
    "        ModelCheckpoint(ckpt_path, monitor=\"val_log_cosh\", mode=\"min\", save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(train_ds, validation_data=val_ds, epochs=160, callbacks=callbacks, verbose=1)\n",
    "    vlc = np.array(hist.history.get(\"val_log_cosh\", []), dtype=np.float32)\n",
    "    vlc = vlc[np.isfinite(vlc)]\n",
    "    best_val_logcosh = float(np.min(vlc)) if vlc.size > 0 else np.inf\n",
    "\n",
    "    vll = np.array(hist.history.get(\"val_loss\", []), dtype=np.float32)\n",
    "    vll = vll[np.isfinite(vll)]\n",
    "    best_val_huber = float(np.min(vll)) if vll.size > 0 else np.inf\n",
    "    \n",
    "    return model, best_val_logcosh, best_val_huber, ckpt_path\n",
    "\n",
    "# ---------- Barrido de deltas (selección por val_log_cosh) ----------\n",
    "def sweep_deltas(train_ds, val_ds, scenario_tag: str, scaler) -> tuple[Model, float, str]:\n",
    "    deltas = build_delta_grid(val_ds)\n",
    "    print(f\"\\n=== Barrido Huber delta {scenario_tag} (Transformer) ===\")\n",
    "    results = []  # (delta, best_val_logcosh, best_val_huber, ckpt_path)\n",
    "\n",
    "    best_score = np.inf; best_ckpt=None; best_delta=None; best_model=None\n",
    "    \n",
    "    for d in deltas:\n",
    "        print(f\"\\n--- Entrenando δ={d} ---\")\n",
    "        model, val_logcosh, val_huber, ckpt_path = train_for_delta(train_ds, val_ds, d, scenario_tag, scaler)\n",
    "        print(f\"  -> min val_log_cosh={val_logcosh:.12f} | min val_huber={val_huber:.12f}\")\n",
    "        results.append((d, val_logcosh, val_huber, ckpt_path))\n",
    "        if val_logcosh < best_score:  # selección por métrica común\n",
    "            best_score, best_ckpt, best_delta, best_model = val_logcosh, ckpt_path, d, model\n",
    "\n",
    "    # Carga el mejor checkpoint (Flask-ready)\n",
    "    if best_ckpt:\n",
    "        best_model = tf.keras.models.load_model(best_ckpt, compile=False)\n",
    "\n",
    "    # Tabla ordenada para inspección\n",
    "    results_sorted = sorted(results, key=lambda x: x[1])\n",
    "    print(\"\\nTabla val_log_cosh(min) por δ (orden asc):\")\n",
    "    for d, v_log, v_hub, _ in results_sorted:\n",
    "        print(f\"  δ={d:>8g}: val_log_cosh={v_log:.12f} | val_huber={v_hub:.12f}\")\n",
    "    print(f\"\\n>>> Mejor δ por val_log_cosh: {best_delta} (val_log_cosh={best_score:.12f})\")\n",
    "    return best_model, best_delta, best_ckpt\n",
    "\n",
    "# ---------- Evaluación en TEST ----------\n",
    "def evaluate_on_test(model: tf.keras.Model, ds: tf.data.Dataset, best_delta: float, scaler):\n",
    "    if (model is None) or (best_delta is None) or (not np.isfinite(best_delta)):\n",
    "        print(\"  [AVISO] No se pudo entrenar un modelo válido.\")\n",
    "        return\n",
    "    _, f, _ = infer_shapes_from_dataset(ds)\n",
    "    metrics = build_within_metrics_minmax(scaler, EPS_LIST, n_features=f)\n",
    "    model.compile(optimizer=\"adam\", loss=make_huber_loss(best_delta), metrics=metrics)\n",
    "\n",
    "    res = model.evaluate(ds, return_dict=True, verbose=0)\n",
    "    print(\"  loss (Huber):              {:.6f}\".format(res.get(\"loss\", float(\"nan\"))))\n",
    "    print(\"  log_cosh:                  {:.6f}\".format(res.get(\"log_cosh\", float(\"nan\"))))\n",
    "    for e in EPS_LIST:\n",
    "        key = f\"within_eps_{_eps_tag(e)}\"\n",
    "        print(f\"  {key:26s}: {res.get(key, float('nan')):.6f}\")\n",
    "    autc = compute_autc_from_results(res, EPS_LIST)\n",
    "    eps_min, eps_max = float(min(EPS_LIST)), float(max(EPS_LIST))\n",
    "    print(f\"  AUTC[{eps_min:.3f}–{eps_max:.3f}]:         {autc:.6f}\")\n",
    "\n",
    "# ================== EJECUCIÓN: TRES ESCENARIOS ==================\n",
    "# Usa tus datasets (sin shuffle en val/test):\n",
    "#   train_dss/val_dss/test_dss, train_dsm/val_dsm/test_dsm, train_dsl/val_dsl/test_dsl\n",
    "\n",
    "# Escenario S (20→1)\n",
    "model_s, delta_s, path_s = sweep_deltas(train_dss, val_dss, scenario_tag=\"_S\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario S (Transformer)\")\n",
    "evaluate_on_test(model_s, test_dss, best_delta=delta_s, scaler=scaler)\n",
    "\n",
    "# Escenario M (60→5)\n",
    "model_m, delta_m, path_m = sweep_deltas(train_dsm, val_dsm, scenario_tag=\"_M\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario M (Transformer)\")\n",
    "evaluate_on_test(model_m, test_dsm, best_delta=delta_m, scaler=scaler)\n",
    "\n",
    "# Escenario L (120→20)\n",
    "model_l, delta_l, path_l = sweep_deltas(train_dsl, val_dsl, scenario_tag=\"_L\", scaler=scaler)\n",
    "print(\"\\nResultados TEST - Escenario L (Transformer)\")\n",
    "evaluate_on_test(model_l, test_dsl, best_delta=delta_l, scaler=scaler)\n",
    "\n",
    "print(\"\\n=== Mejor δ por escenario (Transformer, métrica común: val_log_cosh) ===\")\n",
    "print(f\"  S: {delta_s}  -> {path_s}\")\n",
    "print(f\"  M: {delta_m}  -> {path_m}\")\n",
    "print(f\"  L: {delta_l}  -> {path_l}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e4eef-889c-4f81-b927-8f1dfe137bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
